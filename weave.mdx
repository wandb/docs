---
title: "W&B Weave"
description: "Track, test, and improve language model apps with W&B Weave"
mode: wide
---

W&B Weave is an observability and evaluation platform that helps you track, evaluate, and improve your LLM application. With Weave, you can:

* [Observe and debug](/weave/quickstart) your LLM application
* [Evaluate](/weave/tutorial-eval) your application's responses using scorers and LLM judges

## Get Started

The following quickstart docs guide you through how to use Weave's suite of tools.

<CardGroup cols={4}>
  <Card
    title="Track LLM inputs & outputs"
    icon="chart-line"
    href="/weave/quickstart"
  >
    Start by tracing a basic call to an LLM and reviewing the data in your W&B account.
  </Card>

  <Card
    title="Get started evaluating your app"
    icon="clipboard-check"
    href="/weave/tutorial-eval"
  >
    Learn how to build an evaluation pipeline using Weave scorers to test and track your application's performance.
  </Card>

  <Card
    title="Evaluate a RAG application"
    icon="search"
    href="/weave/tutorial-rag"
  >
    Build and evaluate RAG applications using Weave with LLM judges to measure retrieval quality.
  </Card>
  <Card
    title="Learn Weave with W&B Inference"
    icon="rocket"
    href="/weave/quickstart-inference"
  >
    Build and trace LLM applications using live open-source models without managing infrastructure or API keys.
  </Card>
</CardGroup>

## Install Weave

W&B Weave provides Python and TypeScript libraries. To install the Weave library, run the following command:

<Tabs>
  <Tab title="Python">
    ```bash
    pip install weave
    ```
  </Tab>
  <Tab title="TypeScript">
    ```bash
    pnpm install weave
    ```
  </Tab>
</Tabs>

To start using the Weave library, create a [Weights & Biases (W&B) account](https://wandb.ai) and [obtain a copy your API key](https://wandb.ai/authorize). The API key allows you to authenticate to your W&B account and start sending data to it.

