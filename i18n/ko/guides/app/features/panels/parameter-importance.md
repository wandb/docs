---
description: Visualize the relationships between your model's hyperparameters and
  output metrics
displayed_sidebar: default
---

# 파라미터 중요도

이 패널은 어떤 하이퍼파라미터가 가장 좋은 예측자였으며, 바람직한 메트릭 값과 높은 상관관계를 가졌는지를 보여줍니다.

![](https://paper-attachments.dropbox.com/s\_B78AACEDFC4B6CE0BF245AA5C54750B01173E5A39173E03BE6F3ACF776A01267\_1578795733856\_image.png)

**상관관계**는 하이퍼파라미터와 선택한 메트릭(이 경우 val\_loss) 사이의 선형 상관관계입니다. 따라서 높은 상관관계는 하이퍼파라미터의 값이 높을 때 메트릭의 값도 높고 반대의 경우도 마찬가지라는 것을 의미합니다. 상관관계는 훌륭한 지표이지만, 입력 간의 2차 상호작용을 포착할 수 없으며, 범위가 크게 다른 입력을 비교할 때 혼란스러울 수 있습니다.

그렇기 때문에 우리는 또한 **중요도** 메트릭을 계산합니다. 여기서는 하이퍼파라미터를 입력으로, 메트릭을 목표 출력으로 사용하여 랜덤 포레스트를 학습시키고 랜덤 포레스트의 특성 중요도 값을 보고합니다.

이 기술에 대한 아이디어는 [Fast.ai](http://fast.ai)에서 하이퍼파라미터 공간을 탐색하기 위해 랜덤 포레스트 특성 중요도를 사용하는 데 선구자적 역할을 한 [Jeremy Howard](https://twitter.com/jeremyphoward)와의 대화에서 영감을 받았습니다. 이 분석의 배경이 되는 동기에 대해 더 알고 싶다면 그의 뛰어난 [강의](http://course18.fast.ai/lessonsml1/lesson4.html) (그리고 이 [노트](https://forums.fast.ai/t/wiki-lesson-thread-lesson-4/7540))를 확인하는 것이 좋습니다.

이 하이퍼파라미터 중요도 패널은 상관관계가 높은 하이퍼파라미터 간의 복잡한 상호작용을 풀어줍니다. 이를 통해 모델 성능을 예측하는 데 가장 중요한 하이퍼파라미터가 무엇인지 보여주어 하이퍼파라미터 검색을 미세 조정하는 데 도움이 됩니다.

## 하이퍼파라미터 중요도 패널 만들기

W&B 프로젝트로 이동하세요. 프로젝트가 없다면, [이 프로젝트](https://app.wandb.ai/sweep/simpsons)를 사용할 수 있습니다.

프로젝트 페이지에서 **시각화 추가**를 클릭하세요.

![](https://paper-attachments.dropbox.com/s\_B78AACEDFC4B6CE0BF245AA5C54750B01173E5A39173E03BE6F3ACF776A01267\_1578795570241\_image.png)

그런 다음 **파라미터 중요도**를 선택하세요.

프로젝트에 [W&B를 통합](https://docs.wandb.com/quickstart)하는 것 외에 새로운 코드를 작성할 필요가 없습니다.

![](https://paper-attachments.dropbox.com/s\_B78AACEDFC4B6CE0BF245AA5C54750B01173E5A39173E03BE6F3ACF776A01267\_1578795636072\_image.png)

:::info
패널이 비어 있으면, 실행이 그룹화되지 않았는지 확인하세요
:::

## 하이퍼파라미터 중요도 패널 사용하기

파라미터 관리자 옆에 있는 마법봉을 클릭하여 가장 유용한 하이퍼파라미터 세트를 wandb가 시각화하도록 할 수 있습니다. 그런 다음 중요도에 따라 하이퍼파라미터를 정렬할 수 있습니다.

![자동 파라미터 시각화 사용하기](/images/app_ui/hyperparameter_importance_panel.gif)

파라미터 관리자를 사용하여 보이는 파라미터와 숨겨진 파라미터를 수동으로 설정할 수 있습니다.

![보이는 필드와 숨겨진 필드를 수동으로 설정하기](/images/app_ui/hyperparameter_importance_panel_manual.gif)

## 하이퍼파라미터 중요도 패널 해석하기

![](https://paper-attachments.dropbox.com/s\_B78AACEDFC4B6CE0BF245AA5C54750B01173E5A39173E03BE6F3ACF776A01267\_1578798509642\_image.png)

이 패널은 학습 스크립트의 [wandb.config](https://docs.wandb.com/library/python/config) 객체에 전달된 모든 파라미터를 보여줍니다. 다음으로, 이러한 구성 파라미터의 특성 중요도와 선택한 모델 메트릭(`val_loss`인 경우)과의 상관관계를 보여줍니다.

### 중요도

중요도 열은 각 하이퍼파라미터가 선택한 메트릭을 예측하는 데 얼마나 유용했는지를 보여줍니다. 우리는 다양한 하이퍼파라미터를 조정하면서 시작하고, 이 플롯을 사용하여 더 많은 탐색을 할 가치가 있는 하이퍼파라미터를 찾아내는 시나리오를 상상할 수 있습니다. 그런 다음 진행하는 스윕은 가장 중요한 하이퍼파라미터에 국한될 수 있으므로, 더 나은 모델을 더 빠르고 저렴하게 찾을 수 있습니다.

참고: 우리는 이 중요도를 선형 모델이 아닌 트리 기반 모델을 사용하여 계산합니다. 왜냐하면 후자는 범주형 데이터와 정규화되지 않은 데이터를 더 잘 처리하기 때문입니다.\
위의 패널에서 볼 수 있듯이, `에포크, 학습률, 배치 크기` 및 `가중치 감소`가 상당히 중요했습니다.

다음 단계로, 우리는 이 하이퍼파라미터의 더 세밀한 값을 탐색하는 또 다른 스윕을 실행할 수 있습니다. 흥미롭게도, `학습률`과 `배치 크기`는 중요했지만, 출력과 잘 상관되지 않았습니다.\
이것은 상관관계로 이어집니다.

### 상관관계

상관관계는 개별 하이퍼파라미터와 메트릭 값 사이의 선형 관계를 포착합니다. 그들은 이 질문에 답합니다 - 하이퍼파라미터를 사용하고, 예를 들어 SGD 옵티마이저를 사용하는 것과 내 val\_loss 사이에 유의미한 관계가 있습니까? (이 경우의 대답은 예입니다). 상관관계 값은 -1에서 1까지의 범위를 가지며, 양의 값은 양의 선형 상관관계를 나타내고, 음의 값은 음의 선형 상관관계를 나타내며, 0의 값은 상관관계가 없음을 나타냅니다. 일반적으로 어느 방향으로든 0.7보다 큰 값은 강한 상관관계를 나타냅니다.

우리는 이 그래프를 사용하여 메트릭과 더 높은 상관관계를 가진 값을 더 탐색하거나 더 많은 에포크 동안 학습할 수 있습니다.

상관관계를 해석하는 데 대한 간단한 메모:

* 상관관계는 연관성의 증거를 보여주지만, 반드시 인과관계를 의미하지는 않습니다.
* 상관관계는 이상치에 민감하며, 특히 시도된 하이퍼파라미터의 샘플 크기가 작은 경우 강한 관계를 중간 관계로 바꿀 수 있습니다.
* 마지막으로, 상관관계는 하이퍼파라미터와 메트릭 사이의 선형 관계만을 포착합니다. 강한 다항식 관계가 있다면, 상관관계에 의해 포착되지 않을 것입니다.

중요도와 상관관계 사이의 차이점은 중요도가 하이퍼파라미터 간의 상호작용을 고려한다는 사실에서 비롯됩니다. 반면 상관관계는 단일 하이퍼파라미터의 메트릭 값에 대한 영향만을 측정합니다. 둘째로, 상관관계는 단지 선형 관계만을 포착하는 반면, 중요도는 더 복잡한 것들을 포착할 수 있습니다.

보시다시피 중요도와 상관관계는 모두 하이퍼파라미터가 모델 성능에 미치는 영향을 이해하는 데 강력한 도구입니다.

이 패널이 이러한 통찰력을 포착하고 더 강력한 모델을 더 빨리 확보하는 데 도움이 되기를 바랍니다.