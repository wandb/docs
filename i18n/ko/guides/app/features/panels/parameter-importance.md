---
description: Visualize the relationships between your model's hyperparameters and
  output metrics
displayed_sidebar: default
---

# 파라미터 중요도

이 패널은 메트릭의 바람직한 값과 높은 상관관계를 가지거나, 최고의 예측 변수인 하이퍼파라미터가 무엇인지 보여줍니다.

![](https://paper-attachments.dropbox.com/s\_B78AACEDFC4B6CE0BF245AA5C54750B01173E5A39173E03BE6F3ACF776A01267\_1578795733856\_image.png)

**상관관계**는 선택된 메트릭(이 경우 val_loss)과 하이퍼파라미터 사이의 선형 상관관계를 말합니다. 따라서 높은 상관관계는 하이퍼파라미터의 값이 높을 때 메트릭의 값도 높고 그 반대의 경우도 마찬가지임을 의미합니다. 상관관계는 중요한 지표이지만, 입력 간의 2차 상호작용을 포착할 수 없으며, 범위가 크게 다른 입력을 비교할 때 복잡해질 수 있습니다.

그러므로 우리는 또한 **중요도** 지표를 계산합니다. 여기서는 하이퍼파라미터를 입력으로, 메트릭을 목표 출력으로 사용하여 랜덤 포레스트를 훈련시키고 랜덤 포레스트의 특성 중요도 값을 보고합니다.

이 기술에 대한 아이디어는 [Fast.ai](http://fast.ai)에서 하이퍼파라미터 공간을 탐색하기 위해 랜덤 포레스트 특성 중요도를 사용하는 선구자인 [Jeremy Howard](https://twitter.com/jeremyphoward)와의 대화에서 영감을 받았습니다. 우리는 이 분석의 동기에 대해 자세히 알아보기 위해 그의 뛰어난 [레슨](http://course18.fast.ai/lessonsml1/lesson4.html) (그리고 이 [노트](https://forums.fast.ai/t/wiki-lesson-thread-lesson-4/7540))를 확인할 것을 강력히 추천합니다.

이 하이퍼파라미터 중요도 패널은 상호 연관성이 높은 하이퍼파라미터 간의 복잡한 상호작용을 풀어줍니다. 이를 통해 모델 성능을 예측하는 데 가장 중요한 하이퍼파라미터가 무엇인지 보여주면서 하이퍼파라미터 검색을 미세 조정할 수 있도록 도와줍니다.

## 하이퍼파라미터 중요도 패널 만들기

당신의 W&B 프로젝트로 이동하세요. 프로젝트가 없다면, [이 프로젝트](https://app.wandb.ai/sweep/simpsons)를 사용할 수 있습니다.

프로젝트 페이지에서 **시각화 추가**를 클릭하세요.

![](https://paper-attachments.dropbox.com/s\_B78AACEDFC4B6CE0BF245AA5C54750B01173E5A39173E03BE6F3ACF776A01267\_1578795570241\_image.png)

그런 다음 **파라미터 중요도**를 선택하세요.

프로젝트에 [W&B 통합](https://docs.wandb.com/quickstart) 외에 새로운 코드를 작성할 필요는 없습니다.

![](https://paper-attachments.dropbox.com/s\_B78AACEDFC4B6CE0BF245AA5C54750B01173E5A39173E03BE6F3ACF776A01267\_1578795636072\_image.png)

:::info
패널이 비어 보인다면, run이 그룹화되지 않았는지 확인하세요
:::

## 하이퍼파라미터 중요도 패널 사용하기

매개변수 관리자 옆에 있는 마법사 지팡이를 클릭하여 유용한 하이퍼파라미터 세트를 wandb가 시각화하도록 할 수 있습니다. 그런 다음 중요도를 기준으로 하이퍼파라미터를 정렬할 수 있습니다.

![자동 파라미터 시각화 사용](/images/app_ui/hyperparameter_importance_panel.gif)

파라미터 관리자를 사용하여 보이는 파라미터와 숨겨진 파라미터를 수동으로 설정할 수 있습니다.

![보이는 필드와 숨겨진 필드 수동 설정](/images/app_ui/hyperparameter_importance_panel_manual.gif)

## 하이퍼파라미터 중요도 패널 해석하기

![](https://paper-attachments.dropbox.com/s\_B78AACEDFC4B6CE0BF245AA5C54750B01173E5A39173E03BE6F3ACF776A01267\_1578798509642\_image.png)

이 패널은 교육 스크립트의 [wandb.config](https://docs.wandb.com/library/python/config) 오브젝트에 전달된 모든 파라미터를 보여줍니다. 다음으로, 이 config 파라미터들의 특성 중요도와 선택한 모델 메트릭(`val_loss`가 이 경우에 해당)과의 상관관계를 보여줍니다.

### 중요도

중요도 열은 각 하이퍼파라미터가 선택한 메트릭을 예측하는 데 얼마나 유용했는지를 보여줍니다. 우리는 다양한 하이퍼파라미터를 튜닝하며 시작하고, 이 그래프를 사용하여 추가 탐색을 위한 가치가 있는 하이퍼파라미터를 선별하는 시나리오를 상상할 수 있습니다. 그 후의 스윕은 가장 중요한 하이퍼파라미터로 제한될 수 있으므로, 더 나은 모델을 더 빠르고 저렴하게 찾을 수 있습니다.

참고: 우리는 선형 모델이 아닌 트리 기반 모델을 사용하여 이 중요도를 계산합니다. 후자는 범주형 데이터와 정규화되지 않은 데이터에 대해 더 관용적입니다.\
위의 패널에서 볼 수 있듯이 `에포크, learning_rate, batch_size` 및 `weight_decay`는 상당히 중요했습니다.

다음 단계로, 우리는 이 하이퍼파라미터의 더 세분화된 값을 탐색하는 또 다른 스윕을 실행할 수 있습니다. 흥미롭게도, `learning_rate`와 `batch_size`는 중요했지만, 출력과 잘 상관되지 않았습니다.\
이것은 우리를 상관관계로 이끕니다.

### 상관관계

상관관계는 개별 하이퍼파라미터와 메트릭 값 간의 선형 관계를 포착합니다. 그들은 이 질문에 답합니다 - 하이퍼파라미터를 사용하는 것과 나의 val_loss 사이에 유의미한 관계가 있는가(이 경우의 답은 예입니다). 상관관계 값은 -1에서 1까지의 범위를 가지며, 양의 값은 양의 선형 상관관계를, 음의 값은 음의 선형 상관관계를, 0의 값은 상관관계가 없음을 나타냅니다. 일반적으로 어느 방향으로든 0.7보다 큰 값은 강한 상관관계를 나타냅니다.

우리는 이 그래프를 사용하여 우리의 메트릭(이 경우에는 rmsprop이나 nadam보다는 확률적 그레이디언트 하강법이나 adam을 선택할 수 있음)에 더 높은 상관관계를 가지는 값을 추가로 탐색하거나 더 많은 에포크 동안 훈련할 수 있습니다.

상관관계를 해석하는 데 대한 빠른 참고:

* 상관관계는 연관성의 증거를 보여주지만 반드시 인과관계를 의미하지는 않습니다.
* 상관관계는 이상치에 민감하여, 특히 시도된 하이퍼파라미터의 샘플 크기가 작을 경우 강한 관계를 중간 정도의 관계로 바꿀 수 있습니다.
* 마지막으로, 상관관계는 하이퍼파라미터와 메트릭 간의 선형 관계만을 포착합니다. 강한 다항식 관계가 있다면, 상관관계에 의해 포착되지 않을 것입니다.

중요도와 상관관계 사이의 차이는 중요도가 하이퍼파라미터 간의 상호작용을 고려한다는 사실에서 비롯되며, 상관관계는 개별 하이퍼파라미터가 메트릭 값에 미치는 영향만을 측정합니다. 둘째, 상관관계는 선형 관계만을 포착하는 반면, 중요도는 더 복잡한 관계를 포착할 수 있습니다.

보시다시피, 중요도와 상관관계 모두 모델 성능에 하이퍼파라미터가 어떻게 영향을 미치는지 이해하는 데 강력한 도구입니다.

이 패널이 이러한 통찰을 포착하고 더 강력한 모델을 더 빠르게 확보하는 데 도움이 되기를 바랍니다.