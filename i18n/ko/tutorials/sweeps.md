
# ν•μ΄νΌνλΌλ―Έν„° νλ‹ν•κΈ°

[**Colab λ…ΈνΈλ¶μ—μ„ μ‹λ„ν•΄λ³΄κΈ° β†’**](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W&B.ipynb)

λ†’μ€ μ°¨μ›μ ν•μ΄νΌνλΌλ―Έν„° κ³µκ°„μ„ νƒμƒ‰ν•μ—¬ κ°€μ¥ μ„±λ¥μ΄ μΆ‹μ€ λ¨λΈμ„ μ°Ύλ” κ²ƒμ€ λ§¤μ° λ³µμ΅ν•΄μ§ μ μμµλ‹λ‹¤. ν•μ΄νΌνλΌλ―Έν„° μ¤μ•μ€ λ¨λΈλ“¤μ λ€κ²°μ—μ„ κ°€μ¥ μ •ν™•ν• λ¨λΈμ„ μ„ νƒν•  μ μλ” μ΅°μ§μ μ΄κ³  ν¨μ¨μ μΈ λ°©λ²•μ„ μ κ³µν•©λ‹λ‹¤. μ΄λ” ν•μ΄νΌνλΌλ―Έν„° κ°’(μ: ν•™μµλ¥ , λ°°μΉ ν¬κΈ°, μ€λ‹‰μΈµμ μ, μµν‹°λ§μ΄μ € μ ν•)μ μ΅°ν•©μ„ μλ™μΌλ΅ νƒμƒ‰ν•μ—¬ κ°€μ¥ μµμ μ κ°’μ„ μ°ΎμμΌλ΅μ¨ κ°€λ¥ν•©λ‹λ‹¤.

μ΄ νν† λ¦¬μ–Όμ—μ„λ” Weights & Biasesλ¥Ό μ‚¬μ©ν•μ—¬ 3λ‹¨κ³„λ§μΌλ΅ κ³ κΈ‰ ν•μ΄νΌνλΌλ―Έν„° μ¤μ•μ„ μ‹¤ν–‰ν•λ” λ°©λ²•μ„ μ‚΄ν΄λ³΄κ² μµλ‹λ‹¤.

### [λΉ„λ””μ¤ νν† λ¦¬μ–Ό](http://wandb.me/sweeps-video)μ„ λ”°λΌν•΄ λ³΄μ„Έμ”!

![](https://i.imgur.com/WVKkMWw.png)

# π€ μ„¤μ •

μ‹¤ν— μ¶”μ  λΌμ΄λΈλ¬λ¦¬λ¥Ό μ„¤μΉν•κ³  λ¬΄λ£ W&B κ³„μ •μ„ μ„¤μ •ν•μ—¬ μ‹μ‘ν•μ„Έμ”:

1. `!pip install`λ΅ μ„¤μΉ
2. Pythonμ— λΌμ΄λΈλ¬λ¦¬λ¥Ό `import`
3. ν”„λ΅μ νΈμ— λ©”νΈλ¦­μ„ λ΅κ·Έν•  μ μλ„λ΅ `.login()`

Weights & Biasesλ¥Ό μ²μ μ‚¬μ©ν•λ” κ²½μ°,
`login` νΈμ¶μ€ κ³„μ •μ— κ°€μ…ν•  μ μλ” λ§ν¬λ¥Ό μ κ³µν•©λ‹λ‹¤.
W&Bλ” κ°μΈ λ° ν•™μ  ν”„λ΅μ νΈμ— λ¬΄λ£λ΅ μ‚¬μ©ν•  μ μμµλ‹λ‹¤!


```python
!pip install wandb -Uq
```


```python
import wandb

wandb.login()
```

# 1οΈβƒ£ λ‹¨κ³„. μ¤μ• μ •μν•κΈ°

κΈ°λ³Έμ μΌλ΅, μ¤μ•μ€ λ§μ€ ν•μ΄νΌνλΌλ―Έν„° κ°’λ“¤μ„ μ‹λ„ν•΄λ³΄λ” μ „λµκ³Ό μ΄λ¥Ό ν‰κ°€ν•λ” μ½”λ“λ¥Ό κ²°ν•©ν•©λ‹λ‹¤.
[μ„¤μ •](https://docs.wandb.com/sweeps/configuration)μ ν•νƒλ΅ _μ „λµμ„ μ •μ_ν•κΈ°λ§ ν•λ©΄ λ©λ‹λ‹¤.

λ…ΈνΈλ¶μ—μ„ μ¤μ•μ„ μ„¤μ •ν•  λ•λ”
config μ¤λΈμ νΈκ°€ μ¤‘μ²©λ μ‚¬μ „μ…λ‹λ‹¤.
μ»¤λ§¨λ“λΌμΈμ„ ν†µν•΄ μ¤μ•μ„ μ‹¤ν–‰ν•  λ•λ”
config μ¤λΈμ νΈκ°€
[YAML νμΌ](https://docs.wandb.ai/guides/sweeps/define-sweep-configuration)μ…λ‹λ‹¤.

ν•¨κ» μ¤μ• configλ¥Ό μ •μν•΄ λ΄…μ‹λ‹¤.
μ²μ²ν μ§„ν–‰ν•΄μ„ κ° κµ¬μ„± μ”μ†λ¥Ό μ„¤λ…ν•  κΈ°νλ¥Ό κ°–κ² μµλ‹λ‹¤.
μΌλ°μ μΈ μ¤μ• νμ΄ν”„λΌμΈμ—μ„λ”
μ΄ λ‹¨κ³„κ°€ λ‹¨μΌ ν• λ‹Ήμ—μ„ μ΄λ£¨μ–΄μ§‘λ‹λ‹¤.

### π‘ `method` μ„ νƒν•κΈ°

μƒλ΅μ΄ νλΌλ―Έν„° κ°’μ„ μ„ νƒν•λ” `method`κ°€ μ²« λ²μ§Έλ΅ μ •μν•΄μ•Ό ν•  κ²ƒμ…λ‹λ‹¤.

λ‹¤μκ³Ό κ°™μ€ κ²€μƒ‰ `methods`λ¥Ό μ κ³µν•©λ‹λ‹¤:
*   **`grid` κ²€μƒ‰** β€“ ν•μ΄νΌνλΌλ―Έν„° κ°’μ λ¨λ“  μ΅°ν•©μ„ λ°λ³µν•©λ‹λ‹¤.
λ§¤μ° ν¨κ³Όμ μ΄μ§€λ§ κ³„μ‚° λΉ„μ©μ΄ λ§μ΄ λ“¤ μ μμµλ‹λ‹¤.
*   **`random` κ²€μƒ‰** β€“ μ κ³µλ `distribution`λ“¤μ— λ”°λΌ κ° μƒλ΅μ΄ μ΅°ν•©μ„ λ¬΄μ‘μ„λ΅ μ„ νƒν•©λ‹λ‹¤. μμ™Έλ΅ ν¨κ³Όμ μ…λ‹λ‹¤!
*   **`bayes`ian κ²€μƒ‰** β€“ λ©”νΈλ¦­ μ μλ¥Ό ν•μ΄νΌνλΌλ―Έν„°μ ν•¨μλ΅ ν•λ” ν™•λ¥  λ¨λΈμ„ λ§λ“¤κ³ , λ©”νΈλ¦­μ„ κ°μ„ ν•  κ°€λ¥μ„±μ΄ λ†’μ€ νλΌλ―Έν„°λ¥Ό μ„ νƒν•©λ‹λ‹¤. μ—°μ†μ μΈ νλΌλ―Έν„°μ μ†μμ— λ€ν•΄ μ μ‘λ™ν•μ§€λ§ κ·λ¨κ°€ μ»¤μ§€λ©΄ μ ν™•μ¥λμ§€ μ•μµλ‹λ‹¤.

μ°λ¦¬λ” `random`μ„ μ‚¬μ©ν•  κ²ƒμ…λ‹λ‹¤.


```python
sweep_config = {
    'method': 'random'
    }
```

`bayes`ian μ¤μ•μ κ²½μ°,
λ©”νΈλ¦­μ— λ€ν•΄ μ•½κ°„μ μ •λ³΄λ¥Ό λ” μ•λ ¤μ£Όμ–΄μ•Ό ν•©λ‹λ‹¤.
λ¨λΈ μ¶λ ¥μ—μ„ μ°Ύμ„ μ μλ„λ΅ λ©”νΈλ¦­μ `name`μ„ μ•μ•„μ•Ό ν•κ³ 
`goal`μ΄ λ©”νΈλ¦­μ„ `minimize`ν•λ” κ²ƒμΈμ§€
(μ: μ κ³± μ¤μ°¨μΈ κ²½μ°)
μ•„λ‹λ©΄ `maximize`ν•λ” κ²ƒμΈμ§€
(μ: μ •ν™•λ„μΈ κ²½μ°) μ•μ•„μ•Ό ν•©λ‹λ‹¤.


```python
metric = {
    'name': 'loss',
    'goal': 'minimize'   
    }

sweep_config['metric'] = metric
```

`bayes`ian μ¤μ•μ„ μ‹¤ν–‰ν•μ§€ μ•λ” κ²½μ°μ—λ„,
λ‚μ¤‘μ— λ§μμ΄ λ°”λ€μ—μ„ λ•λ¥Ό λ€λΉ„ν•΄ `sweep_config`μ— μ΄λ¥Ό ν¬ν•¨ν•λ” κ²ƒμ΄ λ‚μμ§€ μ•μµλ‹λ‹¤.
λν• 6κ°μ›” λλ” 6λ…„ ν›„μ— λ‹Ήμ‹ μ΄λ‚ λ‹¤λ¥Έ μ‚¬λμ΄
λ‹Ήμ‹ μ μ¤μ•μΌλ΅ λμ•„μ™”μ„ λ• `val_G_batch`κ°€ λ†’μ•„μ•Ό ν•λ”μ§€ λ‚®μ•„μ•Ό ν•λ”μ§€ λ¨λ¥΄λ” κ²½μ°μ™€ κ°™μ΄,
μ¬ν„μ„±μ„ μ„ν• μΆ‹μ€ κ΄€ν–‰μ…λ‹λ‹¤.

### π“ƒ ν•μ΄νΌ`parameters` μ΄λ¦„ μ§€μ •ν•κΈ°

μƒλ΅μ΄ ν•μ΄νΌνλΌλ―Έν„° κ°’μ μƒλ΅μ΄ `method`λ¥Ό μ„ νƒν•λ©΄,
κ·Έ `parameters`κ°€ λ¬΄μ—‡μΈμ§€ μ •μν•΄μ•Ό ν•©λ‹λ‹¤.

λ€λ¶€λ¶„μ κ²½μ° μ΄ λ‹¨κ³„λ” κ°„λ‹¨ν•©λ‹λ‹¤:
`parameter`μ— μ΄λ¦„μ„ μ§€μ •ν•κ³ 
νλΌλ―Έν„°μ ν•©λ²•μ μΈ `values` λ©λ΅μ„ μ§€μ •ν•κΈ°λ§ ν•λ©΄ λ©λ‹λ‹¤.

μλ¥Ό λ“¤μ–΄, λ„¤νΈμ›ν¬μ `optimizer`λ¥Ό μ„ νƒν•  λ•,
μµμ…μ΄ μ ν•ν• μμ…λ‹λ‹¤.
μ—¬κΈ°μ„λ” κ°€μ¥ μΈκΈ° μλ” λ‘ κ°€μ§€ μ„ νƒμΈ `adam`κ³Ό `sgd`λ¥Ό μ‚¬μ©ν•©λ‹λ‹¤.
ν•μ΄νΌνλΌλ―Έν„°κ°€ λ¬΄ν•ν• μµμ…μ„ κ°€μ§ μ μλ”λΌλ„,
μ—¬κΈ°μ„μ™€ κ°™μ΄ μ€λ‹‰ `layer_size`μ™€ `dropout`μ— λ€ν•΄
λ‡ κ°€μ§€ μ„ νƒλ `values`λ§ μ‹λ„ν•λ” κ²ƒμ΄ μΌλ°μ μΌλ΅ μλ―Έκ°€ μμµλ‹λ‹¤.


```python
parameters_dict = {
    'optimizer': {
        'values': ['adam', 'sgd']
        },
    'fc_layer_size': {
        'values': [128, 256, 512]
        },
    'dropout': {
          'values': [0.3, 0.4, 0.5]
        },
    }

sweep_config['parameters'] = parameters_dict
```

μ΄ μ¤μ•μ—μ„λ” λ³€ν™”μ‹ν‚¤κ³  μ‹¶μ§€ μ•μ§€λ§,
μ—¬μ „ν `sweep_config`μ—μ„ μ„¤μ •ν•κ³  μ‹¶μ€ ν•μ΄νΌνλΌλ―Έν„°κ°€ μΆ…μΆ… μμµλ‹λ‹¤.

μ΄ κ²½μ°, `value`λ¥Ό μ§μ ‘ μ„¤μ •ν•©λ‹λ‹¤:


```python
parameters_dict.update({
    'epochs': {
        'value': 1}
    })
```

`grid` κ²€μƒ‰μ κ²½μ°, μ΄κ²ƒμ΄ μ „λ¶€μ…λ‹λ‹¤.

`random` κ²€μƒ‰μ κ²½μ°,
μ£Όμ–΄μ§„ μ‹¤ν–‰μ—μ„ νλΌλ―Έν„°μ λ¨λ“  `values`κ°€ μ„ νƒλ  ν™•λ¥ μ΄ λ™μΌν•©λ‹λ‹¤.

μ΄κ²ƒμΌλ΅ μ¶©λ¶„ν•μ§€ μ•λ‹¤λ©΄,
λ€μ‹  λ…λ…λ `distribution`κ³Ό
ν‰κ·  `mu`μ™€ ν‘μ¤€ νΈμ°¨ `sigma`μ™€ κ°™μ€ λ§¤κ°λ³€μλ¥Ό μ§€μ •ν•  μ μμµλ‹λ‹¤.

λ¬΄μ‘μ„ λ³€μμ λ¶„ν¬λ¥Ό μ„¤μ •ν•λ” λ°©λ²•μ— λ€ν• μμ„Έν• λ‚΄μ©μ€ [μ—¬κΈ°](https://docs.wandb.com/sweeps/configuration#distributions)μ—μ„ ν™•μΈν•  μ μμµλ‹λ‹¤.


```python
parameters_dict.update({
    'learning_rate': {
        # 0κ³Ό 0.1 μ‚¬μ΄μ κ· μΌ λ¶„ν¬
        'distribution': 'uniform',
        'min': 0,
        'max': 0.1
      },
    'batch_size': {
        # 32μ™€ 256 μ‚¬μ΄μ μ •μ
        # λ΅κ·Έκ°€ κ· λ“±ν•κ² λ¶„ν¬λ¨
        'distribution': 'q_log_uniform_values',
        'q': 8,
        'min': 32,
        'max': 256,
      }
    })
```

μ™„λ£λλ©΄, `sweep_config`μ€ μ •ν™•ν μ–΄λ–¤ `parameters`μ— κ΄€μ‹¬μ΄ μλ”μ§€
κ·Έλ¦¬κ³  κ·Έκ²ƒλ“¤μ„ μ‹λ„ν•κΈ° μ„ν•΄ μ–΄λ–¤ `method`λ¥Ό μ‚¬μ©ν•  κ²ƒμΈμ§€λ¥Ό
λ…μ‹ν•λ” μ¤‘μ²©λ μ‚¬μ „μ…λ‹λ‹¤.


```python
import pprint

pprint.pprint(sweep_config)
```

ν•μ§€λ§ μ΄κ²ƒμ΄ λ¨λ“  μ„¤μ • μµμ…μ€ μ•„λ‹™λ‹λ‹¤!

μλ¥Ό λ“¤μ–΄, [HyperBand](https://arxiv.org/pdf/1603.06560.pdf) μ¤μΌ€μ¤„λ§ μ•κ³ λ¦¬μ¦μ„ μ‚¬μ©ν•μ—¬ μ‹¤ν–‰μ„ `early_terminate`ν•λ” μµμ…λ„ μ κ³µν•©λ‹λ‹¤. μμ„Έν• λ‚΄μ©μ€ [μ—¬κΈ°](https://docs.wandb.com/sweeps/configuration#stopping-criteria)μ—μ„ ν™•μΈν•μ„Έμ”.

λ¨λ“  κµ¬μ„± μµμ… λ©λ΅μ€ [μ—¬κΈ°](https://docs.wandb.com/library/sweeps/configuration)μ—μ„ μ°Ύμ„ μ μμΌλ©°,
YAML ν•μ‹μ ν° μμ  λ¨μμ€ [μ—¬κΈ°](https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion)μ—μ„ ν™•μΈν•  μ μμµλ‹λ‹¤.

# 2οΈβƒ£ λ‹¨κ³„. μ¤μ• μ΄κΈ°ν™”ν•κΈ°

κ²€μƒ‰ μ „λµμ„ μ •μν• ν›„μ—λ” μ΄λ¥Ό κµ¬ν„ν•  λ¬΄μ–Έκ°€λ¥Ό μ„¤μ •ν•  μ‹κ°„μ…λ‹λ‹¤.

μ°λ¦¬μ μ¤μ•μ„ λ‹΄λ‹Ήν•λ” μ‹κ³„μ‘μ—…μ¥μ΄μλ” _μ¤μ• μ»¨νΈλ΅¤λ¬_λ΅ μ•λ ¤μ Έ μμµλ‹λ‹¤.
κ° μ‹¤ν–‰μ΄ μ™„λ£λ  λ•λ§λ‹¤, μ‹¤ν–‰ν•  μƒλ΅μ΄ μ‹¤ν–‰μ„ μ„¤λ…ν•λ” μƒλ΅μ΄ μΌλ ¨μ μ§€μΉ¨μ„ λ°ν–‰ν•©λ‹λ‹¤.
μ΄ μ§€μΉ¨μ€ μ‹¤ν–‰μ„ μ‹¤μ λ΅ μν–‰ν•λ” _μ—μ΄μ „νΈ_κ°€ μμ§‘ν•©λ‹λ‹¤.

μΌλ°μ μΈ μ¤μ•μ—μ„λ” μ»¨νΈλ΅¤λ¬κ°€ _μ°λ¦¬μ_ κΈ°κ³„μ— μ΅΄μ¬ν•κ³ ,
μ‹¤ν–‰μ„ μ™„λ£ν•λ” μ—μ΄μ „νΈκ°€ _λ‹Ήμ‹ μ_ κΈ°κ³„(λ“¤)μ— μ΅΄μ¬ν•©λ‹λ‹¤.
μ΄ μ‘μ—… λ¶„λ‹΄μ€ μ—μ΄μ „νΈλ¥Ό μ‹¤ν–‰ν•κΈ° μ„ν•΄ λ” λ§μ€ κΈ°κ³„λ¥Ό μ¶”κ°€ν•κΈ°λ§ ν•λ©΄ μ¤μ•μ„ μ‰½κ² ν™•μ¥ν•  μ μκ² ν•©λ‹λ‹¤!

μ•„λμ λ‹¤μ΄μ–΄κ·Έλ¨μ²λΌ.
<img src="https://i.imgur.com/zlbw3vQ.png" alt="sweeps-diagram" width="500"/>

μ μ ν• `sweep_config`μ™€ `ν”„λ΅μ νΈ` μ΄λ¦„μΌλ΅ `wandb.sweep`μ„ νΈμ¶ν•μ—¬ μ¤μ• μ»¨νΈλ΅¤λ¬λ¥Ό μ‘λ™μ‹ν‚¬ μ μμµλ‹λ‹¤.

μ΄ ν•¨μλ” λ‚μ¤‘μ— μ΄ μ»¨νΈλ΅¤λ¬μ— μ—μ΄μ „νΈλ¥Ό ν• λ‹Ήν•κΈ° μ„ν•΄ μ‚¬μ©ν•  `sweep_id`λ¥Ό λ°ν™ν•©λ‹λ‹¤.

> _μ‚¬μ΄λ“ λ…ΈνΈ_: μ»¤λ§¨λ“λΌμΈμ—μ„, μ΄ ν•¨μλ” λ‹¤μκ³Ό κ°™μ΄ λ€μ²΄λ©λ‹λ‹¤.
```python
wandb sweep config.yaml
```
[μ»¤λ§¨λ“λΌμΈμ—μ„ μ¤μ• μ‚¬μ©μ— λ€ν•΄ λ” μ•μ•„λ³΄κΈ° β΅](https://docs.wandb.ai/guides/sweeps/walkthrough)


```python
sweep_id = wandb.sweep(sweep_config, project="pytorch-sweeps-demo")
```

# 3οΈβƒ£ λ‹¨κ³„. μ¤μ• μ—μ΄μ „νΈ μ‹¤ν–‰ν•κΈ°

### π’» νΈλ μ΄λ‹ μ μ°¨ μ •μν•κΈ°

μ¤μ•μ„ μ‹¤μ λ΅ μ‹¤ν–‰ν•κΈ° μ „μ—,
κ·Έ κ°’μ„ μ‚¬μ©ν•λ” νΈλ μ΄λ‹ μ μ°¨λ¥Ό μ •μν•΄μ•Ό ν•©λ‹λ‹¤.

μ•„λ ν•¨μμ—μ„λ” PyTorchμ—μ„ κ°„λ‹¨ν• μ™„μ „ μ—°κ²° μ‹ κ²½λ§μ„ μ •μν•κ³  λ‹¤μ `wandb` λ„κµ¬λ¥Ό μ¶”κ°€ν•μ—¬ λ¨λΈ λ©”νΈλ¦­μ„ λ΅κ·Έν•κ³ , μ„±λ¥κ³Ό μ¶λ ¥μ„ μ‹κ°ν™”ν•λ©°, μ‹¤ν—μ„ μ¶”μ ν•©λ‹λ‹¤:
* [**`wandb.init()`**](https://docs.wandb.com/library/init) β€“ μƒλ΅μ΄ W&B μ‹¤ν–‰μ„ μ΄κΈ°ν™”ν•©λ‹λ‹¤. κ° μ‹¤ν–‰μ€ νΈλ μ΄λ‹ ν•¨μμ λ‹¨μΌ μ‹¤ν–‰μ…λ‹λ‹¤.
* [**`wandb.config`**](https://docs.wandb.com/library/config) β€“ λ¨λ“  ν•μ΄νΌνλΌλ―Έν„°λ¥Ό κµ¬μ„± μ¤λΈμ νΈμ— μ €μ¥ν•μ—¬ λ΅κ·Έν•©λ‹λ‹¤. `wandb.config` μ‚¬μ© λ°©λ²•μ— λ€ν•΄ μμ„Έν μ•μ•„λ³΄λ ¤λ©΄ [μ—¬κΈ°](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Configs_in_W%26B.ipynb)λ¥Ό μ°Έμ΅°ν•μ„Έμ”.
* [**`wandb.log()`**](https://docs.wandb.com/library/log) β€“ W&Bμ— λ¨λΈ λ™μ‘μ„ λ΅κ·Έν•©λ‹λ‹¤. μ—¬κΈ°μ„λ” μ„±λ¥λ§ λ΅κ·Έν•©λ‹λ‹¤; `wandb.log`λ΅ λ΅κ·Έν•  μ μλ” λ‹¤λ¥Έ λ¨λ“  λ¦¬μΉ λ―Έλ””μ–΄λ” [μ΄ Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Log_(Almost)_Anything_with_W%26B_Media.ipynb)μ—μ„ ν™•μΈν•μ„Έμ”.

PyTorchμ™€ W&Bλ¥Ό ν•¨κ» μ‚¬μ©ν•λ” λ” μμ„Έν• λ‚΄μ©μ€ [μ΄ Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Simple_PyTorch_Integration.ipynb)μ„ μ°Έμ΅°ν•μ„Έμ”.


```python
import torch
import torch.optim as optim
import torch.nn.functional as F
import torch.nn as nn
from torchvision import datasets, transforms

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def train(config=None):
    # μƒλ΅μ΄ wandb μ‹¤ν–‰μ„ μ΄κΈ°ν™”ν•©λ‹λ‹¤.
    with wandb.init(config=config):
        # wandb.agent μ•„λμ—μ„ νΈμ¶λ κ²½μ°,
        # μ΄ configλ” μ¤μ• μ»¨νΈλ΅¤λ¬μ— μν•΄ μ„¤μ •λ©λ‹λ‹¤.
        config = wandb.config

        loader = build_dataset(config.batch_size)
        network = build_network(config.fc_layer_size, config.dropout)
        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)

        for epoch in range(config.epochs):
            avg_loss = train_epoch(network, loader, optimizer)
            wandb.log({"loss": avg_loss, "epoch": epoch})           
```

μ΄ μ…€μ€ μ°λ¦¬μ νΈλ μ΄λ‹ μ μ°¨μ λ„¤ λ¶€λ¶„μ„ μ •μν•©λ‹λ‹¤:
`build_dataset`, `build_network`, `build_optimizer`, `train_epoch`.

μ΄ λ¨λ“  κ²ƒμ€ κΈ°λ³Έ PyTorch νμ΄ν”„λΌμΈμ ν‘μ¤€ λ¶€λ¶„μ΄λ©°,
W&B μ‚¬μ©μ— μν–¥μ„ λ°›μ§€ μ•μΌλ―€λ΅
μ΄μ— λ€ν•΄ λ…Όν‰ν•μ§€ μ•κ² μµλ‹λ‹¤.


```python
def build_dataset(batch_size):
   
    transform = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.1307,), (0.3081,))])
    # MNIST νΈλ μ΄λ‹ λ°μ΄ν„°μ…‹ λ‹¤μ΄λ΅λ“
    dataset = datasets.MNIST(".", train=True, download=True,
                             transform=transform)
    sub_dataset = torch.utils.data.Subset(
        dataset, indices=range(0, len(dataset), 5))
    loader = torch.utils.data.DataLoader(sub_dataset, batch_size=batch_size)

    return loader


def build_network(fc_layer_size, dropout):
    network = nn.Sequential(  # μ™„μ „ μ—°κ²°, λ‹¨μΌ μ€λ‹‰μΈµ
        nn.Flatten(),
        nn.Linear(784, fc_layer_size), nn.ReLU(),
        nn.Dropout(dropout),
        nn.Linear(fc_layer_size, 10),
        nn.LogSoftmax(dim=1))

    return network.to(device)
        

def build_optimizer(network, optimizer, learning_rate):
    if optimizer == "sgd":
        optimizer = optim.SGD(network.parameters(),
                              lr=learning_rate, momentum=0.9)
    elif optimizer == "adam":
        optimizer = optim.Adam(network.parameters(),
                               lr=learning_rate)
    return optimizer


def train_epoch(network, loader, optimizer):
    cumu