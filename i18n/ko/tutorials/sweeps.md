
# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •

[**Colab ë…¸íŠ¸ë¶ì—ì„œ ì‹œë„í•´ë³´ê¸° â†’**](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W&B.ipynb)

ë†’ì€ ì°¨ì›ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê³µê°„ì„ ê²€ìƒ‰í•˜ì—¬ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ì„ ì°¾ëŠ” ê²ƒì€ ë§¤ìš° ë²ˆê±°ë¡œìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìŠ¤ìœ•ì€ ëª¨ë¸ë“¤ì˜ ë°°í‹€ ë¡œì–„ì„ ì¡°ì§ì ì´ê³  íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ì—¬ ê°€ì¥ ì •í™•í•œ ëª¨ë¸ì„ ì„ íƒí•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’(ì˜ˆ: í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸°, ì€ë‹‰ì¸µì˜ ìˆ˜, ì˜µí‹°ë§ˆì´ì € ìœ í˜•)ì˜ ì¡°í•©ì„ ìë™ìœ¼ë¡œ ê²€ìƒ‰í•˜ì—¬ ê°€ì¥ ìµœì ì˜ ê°’ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Weights & Biasesë¥¼ ì‚¬ìš©í•˜ì—¬ 3ë‹¨ê³„ë¡œ ê³ ê¸‰ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìŠ¤ìœ•ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

### [ë¹„ë””ì˜¤ íŠœí† ë¦¬ì–¼](http://wandb.me/sweeps-video) ë”°ë¼í•˜ê¸°!

![](https://i.imgur.com/WVKkMWw.png)

# ğŸš€ ì„¤ì •

ì‹¤í—˜ ì¶”ì  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ê³  ë¬´ë£Œ W&B ê³„ì •ì„ ì„¤ì •í•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”:

1. `!pip install`ë¡œ ì„¤ì¹˜
2. ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ Pythonì— `import`
3. í”„ë¡œì íŠ¸ì— ë©”íŠ¸ë¦­ì„ ë¡œê·¸í•  ìˆ˜ ìˆë„ë¡ `.login()`

Weights & Biasesë¥¼ ì²˜ìŒ ì‚¬ìš©í•œë‹¤ë©´,
`login` í˜¸ì¶œì€ ê³„ì •ì„ ë“±ë¡í•  ìˆ˜ ìˆëŠ” ë§í¬ë¥¼ ì œê³µí•  ê²ƒì…ë‹ˆë‹¤.
W&BëŠ” ê°œì¸ ë° í•™ìˆ  í”„ë¡œì íŠ¸ì— ë¬´ë£Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!


```python
!pip install wandb -Uq
```


```python
import wandb

wandb.login()
```

# 1ï¸âƒ£ë‹¨ê³„. ìŠ¤ìœ• ì •ì˜

ê¸°ë³¸ì ìœ¼ë¡œ, ìŠ¤ìœ•ì€ ë§ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì„ ì‹œë„í•˜ëŠ” ì „ëµê³¼ ê·¸ê²ƒì„ í‰ê°€í•˜ëŠ” ì½”ë“œë¥¼ ê²°í•©í•©ë‹ˆë‹¤.
_ì „ëµì„ ì •ì˜_í•´ì•¼ í•©ë‹ˆë‹¤.
[êµ¬ì„±](https://docs.wandb.com/sweeps/configuration)ì˜ í˜•íƒœë¡œ.

ë…¸íŠ¸ë¶ì—ì„œ ìŠ¤ìœ•ì„ ì„¤ì •í•  ë•Œ,
í•´ë‹¹ êµ¬ì„± ê°ì²´ëŠ” ì¤‘ì²©ëœ ì‚¬ì „ì…ë‹ˆë‹¤.
ì»¤ë§¨ë“œ ë¼ì¸ì„ í†µí•´ ìŠ¤ìœ•ì„ ì‹¤í–‰í•  ë•Œ,
êµ¬ì„± ê°ì²´ëŠ”
[YAML íŒŒì¼](https://docs.wandb.ai/guides/sweeps/define-sweep-configuration)ì…ë‹ˆë‹¤.

ìŠ¤ìœ• êµ¬ì„±ì„ í•¨ê»˜ ì •ì˜í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.
ì²œì²œíˆ ì§„í–‰í•˜ì—¬ ê° êµ¬ì„± ìš”ì†Œë¥¼ ì„¤ëª…í•˜ëŠ” ê¸°íšŒë¥¼ ê°–ê² ìŠµë‹ˆë‹¤.
ì¼ë°˜ì ì¸ ìŠ¤ìœ• íŒŒì´í”„ë¼ì¸ì—ì„œ,
ì´ ë‹¨ê³„ëŠ” ë‹¨ì¼ í• ë‹¹ìœ¼ë¡œ ìˆ˜í–‰ë©ë‹ˆë‹¤.

### ğŸ‘ˆ `method` ì„ íƒ

ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„° ê°’ ì„ íƒì„ ìœ„í•œ `method`ë¥¼ ì •ì˜í•˜ëŠ” ê²ƒì´ ì²« ë²ˆì§¸ ë‹¨ê³„ì…ë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì€ ê²€ìƒ‰ `methods`ë¥¼ ì œê³µí•©ë‹ˆë‹¤:
*   **`grid` ê²€ìƒ‰** - í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì˜ ëª¨ë“  ì¡°í•©ì„ ë°˜ë³µí•©ë‹ˆë‹¤.
ë§¤ìš° íš¨ê³¼ì ì´ì§€ë§Œ, ê³„ì‚° ë¹„ìš©ì´ ë§ì´ ë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
*   **`random` ê²€ìƒ‰** - ì œê³µëœ `distribution`ì— ë”°ë¼ ê° ìƒˆë¡œìš´ ì¡°í•©ì„ ë¬´ì‘ìœ„ë¡œ ì„ íƒí•©ë‹ˆë‹¤. ë†€ëê²Œë„ íš¨ê³¼ì ì…ë‹ˆë‹¤!
*   **`bayes`ian ê²€ìƒ‰** - ë©”íŠ¸ë¦­ ì ìˆ˜ë¥¼ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ í•¨ìˆ˜ë¡œ í•˜ëŠ” í™•ë¥ ì  ëª¨ë¸ì„ ìƒì„±í•˜ê³ , ë©”íŠ¸ë¦­ì„ ê°œì„ í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì„ íƒí•©ë‹ˆë‹¤. ì—°ì† íŒŒë¼ë¯¸í„°ì˜ ì‘ì€ ìˆ˜ì— ëŒ€í•´ì„œëŠ” ì˜ ì‘ë™í•˜ì§€ë§Œ ê·œëª¨ê°€ ì»¤ì§ˆìˆ˜ë¡ ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤.

ìš°ë¦¬ëŠ” `random`ì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.


```python
sweep_config = {
    'method': 'random'
    }
```

`bayes`ian ìŠ¤ìœ•ì˜ ê²½ìš°,
ë©”íŠ¸ë¦­ì— ëŒ€í•´ ì¡°ê¸ˆ ë” ì•Œë ¤ì¤„ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.
ë©”íŠ¸ë¦­ì˜ `name`ì„ ì•Œì•„ì•¼ í•˜ë©°,
ë©”íŠ¸ë¦­ì„ `minimize`í•  ê²ƒì¸ì§€
(ì˜ˆ: ì œê³± ì˜¤ë¥˜ì¸ ê²½ìš°)
ì•„ë‹ˆë©´ `maximize`í•  ê²ƒì¸ì§€
(ì˜ˆ: ì •í™•ë„ì¸ ê²½ìš°) ì•Œì•„ì•¼ í•©ë‹ˆë‹¤.


```python
metric = {
    'name': 'loss',
    'goal': 'minimize'   
    }

sweep_config['metric'] = metric
```

`bayes`ian ìŠ¤ìœ•ì„ ì‹¤í–‰í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ë„,
ë‚˜ì¤‘ì— ë§ˆìŒì„ ë°”ê¾¸ê±°ë‚˜,
6ê°œì›”ì´ë‚˜ 6ë…„ í›„ì— ìŠ¤ìœ•ìœ¼ë¡œ ëŒì•„ì™€ì„œ
`val_G_batch`ê°€ ë†’ê±°ë‚˜ ë‚®ì•„ì•¼ í•˜ëŠ”ì§€ ëª¨ë¥´ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬
`sweep_config`ì— ì´ë¥¼ í¬í•¨í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
ë˜í•œ, ì¬í˜„ì„±ì„ ìœ„í•œ ì¢‹ì€ ì‹¤ì²œ ë°©ë²•ì…ë‹ˆë‹¤.

### ğŸ“ƒ í•˜ì´í¼`parameters` ì´ë¦„ ì§€ì •

í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ ìƒˆë¡œìš´ ê°’ì„ ì‹œë„í•  `method`ë¥¼ ì„ íƒí•œ í›„ì—ëŠ”
ê·¸ `parameters`ê°€ ë¬´ì—‡ì¸ì§€ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.

ëŒ€ë¶€ë¶„ì˜ ê²½ìš°, ì´ ë‹¨ê³„ëŠ” ê°„ë‹¨í•©ë‹ˆë‹¤:
`parameter`ì— ì´ë¦„ì„ ì§€ì •í•˜ê³ 
íŒŒë¼ë¯¸í„°ì˜ í•©ë²•ì ì¸ `values` ëª©ë¡ì„ ì§€ì •í•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´, ë„¤íŠ¸ì›Œí¬ì˜ `optimizer`ë¥¼ ì„ íƒí•  ë•Œ,
ì˜µì…˜ì˜ ìˆ˜ëŠ” ì œí•œë˜ì–´ ìˆìŠµë‹ˆë‹¤.
ì—¬ê¸°ì„œëŠ” ê°€ì¥ ì¸ê¸° ìˆëŠ” ë‘ ê°€ì§€ ì˜µì…˜ì¸ `adam`ê³¼ `sgd`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
ë¬´í•œíˆ ë§ì€ ì˜µì…˜ì´ ìˆëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ë„,
ì—¬ê¸°ì„œì™€ ê°™ì´ ì€ë‹‰ `layer_size`ì™€ `dropout`ì— ëŒ€í•´
ëª‡ ê°€ì§€ ì„ íƒëœ `values`ë§Œ ì‹œë„í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.


```python
parameters_dict = {
    'optimizer': {
        'values': ['adam', 'sgd']
        },
    'fc_layer_size': {
        'values': [128, 256, 512]
        },
    'dropout': {
          'values': [0.3, 0.4, 0.5]
        },
    }

sweep_config['parameters'] = parameters_dict
```

ì´ ìŠ¤ìœ•ì—ì„œ ë³€í™”ì‹œí‚¤ê³  ì‹¶ì§€ ì•Šì€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ ìˆì§€ë§Œ,
ì—¬ì „íˆ `sweep_config`ì— ì„¤ì •í•˜ê³  ì‹¶ì€ ê²½ìš°ê°€ ì¢…ì¢… ìˆìŠµë‹ˆë‹¤.

ì´ ê²½ìš°, `value`ë¥¼ ì§ì ‘ ì„¤ì •í•˜ë©´ ë©ë‹ˆë‹¤:


```python
parameters_dict.update({
    'epochs': {
        'value': 1}
    })
```

`grid` ê²€ìƒ‰ì˜ ê²½ìš°, ì´ê²ƒì´ í•„ìš”í•œ ì „ë¶€ì…ë‹ˆë‹¤.

`random` ê²€ìƒ‰ì˜ ê²½ìš°,
ì£¼ì–´ì§„ ì‹¤í–‰ì—ì„œ íŒŒë¼ë¯¸í„°ì˜ ëª¨ë“  `values`ê°€ ì„ íƒë  í™•ë¥ ì€ ë™ì¼í•©ë‹ˆë‹¤.

ë§Œì•½ ì´ê²ƒì´ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ë©´,
ëŒ€ì‹  ëª…ëª…ëœ `distribution`ê³¼ ê·¸ ë§¤ê°œë³€ìˆ˜, ì˜ˆë¥¼ ë“¤ì–´ `normal` ë¶„í¬ì˜ í‰ê·  `mu`
ë° í‘œì¤€í¸ì°¨ `sigma`ë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

[ì—¬ê¸°](https://docs.wandb.com/sweeps/configuration#distributions)ì—ì„œ ë¬´ì‘ìœ„ ë³€ìˆ˜ì˜ ë¶„í¬ë¥¼ ì„¤ì •í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ì„¸ìš”.


```python
parameters_dict.update({
    'learning_rate': {
        # 0ê³¼ 0.1 ì‚¬ì´ì˜ í‰í‰í•œ ë¶„í¬
        'distribution': 'uniform',
        'min': 0,
        'max': 0.1
      },
    'batch_size': {
        # 32ì™€ 256 ì‚¬ì´ì˜ ì •ìˆ˜
        # ë¡œê·¸ê°€ ê· ë“±í•˜ê²Œ ë¶„í¬ë¨
        'distribution': 'q_log_uniform_values',
        'q': 8,
        'min': 32,
        'max': 256,
      }
    })
```

ì™„ë£Œë˜ë©´, `sweep_config`ì€ ìš°ë¦¬ê°€ ì‹œë„í•˜ê³ ì í•˜ëŠ” `parameters`ì™€
ê·¸ê²ƒë“¤ì„ ì‹œë„í•  `method`ë¥¼ ì •í™•íˆ ì§€ì •í•˜ëŠ” ì¤‘ì²©ëœ ì‚¬ì „ì…ë‹ˆë‹¤.


```python
import pprint

pprint.pprint(sweep_config)
```

í•˜ì§€ë§Œ êµ¬ì„± ì˜µì…˜ì€ ì´ê²ƒë¿ë§Œì´ ì•„ë‹™ë‹ˆë‹¤!

ì˜ˆë¥¼ ë“¤ì–´, [HyperBand](https://arxiv.org/pdf/1603.06560.pdf) ìŠ¤ì¼€ì¤„ë§ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰ì„ `early_terminate`í•  ìˆ˜ ìˆëŠ” ì˜µì…˜ë„ ì œê³µí•©ë‹ˆë‹¤. [ì—¬ê¸°](https://docs.wandb.com/sweeps/configuration#stopping-criteria)ì—ì„œ ë” ìì„¸íˆ ì•Œì•„ë³´ì„¸ìš”.

ëª¨ë“  êµ¬ì„± ì˜µì…˜ ëª©ë¡ì„ [ì—¬ê¸°](https://docs.wandb.com/library/sweeps/configuration)ì—ì„œ ì°¾ì„ ìˆ˜ ìˆê³ , YAML í˜•ì‹ì˜ í° ì˜ˆì œ ëª¨ìŒì„ [ì—¬ê¸°](https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion)ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# 2ï¸âƒ£ë‹¨ê³„. ìŠ¤ìœ• ì´ˆê¸°í™”

ê²€ìƒ‰ ì „ëµì„ ì •ì˜í•œ í›„, ì´ë¥¼ êµ¬í˜„í•  ë¬´ì–¸ê°€ë¥¼ ì„¤ì •í•  ì‹œê°„ì…ë‹ˆë‹¤.

ìš°ë¦¬ ìŠ¤ìœ•ì˜ ì‹œê³„ ì‘ì—…ì¥ì€ _Sweep Controller_ë¡œ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤.
ê° ì‹¤í–‰ì´ ì™„ë£Œë  ë•Œë§ˆë‹¤, ì‹¤í–‰í•  ìƒˆë¡œìš´ ì‹¤í–‰ ì„¸íŠ¸ì— ëŒ€í•œ ì§€ì¹¨ì„ ë°œí–‰í•©ë‹ˆë‹¤.
ì´ëŸ¬í•œ ì§€ì¹¨ì€ ì‹¤í–‰ì„ ì‹¤ì œë¡œ ìˆ˜í–‰í•˜ëŠ” _ì—ì´ì „íŠ¸_ì— ì˜í•´ ìˆ˜ì§‘ë©ë‹ˆë‹¤.

ì¼ë°˜ì ì¸ ìŠ¤ìœ•ì—ì„œ, ì»¨íŠ¸ë¡¤ëŸ¬ëŠ” _ìš°ë¦¬_ ê¸°ê³„ì— ì¡´ì¬í•˜ëŠ” ë°˜ë©´,
ì‹¤í–‰ì„ ì™„ë£Œí•˜ëŠ” ì—ì´ì „íŠ¸ëŠ” _ë‹¹ì‹ _ ê¸°ê³„(ë“¤)ì— ì¡´ì¬í•©ë‹ˆë‹¤.
ì´ ì‘ì—… ë¶„ë‹´ì€ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” ê¸°ê³„ë¥¼ ì¶”ê°€í•¨ìœ¼ë¡œì¨ ìŠ¤ìœ•ì„ ì‰½ê²Œ í™•ì¥í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤!

ì ì ˆí•œ `sweep_config` ë° `project` ì´ë¦„ìœ¼ë¡œ `wandb.sweep`ì„ í˜¸ì¶œí•˜ì—¬ ìŠ¤ìœ• ì»¨íŠ¸ë¡¤ëŸ¬ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ í•¨ìˆ˜ëŠ” ë‚˜ì¤‘ì— ì—ì´ì „íŠ¸ë¥¼ ì´ ì»¨íŠ¸ë¡¤ëŸ¬ì— í• ë‹¹í•˜ëŠ” ë° ì‚¬ìš©í•  `sweep_id`ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

> _ë¶€ê°€ ì„¤ëª…_: ì»¤ë§¨ë“œ ë¼ì¸ì—ì„œ, ì´ í•¨ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ëŒ€ì²´ë©ë‹ˆë‹¤.
```python
wandb sweep config.yaml
```
[ì»¤ë§¨ë“œ ë¼ì¸ì—ì„œ ìŠ¤ìœ• ì‚¬ìš©ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ê¸° â¡](https://docs.wandb.ai/guides/sweeps/walkthrough)


```python
sweep_id = wandb.sweep(sweep_config, project="pytorch-sweeps-demo")
```

# 3ï¸âƒ£ë‹¨ê³„. ìŠ¤ìœ• ì—ì´ì „íŠ¸ ì‹¤í–‰

### ğŸ’» í•™ìŠµ ì ˆì°¨ ì •ì˜

ìŠ¤ìœ•ì„ ì‹¤ì œë¡œ ì‹¤í–‰í•˜ê¸° ì „ì—,
ê·¸ ê°’ë“¤ì„ ì‚¬ìš©í•˜ëŠ” í•™ìŠµ ì ˆì°¨ë¥¼ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.

ì•„ë˜ í•¨ìˆ˜ì—ì„œ, PyTorchì—ì„œ ê°„ë‹¨í•œ ì™„ì „ ì—°ê²° ì‹ ê²½ë§ì„ ì •ì˜í•˜ê³ , ëª¨ë¸ ë©”íŠ¸ë¦­ì„ ë¡œê·¸í•˜ê³ , ì„±ëŠ¥ê³¼ ì¶œë ¥ì„ ì‹œê°í™”í•˜ë©°, ì‹¤í—˜ì„ ì¶”ì í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ `wandb` ë„êµ¬ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤:
* [**`wandb.init()`**](https://docs.wandb.com/library/init) â€“ ìƒˆë¡œìš´ W&B ì‹¤í–‰ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ê° ì‹¤í–‰ì€ í•™ìŠµ í•¨ìˆ˜ì˜ ë‹¨ì¼ ì‹¤í–‰ì…ë‹ˆë‹¤.
* [**`wandb.config`**](https://docs.wandb.com/library/config) â€“ ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ êµ¬ì„± ê°ì²´ì— ì €ì¥í•˜ì—¬ ë¡œê·¸í•©ë‹ˆë‹¤. `wandb.config` ì‚¬ìš© ë°©ë²•ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ë ¤ë©´ [ì—¬ê¸°](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Configs_in_W%26B.ipynb)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
* [**`wandb.log()`**](https://docs.wandb.com/library/log) â€“ ëª¨ë¸ ë™ì‘ì„ W&Bì— ë¡œê·¸í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì„±ëŠ¥ë§Œ ë¡œê·¸í•˜ì§€ë§Œ, `wandb.log`ë¡œ ë¡œê·¸í•  ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ ëª¨ë“  ë¦¬ì¹˜ ë¯¸ë””ì–´ëŠ” [ì´ Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Log_(Almost)_Anything_with_W%26B_Media.ipynb)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

PyTorchì™€ W&Bë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ìì„¸í•œ ë‚´ìš©ì€ [ì´ Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Simple_PyTorch_Integration.ipynb)ì„ ì°¸ì¡°í•˜ì„¸ìš”.


```python
import torch
import torch.optim as optim
import torch.nn.functional as F
import torch.nn as nn
from torchvision import datasets, transforms

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def train(config=None):
    # ìƒˆë¡œìš´ wandb ì‹¤í–‰ì„ ì´ˆê¸°í™”
    with wandb.init(config=config):
        # wandb.agentì— ì˜í•´ í˜¸ì¶œëœ ê²½ìš°,
        # ì´ êµ¬ì„±ì€ ìŠ¤ìœ• ì»¨íŠ¸ë¡¤ëŸ¬ì— ì˜í•´ ì„¤ì •ë©ë‹ˆë‹¤
        config = wandb.config

        loader = build_dataset(config.batch_size)
        network = build_network(config.fc_layer_size, config.dropout)
        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)

        for epoch in range(config.epochs):
            avg_loss = train_epoch(network, loader, optimizer)
            wandb.log({"loss": avg_loss, "epoch": epoch})           
```

ì´ ì…€ì€ í•™ìŠµ ì ˆì°¨ì˜ ë„¤ ë¶€ë¶„ì„ ì •ì˜í•©ë‹ˆë‹¤:
`build_dataset`, `build_network`, `build_optimizer`, `train_epoch`.

ëª¨ë‘ ê¸°ë³¸ PyTorch íŒŒì´í”„ë¼ì¸ì˜ í‘œì¤€ ë¶€ë¶„ì´ë©°,
W&B ì‚¬ìš©ì— ì˜í–¥ì„ ë°›ì§€ ì•Šìœ¼ë¯€ë¡œ ì„¤ëª…í•˜ì§€ ì•Šê² ìŠµë‹ˆë‹¤.


```python
def build_dataset(batch_size):
   
    transform = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.1307,), (0.3081,))])
    # MNIST í•™ìŠµ ë°ì´í„°ì„¸íŠ¸ ë‹¤ìš´ë¡œë“œ
    dataset = datasets.MNIST(".", train=True, download=True,
                             transform=transform)
    sub_dataset = torch.utils.data.Subset(
        dataset, indices=range(0, len(dataset), 5))
    loader = torch.utils.data.DataLoader(sub_dataset, batch_size=batch_size)

    return loader


def build_network(fc_layer_size, dropout):
    network = nn.Sequential(  # ì™„ì „ ì—°ê²°, ë‹¨ì¼ ì€ë‹‰ì¸µ
        nn.Flatten(),
        nn.Linear(784, fc_layer_size), nn.ReLU(),
        nn.Dropout(dropout),
        nn.Linear(fc_layer_size, 10),
        nn.LogSoftmax(dim=1))

    return network.to(device)
        

def build_optimizer(network, optimizer, learning_rate):
    if optimizer == "sgd":
        optimizer = optim.SGD(network.parameters(),
                              lr=learning_rate, momentum=0.9)
    elif optimizer == "adam":
        optimizer = optim.Adam(network.parameters(),
                               lr=learning_rate)
    return optimizer


def train_epoch(network, loader, optimizer):
    cumu_loss = 0
    for _, (data, target) in enumerate(loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()

        # â¡ ìˆœë°©í–¥ ì „ë‹¬
        loss = F.nll_loss(network(data), target)
        cumu_loss += loss.item()

        # â¬… ì—­ë°©í–¥ ì „ë‹¬ + ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        loss.backward()
        optimizer.step()

        wandb.log({"batch loss": loss.item()})

    return cumu_loss / len(loader)
```

ì´ì œ ìŠ¤ìœ•ì„ ì‹œì‘í•  ì¤€ë¹„