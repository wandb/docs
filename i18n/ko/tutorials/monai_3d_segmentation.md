---
displayed_sidebar: default
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { CTAButtons } from '@site/src/components/CTAButtons/CTAButtons.tsx';

# MONAIë¥¼ ì‚¬ìš©í•œ 3D ë‡Œì¢…ì–‘ ë¶„í• 

<CTAButtons colabLink="https://colab.research.google.com/github/wandb/examples/blob/main/colabs/monai/3d_brain_tumor_segmentation.ipynb"></CTAButtons>

ì´ íŠœí† ë¦¬ì–¼ì€ [MONAI](https://github.com/Project-MONAI/MONAI)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì¤‘ ë¼ë²¨ 3D ë‡Œì¢…ì–‘ ë¶„í•  ì‘ì—…ì˜ íŠ¸ë ˆì´ë‹ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•˜ê³  [Weights & Biases](https://wandb.ai/site)ì˜ ì‹¤í—˜ ì¶”ì  ë° ë°ì´í„° ì‹œê°í™” ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì€ ë‹¤ìŒ ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤:

1. Weights & Biases runì„ ì´ˆê¸°í™”í•˜ê³  ì¬í˜„ì„±ì„ ìœ„í•´ runê³¼ ê´€ë ¨ëœ ëª¨ë“  ì„¤ì •ì„ ë™ê¸°í™”í•©ë‹ˆë‹¤.
2. MONAI ë³€í™˜ API:
    1. ì‚¬ì „ í˜•ì‹ ë°ì´í„°ì— ëŒ€í•œ MONAI ë³€í™˜.
    2. MONAI `transforms` APIì— ë”°ë¼ ìƒˆë¡œìš´ ë³€í™˜ì„ ì •ì˜í•˜ëŠ” ë°©ë²•.
    3. ë°ì´í„° ì¦ê°•ì„ ìœ„í•´ ë¬´ì‘ìœ„ë¡œ ê°•ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” ë°©ë²•.
3. ë°ì´í„° ë¡œë”© ë° ì‹œê°í™”:
    1. ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ `Nifti` ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³ , ì´ë¯¸ì§€ ëª©ë¡ì„ ë¡œë“œí•˜ì—¬ ìŒ“ëŠ” ë°©ë²•.
    2. íŠ¸ë ˆì´ë‹ ë° ê²€ì¦ì„ ê°€ì†í™”í•˜ê¸° ìœ„í•´ IO ë° ë³€í™˜ì„ ìºì‹œí•©ë‹ˆë‹¤.
    3. `wandb.Table`ê³¼ Weights & Biases ìƒì˜ ìƒí˜¸ì‘ìš© ë¶„í•  ì˜¤ë²„ë ˆì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
4. 3D `SegResNet` ëª¨ë¸ íŠ¸ë ˆì´ë‹
    1. MONAIì˜ `networks`, `losses`, `metrics` API ì‚¬ìš©.
    2. PyTorch íŠ¸ë ˆì´ë‹ ë£¨í”„ë¥¼ ì‚¬ìš©í•œ 3D `SegResNet` ëª¨ë¸ íŠ¸ë ˆì´ë‹.
    3. Weights & Biasesë¥¼ ì‚¬ìš©í•œ íŠ¸ë ˆì´ë‹ ì‹¤í—˜ ì¶”ì .
    4. Weights & Biasesì—ì„œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œê·¸í•˜ê³  ë²„ì „ì„ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¡œ ê´€ë¦¬.
5. `wandb.Table`ê³¼ Weights & Biases ìƒì˜ ìƒí˜¸ì‘ìš© ë¶„í•  ì˜¤ë²„ë ˆì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ì¦ ë°ì´í„°ì…‹ì˜ ì˜ˆì¸¡ê°’ì„ ì‹œê°í™”í•˜ê³  ë¹„êµ.

## ğŸŒ´ ì„¤ì¹˜ ë° ì„¤ì •

ë¨¼ì €, MONAIì™€ Weights and Biasesì˜ ìµœì‹  ë²„ì „ì„ ì„¤ì¹˜í•˜ì„¸ìš”.

```python
!python -c "import monai" || pip install -q -U "monai[nibabel, tqdm]"
!python -c "import wandb" || pip install -q -U wandb
```

```python
import os

import numpy as np
from tqdm.auto import tqdm
import wandb

from monai.apps import DecathlonDataset
from monai.data import DataLoader, decollate_batch
from monai.losses import DiceLoss
from monai.inferers import sliding_window_inference
from monai.metrics import DiceMetric
from monai.networks.nets import SegResNet
from monai.transforms import (
    Activations,
    AsDiscrete,
    Compose,
    LoadImaged,
    MapTransform,
    NormalizeIntensityd,
    Orientationd,
    RandFlipd,
    RandScaleIntensityd,
    RandShiftIntensityd,
    RandSpatialCropd,
    Spacingd,
    EnsureTyped,
    EnsureChannelFirstd,
)
from monai.utils import set_determinism

import torch
```

ê·¸ëŸ° ë‹¤ìŒ, Colab ì¸ìŠ¤í„´ìŠ¤ë¥¼ W&Bì— ì¸ì¦í•©ë‹ˆë‹¤.

```python
wandb.login()
```

## ğŸŒ³ W&B Run ì´ˆê¸°í™”

ìƒˆë¡œìš´ W&B runì„ ì‹œì‘í•˜ì—¬ ì‹¤í—˜ì„ ì¶”ì í•˜ì„¸ìš”.

```python
wandb.init(project="monai-brain-tumor-segmentation")
```

ì¬í˜„ ê°€ëŠ¥í•œ ê¸°ê³„í•™ìŠµì„ ìœ„í•œ ì ì ˆí•œ ì„¤ì • ì‹œìŠ¤í…œ ì‚¬ìš©ì„ ê¶Œì¥í•˜ëŠ” ìµœì„ ì˜ ê´€í–‰ì…ë‹ˆë‹¤. ëª¨ë“  ì‹¤í—˜ì— ëŒ€í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ W&Bë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
config = wandb.config
config.seed = 0
config.roi_size = [224, 224, 144]
config.batch_size = 1
config.num_workers = 4
config.max_train_images_visualized = 20
config.max_val_images_visualized = 20
config.dice_loss_smoothen_numerator = 0
config.dice_loss_smoothen_denominator = 1e-5
config.dice_loss_squared_prediction = True
config.dice_loss_target_onehot = False
config.dice_loss_apply_sigmoid = True
config.initial_learning_rate = 1e-4
config.weight_decay = 1e-5
config.max_train_epochs = 50
config.validation_intervals = 1
config.dataset_dir = "./dataset/"
config.checkpoint_dir = "./checkpoints"
config.inference_roi_size = (128, 128, 64)
config.max_prediction_images_visualized = 20
```

ê²°ì •ì ì¸ íŠ¸ë ˆì´ë‹ì„ í™œì„±í™”í•˜ê±°ë‚˜ ë„ê¸° ìœ„í•´ ëª¨ë“ˆì˜ ë‚œìˆ˜ ì‹œë“œë„ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.

```python
set_determinism(seed=config.seed)

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(config.dataset_dir, exist_ok=True)
os.makedirs(config.checkpoint_dir, exist_ok=True)
```

## ğŸ’¿ ë°ì´í„° ë¡œë”© ë° ë³€í™˜

ì—¬ê¸°ì—ì„œëŠ” `monai.transforms` APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë©€í‹° í´ë˜ìŠ¤ ë¼ë²¨ì„ ì›-í•« í˜•ì‹ì˜ ë©€í‹° ë¼ë²¨ ë¶„í•  ì‘ì—…ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì‚¬ìš©ì ì •ì˜ ë³€í™˜ì„ ìƒì„±í•©ë‹ˆë‹¤.

```python
class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):
    """
    ë¸Œë í´ë˜ìŠ¤ì— ê¸°ë°˜í•œ ë©€í‹° ì±„ë„ë¡œ ë¼ë²¨ì„ ë³€í™˜:
    ë¼ë²¨ 1ì€ ì£¼ë³€ë¶€ ë¶€ì¢…
    ë¼ë²¨ 2ëŠ” GD-ì¦ê°• ì¢…ì–‘
    ë¼ë²¨ 3ì€ ê´´ì‚¬ ë° ë¹„ì¦ê°• ì¢…ì–‘ í•µ
    ê°€ëŠ¥í•œ í´ë˜ìŠ¤ëŠ” TC (ì¢…ì–‘ í•µ), WT (ì „ì²´ ì¢…ì–‘)
    ë° ET (ì¦ê°• ì¢…ì–‘)ì…ë‹ˆë‹¤.

    ì°¸ì¡°: https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/brats_segmentation_3d.ipynb

    """

    def __call__(self, data):
        d = dict(data)
        for key in self.keys:
            result = []
            # ë¼ë²¨ 2ì™€ ë¼ë²¨ 3ì„ í•©ì³ TCë¥¼ êµ¬ì„±
            result.append(torch.logical_or(d[key] == 2, d[key] == 3))
            # ë¼ë²¨ 1, 2, 3ì„ í•©ì³ WTë¥¼ êµ¬ì„±
            result.append(
                torch.logical_or(
                    torch.logical_or(d[key] == 2, d[key] == 3), d[key] == 1
                )
            )
            # ë¼ë²¨ 2ê°€ ET
            result.append(d[key] == 2)
            d[key] = torch.stack(result, axis=0).float()
        return d
```

ë‹¤ìŒìœ¼ë¡œ, íŠ¸ë ˆì´ë‹ ë° ê²€ì¦ ë°ì´í„°ì…‹ì— ëŒ€í•´ ê°ê° ë³€í™˜ì„ ì„¤ì •í•©ë‹ˆë‹¤.

```python
train_transform = Compose(
    [
        # 4ê°œì˜ Nifti ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³  í•¨ê»˜ ìŒ“ê¸°
        LoadImaged(keys=["image", "label"]),
        EnsureChannelFirstd(keys="image"),
        EnsureTyped(keys=["image", "label"]),
        ConvertToMultiChannelBasedOnBratsClassesd(keys="label"),
        Orientationd(keys=["image", "label"], axcodes="RAS"),
        Spacingd(
            keys=["image", "label"],
            pixdim=(1.0, 1.0, 1.0),
            mode=("bilinear", "nearest"),
        ),
        RandSpatialCropd(
            keys=["image", "label"], roi_size=config.roi_size, random_size=False
        ),
        RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=0),
        RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=1),
        RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=2),
        NormalizeIntensityd(keys="image", nonzero=True, channel_wise=True),
        RandScaleIntensityd(keys="image", factors=0.1, prob=1.0),
        RandShiftIntensityd(keys="image", offsets=0.1, prob=1.0),
    ]
)
val_transform = Compose(
    [
        LoadImaged(keys=["image", "label"]),
        EnsureChannelFirstd(keys="image"),
        EnsureTyped(keys=["image", "label"]),
        ConvertToMultiChannelBasedOnBratsClassesd(keys="label"),
        Orientationd(keys=["image", "label"], axcodes="RAS"),
        Spacingd(
            keys=["image", "label"],
            pixdim=(1.0, 1.0, 1.0),
            mode=("bilinear", "nearest"),
        ),
        NormalizeIntensityd(keys="image", nonzero=True, channel_wise=True),
    ]
)
```

### ğŸ ë°ì´í„°ì…‹

ì´ ì‹¤í—˜ì— ì‚¬ìš©ëœ ë°ì´í„°ì…‹ì€ http://medicaldecathlon.com/ì—ì„œ ì™”ìŠµë‹ˆë‹¤. ë‹¤ì¤‘ ëª¨ë‹¬ ë‹¤ì¤‘ ì‚¬ì´íŠ¸ MRI ë°ì´í„°(FLAIR, T1w, T1gd, T2w)ë¥¼ ì‚¬ìš©í•˜ì—¬ êµëª¨ì„¸í¬ì¢…, ê´´ì‚¬/í™œì„± ì¢…ì–‘ ë° ë¶€ì¢…ì„ ë¶„í• í•©ë‹ˆë‹¤. ë°ì´í„°ì…‹ì€ 750ê°œì˜ 4D ë³¼ë¥¨(484 íŠ¸ë ˆì´ë‹ + 266 í…ŒìŠ¤íŠ¸)ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

`DecathlonDataset`ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì„ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ê³  ì¶”ì¶œí•©ë‹ˆë‹¤. ì´ëŠ” MONAI `CacheDataset`ì„ ìƒì†ë°›ì•„ íŠ¸ë ˆì´ë‹ì— ëŒ€í•´ `cache_num=N`ì„ ì„¤ì •í•˜ì—¬ `N`ê°œ í•­ëª©ì„ ìºì‹œí•˜ê³  ë©”ëª¨ë¦¬ í¬ê¸°ì— ë”°ë¼ ê²€ì¦ í•­ëª© ì „ì²´ë¥¼ ìºì‹œí•˜ëŠ” ê¸°ë³¸ ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
train_dataset = DecathlonDataset(
    root_dir=config.dataset_dir,
    task="Task01_BrainTumour",
    transform=val_transform,
    section="training",
    download=True,
    cache_rate=0.0,
    num_workers=4,
)
val_dataset = DecathlonDataset(
    root_dir=config.dataset_dir,
    task="Task01_BrainTumour",
    transform=val_transform,
    section="validation",
    download=False,
    cache_rate=0.0,
    num_workers=4,
)
```

:::info
**ì°¸ê³ :** `train_dataset`ì— `train_transform`ì„ ì ìš©í•˜ëŠ” ëŒ€ì‹  íŠ¸ë ˆì´ë‹ ë° ê²€ì¦ ë°ì´í„°ì…‹ ëª¨ë‘ì— `val_transform`ì„ ì ìš©í•©ë‹ˆë‹¤. ì´ëŠ” íŠ¸ë ˆì´ë‹ ì „ì— ë°ì´í„°ì…‹ì˜ ë‘ ë¶„í•  ëª¨ë‘ì—ì„œ ìƒ˜í”Œì„ ì‹œê°í™”í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
:::

### ğŸ“¸ ë°ì´í„°ì…‹ ì‹œê°í™”

Weights & BiasesëŠ” ì´ë¯¸ì§€, ë¹„ë””ì˜¤, ì˜¤ë””ì˜¤ ë“±ì„ ì§€ì›í•©ë‹ˆë‹¤. ê²°ê³¼ë¥¼ íƒìƒ‰í•˜ê³  ì‹¤í–‰, ëª¨ë¸ ë° ë°ì´í„°ì…‹ì„ ì‹œê°ì ìœ¼ë¡œ ë¹„êµí•˜ê¸° ìœ„í•´ ë¦¬ì¹˜ ë¯¸ë””ì–´ë¥¼ ë¡œê·¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [ë¶„í•  ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´ ì‹œìŠ¤í…œ](https://docs.wandb.ai/guides/track/log/media#image-overlays-in-tables)ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë³¼ë¥¨ì„ ì‹œê°í™”í•©ë‹ˆë‹¤. [í…Œì´ë¸”](https://docs.wandb.ai/guides/tables)ì— ë¶„í•  ë§ˆìŠ¤í¬ë¥¼ ë¡œê·¸í•˜ë ¤ë©´ ê° í–‰ì— ëŒ€í•´ `wandb.Image` ê°ì²´ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

ì•„ë˜ì˜ ì˜ì‚¬ì½”ë“œì—ì„œ ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤:

```python
table = wandb.Table(columns=["ID", "Image"])

for id, img, label in zip(ids, images, labels):
    mask_img = wandb.Image(
        img,
        masks={
            "prediction": {"mask_data": label, "class_labels": class_labels}
            # ...
        },
    )

    table.add_data(id, img)

wandb.log({"Table": table})
```

ì´ì œ ìƒ˜í”Œ ì´ë¯¸ì§€, ë¼ë²¨, `wandb.Table` ê°ì²´ ë° ì¼ë¶€ ê´€ë ¨ ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ Weights & Biases ëŒ€ì‹œë³´ë“œì— ë¡œê·¸ë  í…Œì´ë¸”ì˜ í–‰ì„ ì±„ìš°ëŠ” ê°„ë‹¨í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

```python
def log_data_samples_into_tables(
    sample_image: np.array,
    sample_label: np.array,
    split: str = None,
    data_idx: int = None,
    table: wandb.Table = None,
):
    num_channels, _, _, num_slices = sample_image.shape
    with tqdm(total=num_slices, leave=False) as progress_bar:
        for slice_idx in range(num_slices):
            ground_truth_wandb_images = []
            for channel_idx in range(num_channels):
                ground_truth_wandb_images.append(
                    masks = {
                        "ground-truth/Tumor-Core": {
                            "mask_data": sample_label[0, :, :, slice_idx],
                            "class_labels": {0: "background", 1: "Tumor Core"},
                        },
                        "ground-truth/Whole-Tumor": {
                            "mask_data": sample_label[1, :, :, slice_idx] * 2,
                            "class_labels": {0: "background", 2: "Whole Tumor"},
                        },
                        "ground-truth/Enhancing-Tumor": {
                            "mask_data": sample_label[2, :, :, slice_idx] * 3,
                            "class_labels": {0: "background", 3: "Enhancing Tumor"},
                        },
                    }
                    wandb.Image(
                        sample_image[channel_idx, :, :, slice_idx],
                        masks=masks,
                    )
                )
            table.add_data(split, data_idx, slice_idx, *ground_truth_wandb_images)
            progress_bar.update(1)
    return table
```

ë‹¤ìŒìœ¼ë¡œ, `wandb.Table` ê°ì²´ì™€ ë°ì´í„° ì‹œê°í™”ë¡œ ì±„ìš¸ ì—´ì´ ë¬´ì—‡ì¸ì§€ ì •ì˜í•©ë‹ˆë‹¤.

```python
table = wandb.Table(
    columns=[
        "Split",
        "Data Index",
        "Slice Index",
        "Image-Channel-0",
        "Image-Channel-1",
        "Image-Channel-2",
        "Image-Channel-3",
    ]
)
```

ê·¸ëŸ° ë‹¤ìŒ, ëŒ€ì‹œë³´ë“œì— ë¡œê·¸ë  í…Œì´ë¸”ì˜ í–‰ì„ ì±„ìš°ê¸° ìœ„í•´ ë°ì´í„° ìƒ˜í”Œì— ëŒ€í•œ ì‹œê°í™”ë¥¼ ìƒì„±í•˜ê³  `train_dataset` ë° `val_dataset`ì„ ê°ê° ë£¨í”„í•˜ì—¬ ì§„í–‰í•©ë‹ˆë‹¤.

```python
# train_datasetì— ëŒ€í•œ ì‹œê°í™” ìƒì„±
max_samples = (
    min(config.max_train_images_visualized, len(train_dataset))
    if config.max_train_images_visualized > 0
    else len(train_dataset)
)
progress_bar = tqdm(
    enumerate(train_dataset[:max_samples]),
    total=max_samples,
    desc="íŠ¸ë ˆì´ë‹ ë°ì´í„°ì…‹ ì‹œê°í™” ìƒì„±:",
)
for data_idx, sample in progress_bar:
    sample_image = sample["image"].detach().cpu().numpy()
    sample_label = sample["label"].detach().cpu().numpy()
    table = log_data_samples_into_tables(
        sample_image,
        sample_label,
        split="train",
        data_idx=data_idx,
        table=table,
    )

# val_datasetì— ëŒ€í•œ ì‹œê°í™” ìƒì„±
max_samples = (
    min(config.max_val_images_visualized, len(val_dataset))
    if config.max_val_images_visualized > 0
    else len(val_dataset)
)
progress_bar = tqdm(
    enumerate(val_dataset[:max_samples]),
    total=max_samples,
    desc="ê²€ì¦ ë°ì´í„°ì…‹ ì‹œê°í™” ìƒì„±:",
)
for data_idx, sample in progress_bar:
    sample_image = sample["image"].detach().cpu().numpy()
    sample_label = sample["label"].detach().cpu().numpy()
    table = log_data_samples_into_tables(
        sample_image,
        sample_label,
        split="val",
        data_idx=data_idx,
        table=table,
    )

# ëŒ€ì‹œë³´ë“œì— í…Œì´ë¸” ë¡œê·¸
wandb.log({"ì¢…ì–‘ ë¶„í•  ë°ì´í„°": table})
```

ë°ì´í„°ëŠ” W&B ëŒ€ì‹œë³´ë“œì—ì„œ ìƒí˜¸ ì‘ìš© ê°€ëŠ¥í•œ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. ë°ì´í„° ë³¼ë¥¨ì˜ íŠ¹ì • ìŠ¬ë¼ì´ìŠ¤ì˜ ê° ì±„ë„ì„ ê°ê°ì˜ ë¶„í•  ë§ˆìŠ¤í¬ì™€ í•¨ê»˜ ì˜¤ë²„ë ˆì´ í•œ í–‰ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. [Weave ì¿¼ë¦¬](https://docs.wandb.ai/guides/weave)ë¥¼ ì‘ì„±í•˜ì—¬ í…Œì´ë¸”ì˜ ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ê³  íŠ¹ì • í–‰ì— ì§‘ì¤‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

| ![ë¡œê·¸ëœ í…Œì´ë¸” ë°ì´í„°ì˜ ì˜ˆì‹œì…ë‹ˆë‹¤.](@site/static/images/t

### ğŸ­ í‘œì¤€ PyTorch íŠ¸ë ˆì´ë‹ ë£¨í”„ ì‹¤í–‰í•˜ê¸°

```python
# W&B Artifact ì˜¤ë¸Œì íŠ¸ ì •ì˜í•˜ê¸°
artifact = wandb.Artifact(
    name=f"{wandb.run.id}-checkpoint", type="model"
)

epoch_progress_bar = tqdm(range(config.max_train_epochs), desc="Training:")

for epoch in epoch_progress_bar:
    model.train()
    epoch_loss = 0

    total_batch_steps = len(train_dataset) // train_loader.batch_size
    batch_progress_bar = tqdm(train_loader, total=total_batch_steps, leave=False)
    
    # íŠ¸ë ˆì´ë‹ ìŠ¤í…
    for batch_data in batch_progress_bar:
        inputs, labels = (
            batch_data["image"].to(device),
            batch_data["label"].to(device),
        )
        optimizer.zero_grad()
        with torch.cuda.amp.autocast():
            outputs = model(inputs)
            loss = loss_function(outputs, labels)
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        epoch_loss += loss.item()
        batch_progress_bar.set_description(f"train_loss: {loss.item():.4f}:")
        ## W&Bì— ë°°ì¹˜ë³„ íŠ¸ë ˆì´ë‹ ì†ì‹¤ ë¡œê·¸í•˜ê¸°
        wandb.log({"batch/batch_step": batch_step, "batch/train_loss": loss.item()})
        batch_step += 1

    lr_scheduler.step()
    epoch_loss /= total_batch_steps
    ## W&Bì— ë°°ì¹˜ë³„ íŠ¸ë ˆì´ë‹ ì†ì‹¤ ë° í•™ìŠµë¥  ë¡œê·¸í•˜ê¸°
    wandb.log(
        {
            "epoch/epoch_step": epoch,
            "epoch/mean_train_loss": epoch_loss,
            "epoch/learning_rate": lr_scheduler.get_last_lr()[0],
        }
    )
    epoch_progress_bar.set_description(f"Training: train_loss: {epoch_loss:.4f}:")

    # ê²€ì¦ ë° ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë‹¨ê³„
    if (epoch + 1) % config.validation_intervals == 0:
        model.eval()
        with torch.no_grad():
            for val_data in val_loader:
                val_inputs, val_labels = (
                    val_data["image"].to(device),
                    val_data["label"].to(device),
                )
                val_outputs = inference(model, val_inputs)
                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]
                dice_metric(y_pred=val_outputs, y=val_labels)
                dice_metric_batch(y_pred=val_outputs, y=val_labels)

            metric_values.append(dice_metric.aggregate().item())
            metric_batch = dice_metric_batch.aggregate()
            metric_values_tumor_core.append(metric_batch[0].item())
            metric_values_whole_tumor.append(metric_batch[1].item())
            metric_values_enhanced_tumor.append(metric_batch[2].item())
            dice_metric.reset()
            dice_metric_batch.reset()

            checkpoint_path = os.path.join(config.checkpoint_dir, "model.pth")
            torch.save(model.state_dict(), checkpoint_path)
            
            # W&B ì•„í‹°íŒ©íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œê·¸ ë° ë²„ì „ ê´€ë¦¬í•˜ê¸°.
            artifact.add_file(local_path=checkpoint_path)
            wandb.log_artifact(artifact, aliases=[f"epoch_{epoch}"])

            # W&B ëŒ€ì‹œë³´ë“œì— ê²€ì¦ ë©”íŠ¸ë¦­ ë¡œê·¸í•˜ê¸°.
            wandb.log(
                {
                    "validation/validation_step": validation_step,
                    "validation/mean_dice": metric_values[-1],
                    "validation/mean_dice_tumor_core": metric_values_tumor_core[-1],
                    "validation/mean_dice_whole_tumor": metric_values_whole_tumor[-1],
                    "validation/mean_dice_enhanced_tumor": metric_values_enhanced_tumor[-1],
                }
            )
            validation_step += 1


# ì´ ì•„í‹°íŒ©íŠ¸ì˜ ë¡œê¹…ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ê¸°
artifact.wait()
```

`wandb.log`ë¡œ ì½”ë“œì— ê³„ì¸¡ì„ ì¶”ê°€í•˜ë©´ íŠ¸ë ˆì´ë‹ ë° ê²€ì¦ í”„ë¡œì„¸ìŠ¤ì™€ ê´€ë ¨ëœ ëª¨ë“  ë©”íŠ¸ë¦­ì„ ì¶”ì í•  ìˆ˜ ìˆì„ ë¿ë§Œ ì•„ë‹ˆë¼ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­(ì´ ê²½ìš° CPU ë° GPU)ë„ W&B ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

| ![W&Bì—ì„œ íŠ¸ë ˆì´ë‹ ë° ê²€ì¦ í”„ë¡œì„¸ìŠ¤ ì¶”ì  ì˜ˆì‹œ.](@site/static/images/tutorials/monai/viz-3.gif) | 
|:--:| 
| **W&Bì—ì„œ íŠ¸ë ˆì´ë‹ ë° ê²€ì¦ í”„ë¡œì„¸ìŠ¤ ì¶”ì  ì˜ˆì‹œ.** |

W&B run ëŒ€ì‹œë³´ë“œì˜ ì•„í‹°íŒ©íŠ¸ íƒ­ìœ¼ë¡œ ì´ë™í•˜ì—¬ íŠ¸ë ˆì´ë‹ ì¤‘ì— ë¡œê·¸ëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì•„í‹°íŒ©íŠ¸ì˜ ë‹¤ì–‘í•œ ë²„ì „ì— ì—‘ì„¸ìŠ¤í•˜ì„¸ìš”.

| ![W&Bì—ì„œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œê¹… ë° ë²„ì „ ê´€ë¦¬ ì˜ˆì‹œ.](@site/static/images/tutorials/monai/viz-4.gif) | 
|:--:| 
| **W&Bì—ì„œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œê¹… ë° ë²„ì „ ê´€ë¦¬ ì˜ˆì‹œ.** |

## ğŸ”± ì¶”ë¡ 

ì•„í‹°íŒ©íŠ¸ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬, ì´ ê²½ìš° í‰ê·  ì—í¬í¬ë³„ íŠ¸ë ˆì´ë‹ ì†ì‹¤ì´ ê°€ì¥ ë‚®ì€ ì•„í‹°íŒ©íŠ¸ ë²„ì „ì„ ìµœê³ ì˜ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¡œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì•„í‹°íŒ©íŠ¸ì˜ ì „ì²´ ê³„ë³´ë¥¼ íƒìƒ‰í•˜ê³  í•„ìš”í•œ ë²„ì „ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

| ![W&Bì—ì„œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì¶”ì  ì˜ˆì‹œ.](@site/static/images/tutorials/monai/viz-5.gif) | 
|:--:| 
| **W&Bì—ì„œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì¶”ì  ì˜ˆì‹œ.** |

ìµœê³ ì˜ ì—í¬í¬ë³„ í‰ê·  íŠ¸ë ˆì´ë‹ ì†ì‹¤ì„ ê°€ì§„ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë²„ì „ì„ ê°€ì ¸ì™€ì„œ ì²´í¬í¬ì¸íŠ¸ ìƒíƒœ ì‚¬ì „ì„ ëª¨ë¸ì— ë¡œë“œí•©ë‹ˆë‹¤.

```python
model_artifact = wandb.use_artifact(
    "geekyrakshit/monai-brain-tumor-segmentation/d5ex6n4a-checkpoint:v49",
    type="model",
)
model_artifact_dir = model_artifact.download()
model.load_state_dict(torch.load(os.path.join(model_artifact_dir, "model.pth")))
model.eval()
```

### ğŸ“¸ ì˜ˆì¸¡ê°’ ì‹œê°í™” ë° ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ ë¼ë²¨ê³¼ ë¹„êµí•˜ê¸°

ëŒ€í™”í˜• ë¶„í•  ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì„ ì‹œê°í™”í•˜ê³  í•´ë‹¹í•˜ëŠ” ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ ë¶„í•  ë§ˆìŠ¤í¬ì™€ ë¹„êµí•˜ëŠ” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë¥¼ ë§Œë“­ë‹ˆë‹¤.

```python
def log_predictions_into_tables(
    sample_image: np.array,
    sample_label: np.array,
    predicted_label: np.array,
    split: str = None,
    data_idx: int = None,
    table: wandb.Table = None,
):
    num_channels, _, _, num_slices = sample_image.shape
    with tqdm(total=num_slices, leave=False) as progress_bar:
        for slice_idx in range(num_slices):
            wandb_images = []
            for channel_idx in range(num_channels):
                wandb_images += [
                    wandb.Image(
                        sample_image[channel_idx, :, :, slice_idx],
                        masks={
                            "ground-truth/Tumor-Core": {
                                "mask_data": sample_label[0, :, :, slice_idx],
                                "class_labels": {0: "background", 1: "Tumor Core"},
                            },
                            "prediction/Tumor-Core": {
                                "mask_data": predicted_label[0, :, :, slice_idx] * 2,
                                "class_labels": {0: "background", 2: "Tumor Core"},
                            },
                        },
                    ),
                    wandb.Image(
                        sample_image[channel_idx, :, :, slice_idx],
                        masks={
                            "ground-truth/Whole-Tumor": {
                                "mask_data": sample_label[1, :, :, slice_idx],
                                "class_labels": {0: "background", 1: "Whole Tumor"},
                            },
                            "prediction/Whole-Tumor": {
                                "mask_data": predicted_label[1, :, :, slice_idx] * 2,
                                "class_labels": {0: "background", 2: "Whole Tumor"},
                            },
                        },
                    ),
                    wandb.Image(
                        sample_image[channel_idx, :, :, slice_idx],
                        masks={
                            "ground-truth/Enhancing-Tumor": {
                                "mask_data": sample_label[2, :, :, slice_idx],
                                "class_labels": {0: "background", 1: "Enhancing Tumor"},
                            },
                            "prediction/Enhancing-Tumor": {
                                "mask_data": predicted_label[2, :, :, slice_idx] * 2,
                                "class_labels": {0: "background", 2: "Enhancing Tumor"},
                            },
                        },
                    ),
                ]
            table.add_data(split, data_idx, slice_idx, *wandb_images)
            progress_bar.update(1)
    return table
```

ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì˜ˆì¸¡ í…Œì´ë¸”ì— ë¡œê·¸í•©ë‹ˆë‹¤.

```python
# ì˜ˆì¸¡ í…Œì´ë¸” ìƒì„±í•˜ê¸°
prediction_table = wandb.Table(
    columns=[
        "Split",
        "Data Index",
        "Slice Index",
        "Image-Channel-0/Tumor-Core",
        "Image-Channel-1/Tumor-Core",
        "Image-Channel-2/Tumor-Core",
        "Image-Channel-3/Tumor-Core",
        "Image-Channel-0/Whole-Tumor",
        "Image-Channel-1/Whole-Tumor",
        "Image-Channel-2/Whole-Tumor",
        "Image-Channel-3/Whole-Tumor",
        "Image-Channel-0/Enhancing-Tumor",
        "Image-Channel-1/Enhancing-Tumor",
        "Image-Channel-2/Enhancing-Tumor",
        "Image-Channel-3/Enhancing-Tumor",
    ]
)

# ì¶”ë¡  ë° ì‹œê°í™” ìˆ˜í–‰í•˜ê¸°
with torch.no_grad():
    config.max_prediction_images_visualized
    max_samples = (
        min(config.max_prediction_images_visualized, len(val_dataset))
        if config.max_prediction_images_visualized > 0
        else len(val_dataset)
    )
    progress_bar = tqdm(
        enumerate(val_dataset[:max_samples]),
        total=max_samples,
        desc="Generating Predictions:",
    )
    for data_idx, sample in progress_bar:
        val_input = sample["image"].unsqueeze(0).to(device)
        val_output = inference(model, val_input)
        val_output = post_trans(val_output[0])
        prediction_table = log_predictions_into_tables(
            sample_image=sample["image"].cpu().numpy(),
            sample_label=sample["label"].cpu().numpy(),
            predicted_label=val_output.cpu().numpy(),
            data_idx=data_idx,
            split="validation",
            table=prediction_table,
        )

    wandb.log({"Predictions/Tumor-Segmentation-Data": prediction_table})


# ì‹¤í—˜ ì¢…ë£Œí•˜ê¸°
wandb.finish()
```

ëŒ€í™”í˜• ë¶„í•  ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° í´ë˜ìŠ¤ì— ëŒ€í•œ ì˜ˆì¸¡ ë¶„í•  ë§ˆìŠ¤í¬ì™€ ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ ë¼ë²¨ì„ ë¶„ì„í•˜ê³  ë¹„êµí•˜ì„¸ìš”.

| ![W&Bì—ì„œ ì˜ˆì¸¡ ë° ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ ì‹œê°í™” ì˜ˆì‹œ.](@site/static/images/tutorials/monai/viz-6.gif) | 
|:--:| 
| **W&Bì—ì„œ ì˜ˆì¸¡ ë° ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ ì‹œê°í™” ì˜ˆì‹œ.** |

## ê°ì‚¬ì˜ ë§ ë° ì¶”ê°€ ìë£Œ

* [MONAI íŠœí† ë¦¬ì–¼: MONAIë¥¼ ì‚¬ìš©í•œ ë‡Œì¢…ì–‘ 3D ë¶„í• ](https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/brats_segmentation_3d.ipynb)
* [WandB ë¦¬í¬íŠ¸: MONAI ë° WandBë¥¼ ì‚¬ìš©í•œ ë‡Œì¢…ì–‘ ë¶„í• ](https://wandb.ai/geekyrakshit/brain-tumor-segmentation/reports/Brain-Tumor-Segmentation-using-MONAI-and-WandB---Vmlldzo0MjUzODIw)