
# ëª¨ë¸ ë“±ë¡í•˜ê¸°

[**Colab ë…¸íŠ¸ë¶ì—ì„œ ì‹œë„í•´ë³´ê¸° â†’**](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-model-registry/Model_Registry_E2E.ipynb)

ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ëŠ” ê¸°ê´€ ì „ë°˜ì— ê±¸ì³ ì‘ì—… ì¤‘ì¸ ëª¨ë“  ëª¨ë¸ ì‘ì—…ê³¼ ê´€ë ¨ ì•„í‹°íŒ©íŠ¸ë¥¼ ì§‘ì¤‘ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ì¡°ì§í•˜ëŠ” ì¤‘ì•™ ì¥ì†Œì…ë‹ˆë‹¤:
- ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬
- í’ë¶€í•œ ëª¨ë¸ ì¹´ë“œë¡œ ëª¨ë¸ ë¬¸ì„œí™”
- ì‚¬ìš©/ë°°í¬ë˜ëŠ” ëª¨ë“  ëª¨ë¸ì˜ ê¸°ë¡ ìœ ì§€
- ëª¨ë¸ì˜ ê¹¨ë—í•œ ì¸ê³„ ë° ë‹¨ê³„ ê´€ë¦¬ ìš©ì´
- ë‹¤ì–‘í•œ ëª¨ë¸ ì‘ì—… íƒœê·¸ ë° ì¡°ì§
- ëª¨ë¸ ì§„í–‰ ì‹œ ìë™ ì•Œë¦¼ ì„¤ì •

ì´ íŠœí† ë¦¬ì–¼ì€ ê°„ë‹¨í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‘ì—…ì— ëŒ€í•œ ëª¨ë¸ ê°œë°œ ë¼ì´í”„ì‚¬ì´í´ì„ ì¶”ì í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

### ğŸ› ï¸ `wandb` ì„¤ì¹˜í•˜ê¸°
 
```bash
!pip install -q wandb onnx pytorch-lightning
```

## W&B ë¡œê·¸ì¸í•˜ê¸°
- `wandb login` ë˜ëŠ” `wandb.login()`ì„ ì‚¬ìš©í•˜ì—¬ ëª…ì‹œì ìœ¼ë¡œ ë¡œê·¸ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ì•„ë˜ ì°¸ì¡°)
- ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. W&B ë¡œê¹…ì˜ ë™ì‘ì„ ë³€ê²½í•  ìˆ˜ ìˆëŠ” ì—¬ëŸ¬ í™˜ê²½ ë³€ìˆ˜ê°€ ìˆìŠµë‹ˆë‹¤. ê°€ì¥ ì¤‘ìš”í•œ ë³€ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
    - `WANDB_API_KEY` - í”„ë¡œí•„ ì•„ë˜ "ì„¤ì •" ì„¹ì…˜ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
    - `WANDB_BASE_URL` - W&B ì„œë²„ì˜ URLì…ë‹ˆë‹¤
- W&B ì•±ì—ì„œ "í”„ë¡œí•„" -> "ì„¤ì •"ì—ì„œ API í† í° ì°¾ê¸°

![api_token](https://drive.google.com/uc?export=view&id=1Xn7hnn0rfPu_EW0A_-32oCXqDmpA0-kx) 

```notebook
!wandb login
```

:::note
**ë°ë””ì¼€ì´í‹°ë“œ í´ë¼ìš°ë“œ** ë˜ëŠ” **ìì²´ ê´€ë¦¬**ì¸ [W&B ì„œë²„](..//guides/hosting/intro.md) ë°°í¬ì— ì—°ê²°í•  ë•ŒëŠ” --relogin ë° --host ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”:

```notebook
!wandb login --relogin --host=http://your-shared-local-host.com
```

í•„ìš”í•œ ê²½ìš° ë°°í¬ ê´€ë¦¬ìì—ê²Œ í˜¸ìŠ¤íŠ¸ ì´ë¦„ì„ ë¬¸ì˜í•˜ì„¸ìš”.
:::

## ë°ì´í„°ì™€ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì•„í‹°íŒ©íŠ¸ë¡œ ë¡œê¹…í•˜ê¸°
W&B ì•„í‹°íŒ©íŠ¸ë¥¼ ì‚¬ìš©í•˜ë©´ ì„ì˜ì˜ ì§ë ¬í™”ëœ ë°ì´í„°(ì˜ˆ: ë°ì´í„°ì„¸íŠ¸, ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸, í‰ê°€ ê²°ê³¼)ë¥¼ ì¶”ì í•˜ê³  ë²„ì „ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„í‹°íŒ©íŠ¸ë¥¼ ìƒì„±í•  ë•Œ ì´ë¦„ê³¼ ìœ í˜•ì„ ì§€ì •í•˜ê³ , í•´ë‹¹ ì•„í‹°íŒ©íŠ¸ëŠ” ì˜ì›íˆ ì‹¤í—˜ ê¸°ë¡ ì‹œìŠ¤í…œì— ì—°ê²°ë©ë‹ˆë‹¤. ê¸°ë³¸ ë°ì´í„°ê°€ ë³€ê²½ë˜ê³  í•´ë‹¹ ë°ì´í„° ìì‚°ì„ ë‹¤ì‹œ ë¡œê¹…í•˜ë©´, W&BëŠ” ë‚´ìš©ì˜ ì²´í¬ì„¬ì„ í†µí•´ ìë™ìœ¼ë¡œ ìƒˆ ë²„ì „ì„ ìƒì„±í•©ë‹ˆë‹¤. W&B ì•„í‹°íŒ©íŠ¸ëŠ” ê³µìœ ë˜ì§€ ì•Šì€ êµ¬ì¡°í™”ëœ íŒŒì¼ ì‹œìŠ¤í…œ ìœ„ì— ìˆëŠ” ê°€ë²¼ìš´ ì¶”ìƒí™” ê³„ì¸µìœ¼ë¡œ ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì•„í‹°íŒ©íŠ¸ì˜ í•´ë¶€í•™

`Artifact` í´ë˜ìŠ¤ëŠ” W&B ì•„í‹°íŒ©íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì˜ í•­ëª©ì— í•´ë‹¹í•©ë‹ˆë‹¤. ì•„í‹°íŒ©íŠ¸ëŠ”
* ì´ë¦„
* ìœ í˜•
* ë©”íƒ€ë°ì´í„°
* ì„¤ëª…
* íŒŒì¼, íŒŒì¼ ë””ë ‰í„°ë¦¬, ë˜ëŠ” ì°¸ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤

ì˜ˆì œ ì‚¬ìš©ë²•:
```python
run = wandb.init(project="my-project")
artifact = wandb.Artifact(name="my_artifact", type="data")
artifact.add_file("/path/to/my/file.txt")
run.log_artifact(artifact)
run.finish()
```

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ì²« ë²ˆì§¸ë¡œ í•™ìŠµ ë°ì´í„°ì„¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  í•™ìŠµ ì‘ì—…ì—ì„œ í•˜ë¥˜ë¡œ ì‚¬ìš©í•  ì•„í‹°íŒ©íŠ¸ë¡œ ë¡œê¹…í•©ë‹ˆë‹¤.

```python
# @title W&B í”„ë¡œì íŠ¸ì™€ ì—”í‹°í‹° ì…ë ¥

# í¼ ë³€ìˆ˜
PROJECT_NAME = "model-registry-tutorial"  # @param {type:"string"}
ENTITY = None  # @param {type:"string"}

# ë‹¤ìŒ ì„¸ ê°€ì§€ ë°ì´í„°ì„¸íŠ¸ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ë ¤ë©´ SIZEë¥¼ "TINY", "SMALL", "MEDIUM", ë˜ëŠ” "LARGE"ë¡œ ì„¤ì •í•˜ì„¸ìš”
# TINY ë°ì´í„°ì„¸íŠ¸: 100ê°œì˜ ì´ë¯¸ì§€, 30MB
# SMALL ë°ì´í„°ì„¸íŠ¸: 1000ê°œì˜ ì´ë¯¸ì§€, 312MB
# MEDIUM ë°ì´í„°ì„¸íŠ¸: 5000ê°œì˜ ì´ë¯¸ì§€, 1.5GB
# LARGE ë°ì´í„°ì„¸íŠ¸: 12,000ê°œì˜ ì´ë¯¸ì§€, 3.6GB

SIZE = "TINY"

if SIZE == "TINY":
    src_url = "https://storage.googleapis.com/wandb_datasets/nature_100.zip"
    src_zip = "nature_100.zip"
    DATA_SRC = "nature_100"
    IMAGES_PER_LABEL = 10
    BALANCED_SPLITS = {"train": 8, "val": 1, "test": 1}
elif SIZE == "SMALL":
    src_url = "https://storage.googleapis.com/wandb_datasets/nature_1K.zip"
    src_zip = "nature_1K.zip"
    DATA_SRC = "nature_1K"
    IMAGES_PER_LABEL = 100
    BALANCED_SPLITS = {"train": 80, "val": 10, "test": 10}
elif SIZE == "MEDIUM":
    src_url = "https://storage.googleapis.com/wandb_datasets/nature_12K.zip"
    src_zip = "nature_12K.zip"
    DATA_SRC = "inaturalist_12K/train"  # (ì‹¤ì œë¡œëŠ” 10K ì´ë¯¸ì§€ë§Œ í¬í•¨ëœ ì„œë¸Œì„¸íŠ¸)
    IMAGES_PER_LABEL = 500
    BALANCED_SPLITS = {"train": 400, "val": 50, "test": 50}
elif SIZE == "LARGE":
    src_url = "https://storage.googleapis.com/wandb_datasets/nature_12K.zip"
    src_zip = "nature_12K.zip"
    DATA_SRC = "inaturalist_12K/train"  # (ì‹¤ì œë¡œëŠ” 10K ì´ë¯¸ì§€ë§Œ í¬í•¨ëœ ì„œë¸Œì„¸íŠ¸)
    IMAGES_PER_LABEL = 1000
    BALANCED_SPLITS = {"train": 800, "val": 100, "test": 100}
```


```notebook
%%capture
!curl -SL $src_url > $src_zip
!unzip $src_zip
```


```python
import wandb
import pandas as pd
import os

with wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type="log_datasets") as run:
    img_paths = []
    for root, dirs, files in os.walk("nature_100", topdown=False):
        for name in files:
            img_path = os.path.join(root, name)
            label = img_path.split("/")[1]
            img_paths.append([img_path, label])

    index_df = pd.DataFrame(columns=["image_path", "label"], data=img_paths)
    index_df.to_csv("index.csv", index=False)

    train_art = wandb.Artifact(
        name="Nature_100",
        type="raw_images",
        description="10 í´ë˜ìŠ¤ë‹¹ 10ê°œ ì´ë¯¸ì§€ë¥¼ í¬í•¨í•˜ëŠ” ìì—° ì´ë¯¸ì§€ ë°ì´í„°ì„¸íŠ¸",
    )
    train_art.add_dir("nature_100")

    # ê° ì´ë¯¸ì§€ì˜ ë ˆì´ë¸”ì„ ë‚˜íƒ€ë‚´ëŠ” csvë„ ì¶”ê°€
    train_art.add_file("index.csv")
    wandb.log_artifact(train_art)
```

### ì•„í‹°íŒ©íŠ¸ ì´ë¦„ê³¼ ë³„ì¹­ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ìì‚°ì„ ì‰½ê²Œ ì¸ê³„í•˜ê³  ì¶”ìƒí™”í•˜ê¸°
- ë°ì´í„°ì„¸íŠ¸ë‚˜ ëª¨ë¸ì˜ `ì´ë¦„:ë³„ì¹­` ì¡°í•©ì„ ë‹¨ìˆœíˆ ì°¸ì¡°í•¨ìœ¼ë¡œì¨ ì›Œí¬í”Œë¡œì˜ êµ¬ì„± ìš”ì†Œë¥¼ ë” í‘œì¤€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ì˜ˆë¥¼ ë“¤ì–´, W&B ì•„í‹°íŒ©íŠ¸ ì´ë¦„ê³¼ ë³„ì¹­ì„ ì¸ìˆ˜ë¡œ ë°›ì•„ ì ì ˆíˆ ë¡œë“œí•˜ëŠ” PyTorch `Dataset` ë˜ëŠ” `DataModule`ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

ì´ì œ ì´ ë°ì´í„°ì„¸íŠ¸ì™€ ì´ë¥¼ ì‚¬ìš©í•˜ëŠ” W&B ì‹¤í–‰, ê·¸ë¦¬ê³  ìƒë¥˜ ë° í•˜ë¥˜ ì•„í‹°íŒ©íŠ¸ì˜ ì „ì²´ ê³„ë³´ì™€ ê´€ë ¨ëœ ëª¨ë“  ë©”íƒ€ë°ì´í„°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

![api_token](https://drive.google.com/uc?export=view&id=1fEEddXMkabgcgusja0g8zMz8whlP2Y5P) 

```python
from torchvision import transforms
import pytorch_lightning as pl
import torch
from torch.utils.data import Dataset, DataLoader, random_split
from skimage import io, transform
from torchvision import transforms, utils, models
import math


class NatureDataset(Dataset):
    def __init__(
        self,
        wandb_run,
        artifact_name_alias="Nature_100:latest",
        local_target_dir="Nature_100:latest",
        transform=None,
    ):
        self.local_target_dir = local_target_dir
        self.transform = transform

        # ì•„í‹°íŒ©íŠ¸ë¥¼ ë¡œì»¬ë¡œ ê°€ì ¸ì™€ ë©”ëª¨ë¦¬ì— ë¡œë“œ
        art = wandb_run.use_artifact(artifact_name_alias)
        path_at = art.download(root=self.local_target_dir)

        self.ref_df = pd.read_csv(os.path.join(self.local_target_dir, "index.csv"))
        self.class_names = self.ref_df.iloc[:, 1].unique().tolist()
        self.idx_to_class = {k: v for k, v in enumerate(self.class_names)}
        self.class_to_idx = {v: k for k, v in enumerate(self.class_names)}

    def __len__(self):
        return len(self.ref_df)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        img_path = self.ref_df.iloc[idx, 0]

        image = io.imread(img_path)
        label = self.ref_df.iloc[idx, 1]
        label = torch.tensor(self.class_to_idx[label], dtype=torch.long)

        if self.transform:
            image = self.transform(image)

        return image, label


class NatureDatasetModule(pl.LightningDataModule):
    def __init__(
        self,
        wandb_run,
        artifact_name_alias: str = "Nature_100:latest",
        local_target_dir: str = "Nature_100:latest",
        batch_size: int = 16,
        input_size: int = 224,
        seed: int = 42,
    ):
        super().__init__()
        self.wandb_run = wandb_run
        self.artifact_name_alias = artifact_name_alias
        self.local_target_dir = local_target_dir
        self.batch_size = batch_size
        self.input_size = input_size
        self.seed = seed

    def setup(self, stage=None):
        self.nature_dataset = NatureDataset(
            wandb_run=self.wandb_run,
            artifact_name_alias=self.artifact_name_alias,
            local_target_dir=self.local_target_dir,
            transform=transforms.Compose(
                [
                    transforms.ToTensor(),
                    transforms.CenterCrop(self.input_size),
                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
                ]
            ),
        )

        nature_length = len(self.nature_dataset)
        train_size = math.floor(0.8 * nature_length)
        val_size = math.floor(0.2 * nature_length)
        self.nature_train, self.nature_val = random_split(
            self.nature_dataset,
            [train_size, val_size],
            generator=torch.Generator().manual_seed(self.seed),
        )
        return self

    def train_dataloader(self):
        return DataLoader(self.nature_train, batch_size=self.batch_size)

    def val_dataloader(self):
        return DataLoader(self.nature_val, batch_size=self.batch_size)

    def predict_dataloader(self):
        pass

    def teardown(self, stage: str):
        pass
```

## ëª¨ë¸ í•™ìŠµ

### ëª¨ë¸ í´ë˜ìŠ¤ì™€ ê²€ì¦ í•¨ìˆ˜ ì‘ì„±í•˜ê¸°

```python
import torch.nn.functional as F
import torch.optim as optim
from torch.optim.lr_scheduler import StepLR
import onnx


def set_parameter_requires_grad(model, feature_extracting):
    if feature_extracting:
        for param in model.parameters():
            param.requires_grad = False


def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):
    # ì´ if ë¬¸ì—ì„œ ì„¤ì •ë  ë³€ìˆ˜ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ê° ë³€ìˆ˜ëŠ” ëª¨ë¸ë³„ë¡œ íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    model_ft = None
    input_size = 0

    if model_name == "resnet":
        """Resnet18"""
        model_ft = models.resnet18(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = torch.nn.Linear(num_ftrs, num_classes)
        input_size = 224

    elif model_name == "alexnet":
        """Alexnet"""
        model_ft = models.alexnet(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.classifier[6].in_features
        model_ft.classifier[6] = torch.nn.Linear(num_ftrs, num_classes)
        input_size = 224

    elif model_name == "vgg":
        """VGG11_bn"""
        model_ft = models.vgg11_bn(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.classifier[6].in_features
        model_ft.classifier[6] = torch.nn.Linear(num_ftrs, num_classes)
        input_size = 224

    elif model_name == "squeezenet":
        """Squeezenet"""
        model_ft = models.squeezenet1_0(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        model_ft.classifier[1] = torch.nn.Conv2d(
            512, num_classes, kernel_size=(1, 1), stride=(1, 1)
        )
        model_ft.num_classes = num_classes
        input_size = 224

    elif model_name == "densenet":
        """Densenet"""
        model_ft = models.densenet121(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.classifier.in_features
        model_ft.classifier = torch.nn.Linear(num_ftrs, num_classes)
        input_size = 224

    else:
        print("ì˜ëª»ëœ ëª¨ë¸ ì´ë¦„, ì¢…ë£Œ...")
        exit()

    return model_ft, input_size


class NaturePyTorchModule(torch.nn.Module):
    def __init__(self, model_name, num_classes=10, feature_extract=True, lr=0.01):
        """ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ì •ì˜í•˜ëŠ” ë©”ì„œë“œ"""
        super().__init__()

        self.model_name = model_name
        self.num_classes = num_classes
        self.feature_extract = feature_extract
        self.lr = lr
        self.model, self.input_size = initialize_model(
            model_name=self.model_name,
            num_classes=self.num_classes,
            feature_extract=True,
        )

    def forward(self, x):
        """ì¶”ë¡ ì„ ìœ„í•œ ë©”ì„œë“œ input -> output"""
        x = self.model(x)

        return x


def evaluate_model(model, eval_data, idx_to_class, class_names, epoch_ndx):
    device = torch.device("cpu")
    model.eval()
    test_loss = 0
    correct = 0
    preds = []
    actual = []

    val_table = wandb.Table(columns=["pred", "actual", "image"])

    with torch.no_grad():
        for data, target in eval_data:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.nll_loss(
                output, target, reduction="sum"
            ).item()  # ë°°ì¹˜ ì†ì‹¤ í•©ê³„
            pred = output.argmax(
                dim=1, keepdim=True
            )  # ìµœëŒ€ ë¡œê·¸-í™•ë¥ ì˜ ì¸ë±ìŠ¤ë¥¼ ì–»ìŒ
            preds += list(pred.flatten().tolist())
            actual += target.numpy().tolist()
            correct += pred.eq(target.view_as(pred)).sum().item()

            for idx, img in enumerate(data):
                img = img.numpy().transpose(1, 2, 0)
                pred_class = idx_to_class[pred.numpy()[idx][0]]
                target_class = idx_to_class[target.numpy()[idx]]
                val_table.add_data(pred_class, target_class, wandb.Image(img))

    test_loss /= len(eval_data.dataset)
    accuracy = 100.0 * correct / len(eval_data.dataset)
    conf_mat = wandb.plot.confusion_matrix(
        y_true=actual, preds=preds, class_names=class_names
    )
    return test_loss, accuracy, preds, val_table, conf_mat
```

### í•™ìŠµ ë£¨í”„ ì¶”ì í•˜ê¸°
í•™ìŠµ ì¤‘ì—ëŠ” ëª¨ë¸ì„ ì‹œê°„ì— ë”°ë¼ ì²´í¬í¬ì¸íŠ¸í•˜ëŠ” ê²ƒì´ ëª¨ë²” ì‚¬ë¡€ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í•™ìŠµì´ ì¤‘ë‹¨ë˜ê±°ë‚˜ ì¸ìŠ¤í„´ìŠ¤ê°€ ì¶©ëŒí•˜ëŠ” ê²½ìš° ì¤‘ë‹¨ëœ ì§€ì ë¶€í„° ë‹¤ì‹œ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„í‹°íŒ©íŠ¸ ë¡œê¹…ì„ ì‚¬ìš©í•˜ë©´ W&Bì—ì„œ ëª¨ë“  ì²´í¬í¬ì¸íŠ¸ë¥¼ ì¶”ì í•˜ê³  ì›í•˜ëŠ” ë©”íƒ€ë°ì´í„°(ì§ë ¬í™” í˜•ì‹, í´ë˜ìŠ¤ ë ˆì´ë¸” ë“±)ë¥¼ ì²¨ë¶€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë©´ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ì‚¬ëŒì´ ì‚¬ìš© ë°©ë²•ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–´ë–¤ í˜•íƒœì˜ ëª¨ë¸ì„ ì•„í‹°íŒ©íŠ¸ë¡œ ë¡œê¹…í•  ë•ŒëŠ” ì•„í‹°íŒ©íŠ¸ì˜ `type`ì„ `model`ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.

```python
run = wandb.init(
    project=PROJECT_NAME,
    entity=ENTITY,
    job_type="training",
    config={
        "model_type": "squeezenet",
        "lr": 1.0,
        "gamma": 0.75,
        "batch_size": 16,
        "epochs": 5,
    },
)

model = NaturePyTorchModule(wandb.config["model_type"])
wandb.watch(model)

wandb.config["input_size"] = 224

nature_module = NatureDatasetModule(
    wandb_run=run,
    artifact_name_alias="Nature_100:latest",
    local_target_dir="Nature_100:latest",
    batch_size=wandb.config["batch_size"],
    input_size=wandb.config["input_size"],
)
nature_module.setup()

# ëª¨ë¸ í•™ìŠµ
learning_rate = wandb.config["lr"]
gamma = wandb.config["gamma"]
epochs = wandb.config["epochs"]

device = torch.device("cpu")
optimizer = optim.Adadelta(model.parameters(), lr=wandb.config["lr"])
scheduler = StepLR(optimizer, step_size=1, gamma=wandb.config["gamma"])

best_loss = float("inf")
best_model = None

for epoch_ndx in range(epochs):
    model.train()
    for batch_ndx, batch in enumerate(nature_module.train_dataloader()):
        data, target = batch[0].to("cpu"), batch[1].to("cpu")
        optimizer.zero_grad()
        preds = model(data)
        loss = F.nll_loss(preds, target)
        loss.backward()
        optimizer.step()
        scheduler.step()

        ### ë©”íŠ¸ë¦­ ë¡œê¹… ###
        wandb.log(
            {
                "train/epoch_ndx": epoch_ndx,
                "train/batch_ndx": batch_ndx,
                "train/train_loss": loss,
                "train/learning_rate": optimizer.param_groups[0]["lr"],
            }
        )

    ### ê° ì—í¬í¬ì˜ ëì—ì„œ í‰ê°€ ###
    model.eval()
    test_loss, accuracy, preds, val_table, conf_mat = evaluate_model(
        model,
        nature_module.val_dataloader(),
        nature_module.nature_dataset.idx_to_class,
        nature_module.nature_dataset.class_names,
        epoch_ndx,
    )

    is_best = test_loss < best_loss

    wandb.log(
        {
            "eval/test_loss": test_loss,
            "eval/accuracy": accuracy,
            "eval/conf_mat": conf_mat,
            "eval/val_table": val_table,
        }
    )

    ### ëª¨ë¸ ê°€ì¤‘ì¹˜ ì²´í¬í¬ì¸íŠ¸ ###
    x = torch.randn(1, 3, 224, 224, requires_grad=True)
    torch.onnx.export(
        model,  # ì‹¤í–‰ë˜ëŠ” ëª¨ë¸
        x,  # ëª¨ë¸ ì…ë ¥ (ë˜ëŠ” ì—¬ëŸ¬ ì…ë ¥ì˜ ê²½ìš° íŠœí”Œ)
        "model.onnx",  # ëª¨ë¸ì„ ì €ì¥í•  ìœ„ì¹˜ (íŒŒì¼ ë˜ëŠ” íŒŒì¼ê³¼ ìœ ì‚¬í•œ ê°ì²´)
        export_params=True,  # ëª¨ë¸ íŒŒì¼ ë‚´ì— í›ˆë ¨ëœ íŒŒë¼ë¯¸í„° ê°€ì¤‘ì¹˜ë¥¼ ì €ì¥
        opset_version=10,  # ëª¨ë¸ì„ ë‚´ë³´ë‚¼ ONNX ë²„ì „
        do_constant_folding=True,  # ìµœì í™”ë¥¼ ìœ„í•´ ìƒìˆ˜ í´ë”©ì„ ì‹¤í–‰í• ì§€ ì—¬ë¶€
        input_names=["input"],  # ëª¨ë¸ì˜ ì…ë ¥ ì´ë¦„
        output_names=["output"],  # ëª¨ë¸ì˜ ì¶œë ¥ ì´ë¦„
        dynamic_axes={
            "input": {0: "batch_size"},  # ê°€ë³€ ê¸¸ì´ ì¶•
            "output": {0: "batch_size"},
        },
    )

    art = wandb.Artifact(
        f"nature-{wandb.run.id}",
        type="model",
        metadata={
            "format": "onnx",
            "num_classes": len(nature_module.nature_dataset.class_names),
            "model_type": wandb.config["model_type"],
            "model_input_size": wandb.config["input_size"],
            "index_to_class": nature_module.nature_dataset.idx_to_class,
        },
    )

    art.add_file("model.onnx")

    ### ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ìµœê³ ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì¶”ì í•˜ê¸° ìœ„í•´ ë³„ì¹­ ì¶”ê°€
    wandb.log_artifact(art, aliases=["best", "latest"] if is_best else None)
    if is_best:
        best_model = art
```

### í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ í•œ ê³³ì—ì„œ ê´€ë¦¬í•˜ì„¸ìš”.

![api_token](https://drive.google.com/uc?export=view&id=1z7nXRgqHTPYjfR1SoP-CkezyxklbAZlM)

### ì°¸ê³ : W&B ì˜¤í”„ë¼ì¸ ë™ê¸°í™”
í•™ìŠµ ê³¼ì • ì¤‘ ì–´ë–¤ ì´ìœ ë¡œë“  ë„¤íŠ¸ì›Œí¬ í†µì‹ ì´ ëŠê¸´ ê²½ìš°, ì–¸ì œë“ ì§€ `wandb sync`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ìƒí™©ì„ ë™ê¸°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

W&B sdkëŠ” ëª¨ë“  ë¡œê·¸ëœ ë°ì´í„°ë¥¼ ë¡œì»¬ `wandb` ë””ë ‰í„°ë¦¬ì— ìºì‹œí•˜ê³  `wandb sync`ë¥¼ í˜¸ì¶œí•˜ë©´ ë¡œì»¬ ìƒíƒœë¥¼ ì›¹ ì•±ê³¼ ë™ê¸°í™”í•©ë‹ˆë‹¤.

## ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
ì‹¤í—˜ ì¤‘ ì—¬ëŸ¬ ì‹¤í–‰ì—ì„œ ë§ì€ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œê¹…í•œ í›„, ì´ì œ ì›Œí¬í”Œë¡œì˜ ë‹¤ìŒ ë‹¨ê³„(ì˜ˆ: í…ŒìŠ¤íŠ¸, ë°°í¬)ë¡œ ìµœê³ ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë„˜ê²¨ì¤„ ì‹œê°„ì…ë‹ˆë‹¤.

ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ëŠ” ê°œë³„ W&B í”„ë¡œì íŠ¸ ìœ„ì— ì¡´ì¬í•˜ëŠ” ì¤‘ì•™ í˜ì´ì§€ì…ë‹ˆë‹¤. **ë“±ë¡ëœ ëª¨ë¸**ì„ ë³´ìœ í•œ í¬íŠ¸í´ë¦¬ì˜¤ëŠ” ê°œë³„ W&B í”„ë¡œì íŠ¸ì—ì„œ ì‚´ì•„ ìˆëŠ” ê°€ì¹˜ ìˆëŠ” ì²´í¬í¬ì¸íŠ¸ì— ëŒ€í•œ "ë§í¬"ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ëŠ” ëª¨ë“  ëª¨ë¸ ì‘ì—…ì— ëŒ€í•œ ìµœê³ ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë³´ê´€í•˜ëŠ” ì¤‘ì•™ ì¥ì†Œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë¡œê¹…í•œ ëª¨ë“  `model` ì•„í‹°íŒ©íŠ¸ëŠ” **ë“±ë¡ëœ ëª¨ë¸**ì— "ë§í¬"ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### UIë¥¼ í†µí•œ **ë“±ë¡ëœ ëª¨ë¸** ìƒì„± ë° ë§í¬

#### 1. íŒ€ í˜ì´ì§€ë¡œ ì´ë™í•˜ì—¬ `Model Registry`ë¥¼ ì„ íƒí•˜ì—¬ íŒ€ì˜ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì—‘ì„¸ìŠ¤í•˜ì„¸ìš”.

![model registry](https://drive.google.com/uc?export=view&id=1ZtJwBsFWPTm4Sg5w8vHhRpvDSeQPwsKw)

#### 2. ìƒˆë¡œìš´ ë“±ë¡ëœ ëª¨ë¸ì„ ìƒì„±í•˜ì„¸ìš”.

![model registry](https://drive.google.com/uc?export=view&id=1RuayTZHNE0LJCxt1t0l6-2zjwiV4aDXe)

#### 3. ëª¨ë“  ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë³´ìœ í•œ í”„ë¡œì íŠ¸ì˜ ì•„í‹°íŒ©íŠ¸ íƒ­ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.

![model registry](https://drive.google.com/uc?export=view&id=1LfTLrRNpBBPaUb_RmBIE7fWFMG0h3e0E)

#### 4. ì›í•˜ëŠ” ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë²„ì „ì— ëŒ€í•´ "Link to Registry"ë¥¼ í´ë¦­í•˜ì„¸ìš”.

### **API**ë¥¼ í†µí•œ ë“±ë¡ëœ ëª¨ë¸ ìƒì„± ë° ë§í¬
`wandb.run.link_artifact`ë¥¼ í˜¸ì¶œí•˜ê³  ì•„í‹°íŒ©íŠ¸ ê°œì²´ì™€ **ë“±ë¡ëœ ëª¨ë¸**ì˜ ì´ë¦„ì„ ì „ë‹¬í•˜ì—¬ [ëª¨ë¸ì„ APIë¥¼ í†µí•´ ë§í¬](https://docs.wandb.ai/guides/models)í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ì¶”ê°€í•˜ê³ ì í•˜ëŠ” ë³„ì¹­ë„ í¬í•¨ë©ë‹ˆë‹¤. **ë“±ë¡ëœ ëª¨ë¸**ì€ W&Bì—ì„œ ì—”í‹°í‹°(íŒ€) ë²”ìœ„ì´ë¯€ë¡œ íŒ€ì˜ ë©¤ë²„ë§Œ í•´ë‹¹ ì—”í‹°í‹°ì˜ **ë“±ë¡ëœ ëª¨ë¸**ì„ ë³¼ ìˆ˜ ìˆê³  ì—‘ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. apië¥¼ í†µí•´ ë“±ë¡ëœ ëª¨ë¸ ì´ë¦„ì„ `<entity>/model-registry/<registered-model-name>`ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤. ë“±ë¡ëœ ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš° ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.

```python
if ENTITY:
    wandb.run.link_artifact(
        best_model,
        f"{ENTITY}/model-registry/Model Registry Tutorial",
        aliases=["staging"],
    )
else:
    print("Must indicate entity where Registered Model will exist")
wandb.finish()
```

### "ë§í¬"ë€ ë¬´ì—‡ì¸ê°€ìš”?
ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë§í¬í•˜ë©´ í•´ë‹¹ í”„ë¡œì íŠ¸ì—ì„œ ì‚´ì•„ ìˆëŠ” ì•„í‹°íŒ©íŠ¸ ë²„ì „ì„ ê°€ë¦¬í‚¤ëŠ” ë“±ë¡ëœ ëª¨ë¸ì˜ ìƒˆ ë²„ì „ì´ ìƒì„±ë©ë‹ˆë‹¤. W&Bê°€ í”„ë¡œì íŠ¸ ë‚´ì˜ ì•„í‹°íŒ©íŠ¸ ë²„ì „ ê´€ë¦¬ì™€ ë“±ë¡ëœ ëª¨ë¸ì˜ ë²„ì „ ê´€ë¦¬ë¥¼ ë¶„ë¦¬í•˜ëŠ” ì´ìœ ê°€ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë²„ì „ì„ ë§í¬í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ëŠ” ë“±ë¡ëœ ëª¨ë¸ ì‘ì—… ì•„ë˜ì—ì„œ í•´ë‹¹ ì•„í‹°íŒ©íŠ¸ ë²„ì „ì„ "ë¶ë§ˆí‚¹"í•˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.

ì¼ë°˜ì ìœ¼ë¡œ R&D/ì‹¤í—˜ ì¤‘ì— ì—°êµ¬ìë“¤ì€ ìˆ˜ë°±, ì•„ë‹ˆë©´ ìˆ˜ì²œ ê°œì˜ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ìƒì„±í•˜ì§€ë§Œ, ì‹¤ì œë¡œ "ë¹›ì„ ë³´ëŠ”" ê²ƒì€ í•œë‘ ê°œì— ë¶ˆê³¼í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë³„ë„ì˜ ë²„ì „ ê´€ë¦¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë§í¬í•˜ëŠ” ê³¼ì •ì€ ëª¨ë¸ ê°œë°œ ì¸¡ë©´ê³¼ ëª¨ë¸ ë°°í¬/ì†Œë¹„ ì¸¡ë©´ì˜ ì›Œí¬í”Œë¡œë¥¼ êµ¬ë¶„í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ëª¨ë¸ì˜ ì „ ì„¸ê³„ì ìœ¼ë¡œ ì´í•´ë˜ëŠ” ë²„ì „/ë³„ì¹­ì€ R&Dì—ì„œ ìƒì„±ë˜ëŠ” ëª¨ë“  ì‹¤í—˜ì  ë²„ì „ìœ¼ë¡œë¶€í„° ì˜¤ì—¼ë˜ì§€ ì•Šì•„ì•¼ í•˜ë¯€ë¡œ ë“±ë¡ëœ ëª¨ë¸ì˜ ë²„ì „ì€ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œê¹… ëŒ€ì‹  ìƒˆë¡œ "ë¶ë§ˆí¬ëœ" ëª¨ë¸ì— ë”°ë¼ ì¦ê°€í•´ì•¼ í•©ë‹ˆë‹¤.

## ëª¨ë“  ëª¨ë¸ì„ ìœ„í•œ ì¤‘ì•™ ì§‘ì¤‘ì‹ í—ˆë¸Œ ìƒì„±
- ë“±ë¡ëœ ëª¨ë¸ì— ëª¨ë¸ ì¹´ë“œ, íƒœê·¸, ìŠ¬ë™ ì•Œë¦¼ ì¶”ê°€
- ëª¨ë¸ì´ ë‹¤ë¥¸ ë‹¨ê³„ë¥¼ ê±°ì¹˜ë©´ì„œ ë³„ì¹­ ë³€ê²½
- ëª¨ë¸ ë¬¸ì„œì™€ íšŒê·€ ë¦¬í¬íŠ¸ë¥¼ ìœ„í•´ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ ë¦¬í¬íŠ¸ì— í¬í•¨ì‹œí‚¤ì„¸ìš”. ì´ [ì˜ˆì‹œ](https://api.wandb.ai/links/wandb-smle/r82bj9at) ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.
![model registry](https://drive.google.com/uc?export=view&id=1lKPgaw-Ak4WK_91aBMcLvUMJL6pDQpgO)

### ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ìƒˆ ëª¨ë¸ì´ ë§í¬ë  ë•Œ ìŠ¬ë™ ì•Œë¦¼ ì„¤ì •

![model registry](https://drive.google.com/uc?export=view&id=1RsWCa6maJYD5y34gQ0nwWiKSWUCqcjT9)

## ë“±ë¡ëœ ëª¨ë¸ ì‚¬ìš©
ì´ì œ í•´ë‹¹ `name:alias`ë¥¼ ì°¸ì¡°í•˜ì—¬ APIë¥¼ í†µí•´ ë“±ë¡ëœ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ ì†Œë¹„ì, ì—”ì§€ë‹ˆì–´, ì—°êµ¬ì ë˜ëŠ” CI/CD í”„ë¡œì„¸ìŠ¤ê°€ ë˜ì—ˆë“ , ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ê±°ì¹˜ê±°ë‚˜ í”„ë¡œë•ì…˜ìœ¼ë¡œ ì´ë™í•´ì•¼ í•˜ëŠ” ëª¨ë“  ëª¨ë¸ì˜ ì¤‘ì•™ í—ˆë¸Œë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```notebook
%%wandb -h 600

run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type='inference')
artifact = run.use_artifact(f'{ENTITY}/model-registry/Model Registry Tutorial:staging', type='model')
artifact_dir = artifact.download()
wandb.finish()
```

# ë‹¤ìŒ ë‹¨ê³„ëŠ”?
ë‹¤ìŒ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” W&B Promptsë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ë°˜ë³µí•˜ê³  ë””ë²„ê¹…í•˜ëŠ” ë°©ë²•ì„ ë°°ìš°ê²Œ ë©ë‹ˆë‹¤:

## ğŸ‘‰ [LLMs ë°˜ë³µí•˜ê¸°](prompts)