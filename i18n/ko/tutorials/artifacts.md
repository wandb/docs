
# ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ ì¶”ì í•˜ê¸°

[**ì—¬ê¸°ì—ì„œ Colab ë…¸íŠ¸ë¶ìœ¼ë¡œ ì‹œë„í•´ ë³´ì„¸ìš” â†’**](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-artifacts/Pipeline_Versioning_with_W&B_Artifacts.ipynb)

ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” W&B ì•„í‹°íŒ©íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ML ì‹¤í—˜ íŒŒì´í”„ë¼ì¸ì„ ì¶”ì í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.

### [ë¹„ë””ì˜¤ íŠœí† ë¦¬ì–¼](http://tiny.cc/wb-artifacts-video)ì„ ë”°ë¼ í•´ë³´ì„¸ìš”!

### ğŸ¤” ì•„í‹°íŒ©íŠ¸ëŠ” ë¬´ì—‡ì´ê³  ì™œ ì¤‘ìš”í•œê°€ìš”?

"ì•„í‹°íŒ©íŠ¸"ëŠ” ê·¸ë¦¬ìŠ¤ [ì•”í¬ë¼ ğŸº](https://en.wikipedia.org/wiki/Amphora)ì™€ ê°™ì´ ìƒì„±ëœ ì˜¤ë¸Œì íŠ¸ì…ë‹ˆë‹¤ -- í”„ë¡œì„¸ìŠ¤ì˜ ì¶œë ¥ë¬¼ì…ë‹ˆë‹¤.
MLì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì•„í‹°íŒ©íŠ¸ëŠ” _ë°ì´í„°ì…‹_ê³¼ _ëª¨ë¸_ì…ë‹ˆë‹¤.

ê·¸ë¦¬ê³  [ì½”ë¡œë‚˜ë„ì˜ ì‹­ìê°€](https://indianajones.fandom.com/wiki/Cross_of_Coronado)ì²˜ëŸ¼, ì´ ì¤‘ìš”í•œ ì•„í‹°íŒ©íŠ¸ëŠ” ë°•ë¬¼ê´€ì— ì†í•©ë‹ˆë‹¤!
ì¦‰, ì¹´íƒˆë¡œê·¸í™”ë˜ì–´ ì¡°ì§í™”ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
ê·¸ë˜ì„œ ë‹¹ì‹ , ë‹¹ì‹ ì˜ íŒ€, ê·¸ë¦¬ê³  ML ì»¤ë®¤ë‹ˆí‹° ì „ì²´ê°€ ê·¸ê²ƒë“¤ë¡œë¶€í„° ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ê²°êµ­, íŠ¸ë ˆì´ë‹ì„ ì¶”ì í•˜ì§€ ì•ŠëŠ” ì´ë“¤ì€ ê·¸ê²ƒì„ ë°˜ë³µí•˜ê²Œ ë©ë‹ˆë‹¤.

ìš°ë¦¬ì˜ ì•„í‹°íŒ©íŠ¸ APIë¥¼ ì‚¬ìš©í•˜ì—¬, ë‹¹ì‹ ì€ W&B `Run`ì˜ ì¶œë ¥ë¬¼ë¡œ `ì•„í‹°íŒ©íŠ¸`ë¥¼ ë¡œê·¸í•˜ê±°ë‚˜ `Run`ì— ì…ë ¥ìœ¼ë¡œ `ì•„í‹°íŒ©íŠ¸`ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤, ì´ ë‹¤ì´ì–´ê·¸ë¨ì—ì„œì²˜ëŸ¼,
ì—¬ê¸°ì„œ íŠ¸ë ˆì´ë‹ runì€ ë°ì´í„°ì…‹ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
 
 ![](https://gblobscdn.gitbook.com/assets%2F-Lqya5RvLedGEWPhtkjU%2F-M94QAXA-oJmE6q07_iT%2F-M94QJCXLeePzH1p_fW1%2Fsimple%20artifact%20diagram%202.png?alt=media&token=94bc438a-bd3b-414d-a4e4-aa4f6f359f21)

í•˜ë‚˜ì˜ runì´ ë‹¤ë¥¸ runì˜ ì¶œë ¥ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, ì•„í‹°íŒ©íŠ¸ì™€ Runì€ ë°©í–¥ì„± ê·¸ë˜í”„ -- ì‹¤ì œë¡œëŠ” ì´ë¶„ [DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph)! -- ë¥¼ í˜•ì„±í•˜ë©°, ë…¸ë“œëŠ” `ì•„í‹°íŒ©íŠ¸`ì™€ `Run`ì— ëŒ€í•œ ê²ƒì´ê³ 
í™”ì‚´í‘œëŠ” `Run`ì´ ì†Œë¹„í•˜ê±°ë‚˜ ìƒì„±í•˜ëŠ” `ì•„í‹°íŒ©íŠ¸`ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.

# 0ï¸âƒ£ ì„¤ì¹˜ ë° ê°€ì ¸ì˜¤ê¸°

ì•„í‹°íŒ©íŠ¸ëŠ” ìš°ë¦¬ì˜ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì¼ë¶€ì´ë©°, ë²„ì „ `0.9.2`ë¶€í„° ì‹œì‘ë©ë‹ˆë‹¤.

ëŒ€ë¶€ë¶„ì˜ ML Python ìŠ¤íƒê³¼ ë§ˆì°¬ê°€ì§€ë¡œ, `pip`ë¥¼ í†µí•´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


```python
# wandb ë²„ì „ 0.9.2+ì™€ í˜¸í™˜ë©ë‹ˆë‹¤
!pip install wandb -qqq
!apt install tree
```


```python
import os
import wandb
```

# 1ï¸âƒ£ ë°ì´í„°ì…‹ ë¡œê·¸í•˜ê¸°

ë¨¼ì €, ëª‡ ê°€ì§€ ì•„í‹°íŒ©íŠ¸ë¥¼ ì •ì˜í•´ ë³´ê² ìŠµë‹ˆë‹¤.

ì´ ì˜ˆì œëŠ” PyTorchì˜
["ê¸°ë³¸ MNIST ì˜ˆì œ"](https://github.com/pytorch/examples/tree/master/mnist/)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì§€ë§Œ,
[TensorFlow](http://wandb.me/artifacts-colab), ë‹¤ë¥¸ í”„ë ˆì„ì›Œí¬ì—ì„œë„ ë§ˆì°¬ê°€ì§€ë¡œ ì‰½ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆìœ¼ë©°,
ìˆœìˆ˜ Pythonì—ì„œë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ìš°ë¦¬ëŠ” `ë°ì´í„°ì…‹`ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤:
- íŒŒë¼ë¯¸í„°ë¥¼ ì„ íƒí•˜ê¸° ìœ„í•œ `train` ì„¸íŠ¸,
- í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì„ íƒí•˜ê¸° ìœ„í•œ `validation` ì„¸íŠ¸,
- ìµœì¢… ëª¨ë¸ì„ í‰ê°€í•˜ê¸° ìœ„í•œ `test` ì„¸íŠ¸

ì•„ë˜ ì²« ë²ˆì§¸ ì…€ì€ ì´ ì„¸ ê°€ì§€ ë°ì´í„°ì…‹ì„ ì •ì˜í•©ë‹ˆë‹¤.


```python
import random 

import torch
import torchvision
from torch.utils.data import TensorDataset
from tqdm.auto import tqdm

# ê²°ì •ì  ë™ì‘ì„ ë³´ì¥í•©ë‹ˆë‹¤
torch.backends.cudnn.deterministic = True
random.seed(0)
torch.manual_seed(0)
torch.cuda.manual_seed_all(0)

# ì¥ì¹˜ ì„¤ì •
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# ë°ì´í„° íŒŒë¼ë¯¸í„°
num_classes = 10
input_shape = (1, 28, 28)

# MNIST ë¯¸ëŸ¬ ëª©ë¡ì—ì„œ ëŠë¦° ë¯¸ëŸ¬ ì œê±°
torchvision.datasets.MNIST.mirrors = [mirror for mirror in torchvision.datasets.MNIST.mirrors
                                      if not mirror.startswith("http://yann.lecun.com")]

def load(train_size=50_000):
    """
    # ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤
    """

    # ë°ì´í„°, íŠ¸ë ˆì¸ê³¼ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• ë©ë‹ˆë‹¤
    train = torchvision.datasets.MNIST("./", train=True, download=True)
    test = torchvision.datasets.MNIST("./", train=False, download=True)
    (x_train, y_train), (x_test, y_test) = (train.data, train.targets), (test.data, test.targets)

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ìœ„í•œ ê²€ì¦ ì„¸íŠ¸ ë¶„ë¦¬
    x_train, x_val = x_train[:train_size], x_train[train_size:]
    y_train, y_val = y_train[:train_size], y_train[train_size:]

    training_set = TensorDataset(x_train, y_train)
    validation_set = TensorDataset(x_val, y_val)
    test_set = TensorDataset(x_test, y_test)

    datasets = [training_set, validation_set, test_set]

    return datasets
```

ì´ëŠ” ì´ ì˜ˆì œì—ì„œ ë°˜ë³µë˜ëŠ” íŒ¨í„´ì„ ì„¤ì •í•©ë‹ˆë‹¤:
ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ì½”ë“œ ì£¼ìœ„ë¡œ ë°ì´í„°ë¥¼ ë¡œê·¸í•˜ëŠ” ì½”ë“œë¥¼ ë˜í•‘í•©ë‹ˆë‹¤.
ì´ ê²½ìš°, `load`ing ë°ì´í„°ì˜ ì½”ë“œëŠ”
ë¡œê·¸í•˜ê³  `load_and_log`í•˜ëŠ” ë°ì´í„°ì˜ ì½”ë“œì™€ ë¶„ë¦¬ë©ë‹ˆë‹¤.

ì´ê²ƒì€ ì¢‹ì€ ê´€í–‰ì…ë‹ˆë‹¤!

ì´ ë°ì´í„°ì…‹ì„ ì•„í‹°íŒ©íŠ¸ë¡œ ë¡œê·¸í•˜ë ¤ë©´,
ìš°ë¦¬ëŠ” ë‹¨ì§€
1. `wandb.init`ìœ¼ë¡œ `Run`ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤ (L4),
2. ë°ì´í„°ì…‹ì— ëŒ€í•œ `ì•„í‹°íŒ©íŠ¸`ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤ (L10), ê·¸ë¦¬ê³ 
3. ê´€ë ¨ëœ `íŒŒì¼`ë“¤ì„ ì €ì¥í•˜ê³  ë¡œê·¸í•´ì•¼ í•©ë‹ˆë‹¤ (L20, L23).

ì•„ë˜ ì½”ë“œ ì…€ì˜ ì˜ˆì œë¥¼ í™•ì¸í•œ ë‹¤ìŒ, ë” ìì„¸í•œ ë‚´ìš©ì„ ì•Œì•„ë³´ê¸° ìœ„í•´ ì´í›„ ì„¹ì…˜ì„ í™•ì¥í•˜ì„¸ìš”.


```python
def load_and_log():

    # ğŸš€ runì„ ì‹œì‘í•˜ê³ , ì´ë¥¼ ë¼ë²¨ë§í•  íƒ€ì…ê³¼ ê·¸ê²ƒì´ ì†í•  í”„ë¡œì íŠ¸ë¥¼ ì§€ì •í•©ë‹ˆë‹¤
    with wandb.init(project="artifacts-example", job_type="load-data") as run:
        
        datasets = load()  # ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ëŠ” ë³„ë„ì˜ ì½”ë“œ
        names = ["training", "validation", "test"]

        # ğŸº ìš°ë¦¬ì˜ ì•„í‹°íŒ©íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
        raw_data = wandb.Artifact(
            "mnist-raw", type="dataset",
            description="Raw MNIST ë°ì´í„°ì…‹, íŠ¸ë ˆì¸/ë°¸/í…ŒìŠ¤íŠ¸ë¡œ ë¶„í• ë¨",
            metadata={"source": "torchvision.datasets.MNIST",
                      "sizes": [len(dataset) for dataset in datasets]})

        for name, data in zip(names, datasets):
            # ğŸ£ ìƒˆ íŒŒì¼ì„ ì•„í‹°íŒ©íŠ¸ì— ì €ì¥í•˜ê³ , ê·¸ ë‚´ìš©ì— ë¬´ì–¸ê°€ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
            with raw_data.new_file(name + ".pt", mode="wb") as file:
                x, y = data.tensors
                torch.save((x, y), file)

        # âœï¸ W&Bì— ì•„í‹°íŒ©íŠ¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
        run.log_artifact(raw_data)

load_and_log()
```

### ğŸš€ `wandb.init`


`Artifact`ë¥¼ ìƒì„±í•  `Run`ì„ ë§Œë“¤ ë•Œ, ì´ê²ƒì´ ì–´ë–¤ `í”„ë¡œì íŠ¸`ì— ì†í•˜ëŠ”ì§€ë¥¼ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ ì›Œí¬í”Œë¡œìš°ì— ë”°ë¼,
í”„ë¡œì íŠ¸ëŠ” `car-that-drives-itself`ì²˜ëŸ¼ í¬ê±°ë‚˜ `iterative-architecture-experiment-117`ì²˜ëŸ¼ ì‘ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> **ğŸ‘ ê·œì¹™**: ê°€ëŠ¥í•˜ë‹¤ë©´, `Artifact`ë¥¼ ê³µìœ í•˜ëŠ” ëª¨ë“  `Run`ì„ ë‹¨ì¼ í”„ë¡œì íŠ¸ ë‚´ì— ìœ ì§€í•˜ì„¸ìš”. ì´ê²ƒì€ ì‚¬ë¬¼ì„ ë‹¨ìˆœí•˜ê²Œ ìœ ì§€í•˜ì§€ë§Œ, ê±±ì •í•˜ì§€ ë§ˆì„¸ìš” -- `ì•„í‹°íŒ©íŠ¸`ëŠ” í”„ë¡œì íŠ¸ ê°„ì— ì´ë™ ê°€ëŠ¥í•©ë‹ˆë‹¤!

ëª¨ë“  ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ì‘ì—…ì„ ì¶”ì í•˜ê¸° ìœ„í•´,
`Run`ì„ ë§Œë“¤ ë•Œ `job_type`ì„ ì œê³µí•˜ëŠ” ê²ƒì´ ìœ ìš©í•©ë‹ˆë‹¤.
ì´ê²ƒì€ ë‹¹ì‹ ì˜ ì•„í‹°íŒ©íŠ¸ ê·¸ë˜í”„ë¥¼ ê¹”ë”í•˜ê²Œ ìœ ì§€í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.

> **ğŸ‘ ê·œì¹™**: `job_type`ì€ ì„¤ëª…ì ì´ì–´ì•¼ í•˜ë©° íŒŒì´í”„ë¼ì¸ì˜ ë‹¨ì¼ ë‹¨ê³„ì— í•´ë‹¹í•´ì•¼ í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ë°ì´í„°ë¥¼ `load`í•˜ëŠ” ê²ƒê³¼ ë°ì´í„°ë¥¼ `preprocess`í•˜ëŠ” ê²ƒì„ êµ¬ë¶„í•©ë‹ˆë‹¤.

### ğŸº `wandb.Artifact`


ë¬´ì–¸ê°€ë¥¼ `ì•„í‹°íŒ©íŠ¸`ë¡œ ë¡œê·¸í•˜ë ¤ë©´, ë¨¼ì € `ì•„í‹°íŒ©íŠ¸` ì˜¤ë¸Œì íŠ¸ë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.

ëª¨ë“  `ì•„í‹°íŒ©íŠ¸`ì—ëŠ” `ì´ë¦„`ì´ ìˆìŠµë‹ˆë‹¤ -- ê·¸ê²ƒì´ ì²« ë²ˆì§¸ ì¸ìˆ˜ê°€ ì„¤ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

> **ğŸ‘ ê·œì¹™**: `ì´ë¦„`ì€ ì„¤ëª…ì ì´ì§€ë§Œ ê¸°ì–µí•˜ê¸° ì‰½ê³  ì…ë ¥í•˜ê¸° ì‰¬ì›Œì•¼ í•©ë‹ˆë‹¤ --
ìš°ë¦¬ëŠ” í•˜ì´í”ˆìœ¼ë¡œ êµ¬ë¶„ëœ ì´ë¦„ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ë©° ì½”ë“œì—ì„œ ë³€ìˆ˜ ì´ë¦„ì— í•´ë‹¹í•©ë‹ˆë‹¤.

ë˜í•œ `ìœ í˜•`ì´ ìˆìŠµë‹ˆë‹¤. `Run`ì˜ `job_type`ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ,
ì´ê²ƒì€ `Run`ê³¼ `ì•„í‹°íŒ©íŠ¸`ì˜ ê·¸ë˜í”„ë¥¼ êµ¬ì„±í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.

> **ğŸ‘ ê·œì¹™**: `ìœ í˜•`ì€ ë‹¨ìˆœí•´ì•¼ í•©ë‹ˆë‹¤:
`dataset`ì´ë‚˜ `model`ì²˜ëŸ¼
`mnist-data-YYYYMMDD`ë³´ë‹¤ëŠ” ê°„ë‹¨í•´ì•¼ í•©ë‹ˆë‹¤.

`ì„¤ëª…`ê³¼ ì¼ë¶€ `ë©”íƒ€ë°ì´í„°`ë¥¼ ì‚¬ì „ í˜•íƒœë¡œ ì²¨ë¶€í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
`ë©”íƒ€ë°ì´í„°`ëŠ” JSONìœ¼ë¡œ ì§ë ¬í™”ë  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

> **ğŸ‘ ê·œì¹™**: `ë©”íƒ€ë°ì´í„°`ëŠ” ê°€ëŠ¥í•œ í•œ ì„¤ëª…ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

### ğŸ£ `artifact.new_file` ë° âœï¸ `run.log_artifact`

`ì•„í‹°íŒ©íŠ¸` ì˜¤ë¸Œì íŠ¸ë¥¼ ë§Œë“  í›„, ê·¸ê²ƒì— íŒŒì¼ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.

ê·¸ë ‡ìŠµë‹ˆë‹¤: _íŒŒì¼ë“¤_ì´ë¼ê³  ë³µìˆ˜í˜•ìœ¼ë¡œ ë§í–ˆìŠµë‹ˆë‹¤.
`ì•„í‹°íŒ©íŠ¸`ëŠ” ë””ë ‰í† ë¦¬ì²˜ëŸ¼ êµ¬ì¡°í™”ë˜ì–´ ìˆìœ¼ë©°,
íŒŒì¼ê³¼ í•˜ìœ„ ë””ë ‰í† ë¦¬ê°€ ìˆìŠµë‹ˆë‹¤.

> **ğŸ‘ ê·œì¹™**: ì˜ë¯¸ê°€ ìˆì„ ë•Œë§ˆë‹¤, `ì•„í‹°íŒ©íŠ¸`ì˜ ë‚´ìš©ì„ ì—¬ëŸ¬ íŒŒì¼ë¡œ ë¶„í• í•˜ì„¸ìš”. ì´ê²ƒì€ í™•ì¥í•  ë•Œ ë„ì›€ì´ ë©ë‹ˆë‹¤!

`new_file` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬
íŒŒì¼ì„ ë™ì‹œì— ì‘ì„±í•˜ê³  `ì•„í‹°íŒ©íŠ¸`ì— ì²¨ë¶€í•©ë‹ˆë‹¤.
ì•„ë˜ì—ì„œëŠ” `add_file` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.
ì´ ë‘ ë‹¨ê³„ë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤.

ëª¨ë“  íŒŒì¼ì„ ì¶”ê°€í•œ í›„, [wandb.ai](https://wandb.ai)ì— `log_artifact` í•´ì•¼ í•©ë‹ˆë‹¤.

ì¶œë ¥ì— ëª‡ ê°€ì§€ URLì´ ë‚˜íƒ€ë‚¬ìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤,
`Run` í˜ì´ì§€ URLì„ í¬í•¨í•©ë‹ˆë‹¤.
ê·¸ê²ƒì€ `Run`ì˜ ê²°ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆëŠ” ê³³ì…ë‹ˆë‹¤,
ë¡œê·¸ëœ ëª¨ë“  `ì•„í‹°íŒ©íŠ¸`ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

ì•„ë˜ì—ì„œëŠ” Run í˜ì´ì§€ì˜ ë‹¤ë¥¸ êµ¬ì„± ìš”ì†Œë¥¼ ë” ì˜ í™œìš©í•˜ëŠ” ëª‡ ê°€ì§€ ì˜ˆì œë¥¼ ë³¼ ê²ƒì…ë‹ˆë‹¤.

# 2ï¸âƒ£ ë¡œê·¸ëœ ë°ì´í„°ì…‹ ì•„í‹°íŒ©íŠ¸ ì‚¬ìš©í•˜ê¸°

W&Bì˜ `ì•„í‹°íŒ©íŠ¸`ëŠ” ë°•ë¬¼ê´€ì˜ ì•„í‹°íŒ©íŠ¸ì™€ ë‹¬ë¦¬,
ì €ì¥ë¿ë§Œ ì•„ë‹ˆë¼ _ì‚¬ìš©_ë˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

ê·¸ê²ƒì´ ì–´ë–¤ ëª¨ìŠµì¸ì§€ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

ì•„ë˜ ì…€ì€ ì›ì‹œ ë°ì´í„°ì…‹ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„
`preprocess`ëœ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ëŠ” íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë¥¼ ì •ì˜í•©ë‹ˆë‹¤:
`ì •ê·œí™”`ë˜ê³  ì˜¬ë°”ë¥´ê²Œ í˜•íƒœê°€ ì§€ì •ë©ë‹ˆë‹¤.

ë‹¤ì‹œ í•œë²ˆ `wandb`ì™€ ì¸í„°í˜ì´ìŠ¤í•˜ëŠ” ì½”ë“œì™€ `preprocess`ì˜ í•µì‹¬ ì½”ë“œë¥¼ ë¶„ë¦¬í–ˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.


```python
def preprocess(dataset, normalize=True, expand_dims=True):
    """
    ## ë°ì´í„° ì¤€ë¹„
    """
    x, y = dataset.tensors

    if normalize:
        # ì´ë¯¸ì§€ë¥¼ [0, 1] ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§í•©ë‹ˆë‹¤
        x = x.type(torch.float32) / 255

    if expand_dims:
        # ì´ë¯¸ì§€ê°€ (1, 28, 28) í˜•íƒœë¥¼ ê°€ì§€ë„ë¡ í•©ë‹ˆë‹¤
        x = torch.unsqueeze(x, 1)
    
    return TensorDataset(x, y)
```

ì´ì œ `wandb.Artifact` ë¡œê¹…ìœ¼ë¡œ ì´ `preprocess` ë‹¨ê³„ë¥¼ ê³„ì¸¡í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.

ì•„ë˜ ì˜ˆì œì—ì„œëŠ” `ì•„í‹°íŒ©íŠ¸`ë¥¼ `ì‚¬ìš©`í•˜ëŠ” ê²ƒì´ ìƒˆë¡­ìŠµë‹ˆë‹¤,
ê·¸ë¦¬ê³  `ë¡œê·¸`í•˜ëŠ” ê²ƒì€ ë§ˆì§€ë§‰ ë‹¨ê³„ì™€ ê°™ìŠµë‹ˆë‹¤.
`ì•„í‹°íŒ©íŠ¸`ëŠ” `Run`ì˜ ì…ë ¥ê³¼ ì¶œë ¥ ëª¨ë‘ì…ë‹ˆë‹¤!

ìƒˆë¡œìš´ `job_type`, `preprocess-data`ë¥¼ ì‚¬ìš©í•˜ì—¬
ì´ê²ƒì´ ì´ì „ ê²ƒê³¼ ë‹¤ë¥¸ ì¢…ë¥˜ì˜ ì‘ì—…ì„ì„ ëª…í™•íˆ í•©ë‹ˆë‹¤.


```python
def preprocess_and_log(steps):

    with wandb.init(project="artifacts-example", job_type="preprocess-data") as run:

        processed_data = wandb.Artifact(
            "mnist-preprocess", type="dataset",
            description="ì „ì²˜ë¦¬ëœ MNIST ë°ì´í„°ì…‹",
            metadata=steps)
         
        # âœ”ï¸ ì‚¬ìš©í•  ì•„í‹°íŒ©íŠ¸ë¥¼ ì„ ì–¸í•©ë‹ˆë‹¤
        raw_data_artifact = run.use_artifact('mnist-raw:latest')

        # ğŸ“¥ í•„ìš”í•˜ë‹¤ë©´, ì•„í‹°íŒ©íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤
        raw_dataset = raw_data_artifact.download()
        
        for split in ["training", "validation", "test"]:
            raw_split = read(raw_dataset, split)
            processed_dataset = preprocess(raw_split, **steps)

            with processed_data.new_file(split + ".pt", mode="wb") as file:
                x, y = processed_dataset.tensors
                torch.save((x, y), file)

        run.log_artifact(processed_data)


def read(data_dir, split):
    filename = split + ".pt"
    x, y = torch.load(os.path.join(data_dir, filename))

    return TensorDataset(x, y)
```

ì—¬ê¸°ì„œ ì£¼ëª©í•´ì•¼ í•  ê²ƒì€ `preprocess` ë‹¨ê³„ì˜ `steps`
ê°€ `preprocessed_data`ì˜ `ë©”íƒ€ë°ì´í„°`ë¡œ ì €ì¥ëœë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì‹¤í—˜ì„ ì¬í˜„ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ë ¤ë©´,
ë§ì€ ë©”íƒ€ë°ì´í„°ë¥¼ ìº¡ì²˜í•˜ëŠ” ê²ƒì´ ì¢‹ì€ ìƒê°ì…ë‹ˆë‹¤!

ë˜í•œ, ìš°ë¦¬ì˜ ë°ì´í„°ì…‹ì´ "`ëŒ€ê·œ

# 4ï¸âƒ£ ë¡œê·¸ëœ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì‚¬ìš©í•˜ê¸°

`ë°ì´í„°ì…‹`ì— `use_artifact`ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆë“¯ì´, ìš°ë¦¬ëŠ” `initialized_model`ì—ë„ ê·¸ê²ƒì„ í˜¸ì¶œí•˜ì—¬ ë‹¤ë¥¸ `Run`ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ë²ˆì—ëŠ” `ëª¨ë¸`ì„ `íŠ¸ë ˆì´ë‹`í•´ë´…ì‹œë‹¤.

ë” ìì„¸í•œ ë‚´ìš©ì€ ìš°ë¦¬ì˜ Colabì—ì„œ í™•ì¸í•˜ì„¸ìš”.
[PyTorchì™€ í•¨ê»˜ W&Bë¥¼ êµ¬ì„±í•˜ëŠ” ë°©ë²•](http://wandb.me/pytorch-colab)ì— ëŒ€í•´.

```python
import torch.nn.functional as F

def train(model, train_loader, valid_loader, config):
    optimizer = getattr(torch.optim, config.optimizer)(model.parameters())
    model.train()
    example_ct = 0
    for epoch in range(config.epochs):
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = F.cross_entropy(output, target)
            loss.backward()
            optimizer.step()

            example_ct += len(data)

            if batch_idx % config.batch_log_interval == 0:
                print('íŠ¸ë ˆì´ë‹ ì—í¬í¬: {} [{}/{} ({:.0%})]\tì†ì‹¤: {:.6f}'.format(
                    epoch, batch_idx * len(data), len(train_loader.dataset),
                    batch_idx / len(train_loader), loss.item()))
                
                train_log(loss, example_ct, epoch)

        # ì—í¬í¬ë§ˆë‹¤ ê²€ì¦ ì„¸íŠ¸ì—ì„œ ëª¨ë¸ í‰ê°€
        loss, accuracy = test(model, valid_loader)  
        test_log(loss, accuracy, example_ct, epoch)

    
def test(model, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.cross_entropy(output, target, reduction='sum')  # ë°°ì¹˜ ì†ì‹¤ í•©ì‚°
            pred = output.argmax(dim=1, keepdim=True)  # ìµœëŒ€ ë¡œê·¸-í™•ë¥ ì˜ ì¸ë±ìŠ¤ë¥¼ ê°€ì ¸ì˜´
            correct += pred.eq(target.view_as(pred)).sum()

    test_loss /= len(test_loader.dataset)

    accuracy = 100. * correct / len(test_loader.dataset)
    
    return test_loss, accuracy


def train_log(loss, example_ct, epoch):
    loss = float(loss)

    # ë§ˆë²•ì´ ì¼ì–´ë‚˜ëŠ” ê³³
    wandb.log({"epoch": epoch, "train/loss": loss}, step=example_ct)
    print(f"ì˜ˆì‹œ " + str(example_ct).zfill(5) + f"ê°œ í›„ ì†ì‹¤: {loss:.3f}")
    

def test_log(loss, accuracy, example_ct, epoch):
    loss = float(loss)
    accuracy = float(accuracy)

    # ë§ˆë²•ì´ ì¼ì–´ë‚˜ëŠ” ê³³
    wandb.log({"epoch": epoch, "validation/loss": loss, "validation/accuracy": accuracy}, step=example_ct)
    print(f"ì˜ˆì‹œ " + str(example_ct).zfill(5) + f"ê°œ í›„ ì†ì‹¤/ì •í™•ë„: {loss:.3f}/{accuracy:.3f}")
```

ì´ë²ˆì—ëŠ” ë‘ ê°œì˜ ë³„ë„ì˜ `Artifact`ì„ ìƒì„±í•˜ëŠ” `Run`ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

ì²« ë²ˆì§¸ê°€ `ëª¨ë¸` íŠ¸ë ˆì´ë‹ì„ ë§ˆì¹˜ë©´,
`ë‘ ë²ˆì§¸`ëŠ” `í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹`ì—ì„œ `trained-model` `Artifact`ì˜ ì„±ëŠ¥ì„ `í‰ê°€`í•¨ìœ¼ë¡œì¨ ê·¸ê²ƒì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

ë˜í•œ, ë„¤íŠ¸ì›Œí¬ê°€ ê°€ì¥ í˜¼ë€ìŠ¤ëŸ¬ì›Œí•˜ëŠ” 32ê°œì˜ ì˜ˆì‹œë“¤ -- `categorical_crossentropy`ê°€ ê°€ì¥ ë†’ì€ ê²ƒë“¤ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤.

ì´ê²ƒì€ ë°ì´í„°ì…‹ê³¼ ëª¨ë¸ì— ëŒ€í•œ ë¬¸ì œë¥¼ ì§„ë‹¨í•˜ëŠ” ì¢‹ì€ ë°©ë²•ì…ë‹ˆë‹¤!

```python
def evaluate(model, test_loader):
    """
    ## íŠ¸ë ˆì´ë‹ëœ ëª¨ë¸ í‰ê°€í•˜ê¸°
    """

    loss, accuracy = test(model, test_loader)
    highest_losses, hardest_examples, true_labels, predictions = get_hardest_k_examples(model, test_loader.dataset)

    return loss, accuracy, highest_losses, hardest_examples, true_labels, predictions

def get_hardest_k_examples(model, testing_set, k=32):
    model.eval()

    loader = DataLoader(testing_set, 1, shuffle=False)

    # ë°ì´í„°ì…‹ì˜ ê° í•­ëª©ì— ëŒ€í•œ ì†ì‹¤ê³¼ ì˜ˆì¸¡ê°’ì„ ê°€ì ¸ì˜´
    losses = None
    predictions = None
    with torch.no_grad():
        for data, target in loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            loss = F.cross_entropy(output, target)
            pred = output.argmax(dim=1, keepdim=True)
            
            if losses is None:
                losses = loss.view((1, 1))
                predictions = pred
            else:
                losses = torch.cat((losses, loss.view((1, 1))), 0)
                predictions = torch.cat((predictions, pred), 0)

    argsort_loss = torch.argsort(losses, dim=0)

    highest_k_losses = losses[argsort_loss[-k:]]
    hardest_k_examples = testing_set[argsort_loss[-k:]][0]
    true_labels = testing_set[argsort_loss[-k:]][1]
    predicted_labels = predictions[argsort_loss[-k:]]

    return highest_k_losses, hardest_k_examples, true_labels, predicted_labels
```

ì´ ë¡œê¹… í•¨ìˆ˜ë“¤ì€ ìƒˆë¡œìš´ `Artifact` ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ìš°ë¦¬ëŠ” ê·¸ê²ƒë“¤ì— ëŒ€í•´ ì–¸ê¸‰í•˜ì§€ ì•Šì„ ê²ƒì…ë‹ˆë‹¤:
ìš°ë¦¬ëŠ” ë‹¨ì§€ `Artifact`ì„ `ì‚¬ìš©`í•˜ê³ , `ë‹¤ìš´ë¡œë“œ`í•˜ê³ ,
`ë¡œê·¸`í•©ë‹ˆë‹¤.

```python
from torch.utils.data import DataLoader

def train_and_log(config):

    with wandb.init(project="artifacts-example", job_type="train", config=config) as run:
        config = wandb.config

        data = run.use_artifact('mnist-preprocess:latest')
        data_dir = data.download()

        training_dataset =  read(data_dir, "training")
        validation_dataset = read(data_dir, "validation")

        train_loader = DataLoader(training_dataset, batch_size=config.batch_size)
        validation_loader = DataLoader(validation_dataset, batch_size=config.batch_size)
        
        model_artifact = run.use_artifact("convnet:latest")
        model_dir = model_artifact.download()
        model_path = os.path.join(model_dir, "initialized_model.pth")
        model_config = model_artifact.metadata
        config.update(model_config)

        model = ConvNet(**model_config)
        model.load_state_dict(torch.load(model_path))
        model = model.to(device)
 
        train(model, train_loader, validation_loader, config)

        model_artifact = wandb.Artifact(
            "trained-model", type="model",
            description="íŠ¸ë ˆì´ë‹ëœ NN ëª¨ë¸",
            metadata=dict(model_config))

        torch.save(model.state_dict(), "trained_model.pth")
        model_artifact.add_file("trained_model.pth")
        wandb.save("trained_model.pth")

        run.log_artifact(model_artifact)

    return model

    
def evaluate_and_log(config=None):
    
    with wandb.init(project="artifacts-example", job_type="report", config=config) as run:
        data = run.use_artifact('mnist-preprocess:latest')
        data_dir = data.download()
        testing_set = read(data_dir, "test")

        test_loader = torch.utils.data.DataLoader(testing_set, batch_size=128, shuffle=False)

        model_artifact = run.use_artifact("trained-model:latest")
        model_dir = model_artifact.download()
        model_path = os.path.join(model_dir, "trained_model.pth")
        model_config = model_artifact.metadata

        model = ConvNet(**model_config)
        model.load_state_dict(torch.load(model_path))
        model.to(device)

        loss, accuracy, highest_losses, hardest_examples, true_labels, preds = evaluate(model, test_loader)

        run.summary.update({"loss": loss, "accuracy": accuracy})

        wandb.log({"high-loss-examples":
            [wandb.Image(hard_example, caption=str(int(pred)) + "," +  str(int(label)))
             for hard_example, pred, label in zip(hardest_examples, preds, true_labels)]})
```


```python
train_config = {"batch_size": 128,
                "epochs": 5,
                "batch_log_interval": 25,
                "optimizer": "Adam"}

model = train_and_log(train_config)
evaluate_and_log()
```

### ğŸ” ê·¸ë˜í”„ ë·°

`Artifact`ì˜ `type`ì„ ë³€ê²½í–ˆìŒì„ ì£¼ëª©í•˜ì„¸ìš”:
ì´ `Run`ë“¤ì€ `ë°ì´í„°ì…‹`ì´ ì•„ë‹Œ `ëª¨ë¸`ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.
`ëª¨ë¸`ì„ ìƒì„±í•˜ëŠ” `Run`ë“¤ì€ Artifacts í˜ì´ì§€ì˜ ê·¸ë˜í”„ ë·°ì—ì„œ `ë°ì´í„°ì…‹`ì„ ìƒì„±í•˜ëŠ” ê²ƒë“¤ê³¼ ë¶„ë¦¬ë©ë‹ˆë‹¤.

í™•ì¸í•´ë³´ì„¸ìš”! ì´ì „ì²˜ëŸ¼, Run í˜ì´ì§€ë¡œ ê°€ì„œ,
ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ "Artifacts" íƒ­ì„ ì„ íƒí•˜ê³ ,
`Artifact`ì„ ì„ íƒí•œ ë‹¤ìŒ,
"Graph View" íƒ­ì„ í´ë¦­í•˜ì‹­ì‹œì˜¤.

### ğŸ’£ í„°ì§„ ê·¸ë˜í”„

"Explode"ë¼ê³  í‘œì‹œëœ ë²„íŠ¼ì„ ì£¼ëª©í–ˆì„ ê²ë‹ˆë‹¤. ê·¸ê²ƒì„ í´ë¦­í•˜ì§€ ë§ˆì„¸ìš”, ì™œëƒí•˜ë©´ ê·¸ê²ƒì€ W&B ë³¸ì‚¬ì— ìˆëŠ” ê²¸ì†í•œ ì €ìì˜ ì±…ìƒ ì•„ë˜ì— ì‘ì€ í­íƒ„ì„ ì„¤ì¹˜í•  ê²ƒì´ê¸° ë•Œë¬¸ì´ì£ !

ë†ë‹´ì…ë‹ˆë‹¤. ê·¸ê²ƒì€ ê·¸ë˜í”„ë¥¼ í›¨ì”¬ ë” ë¶€ë“œëŸ¬ìš´ ë°©ë²•ìœ¼ë¡œ "í­ë°œ"ì‹œí‚µë‹ˆë‹¤:
`Artifact`ê³¼ `Run`ì´ `type`ì˜ ìˆ˜ì¤€ì—ì„œ ë¶„ë¦¬ë˜ì–´,
ë…¸ë“œë“¤ì€ `ë°ì´í„°ì…‹`ê³¼ `load-data`ê°€ ì•„ë‹ˆë¼, `ë°ì´í„°ì…‹:mnist-raw:v1`ê³¼ `load-data:sunny-smoke-1` ë“±ì´ ë©ë‹ˆë‹¤.

ì´ê²ƒì€ ë‹¹ì‹ ì˜ íŒŒì´í”„ë¼ì¸ì— ëŒ€í•œ ì™„ì „í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤,
ë¡œê·¸ëœ ë©”íŠ¸ë¦­, ë©”íƒ€ë°ì´í„° ë“±ì´
ëª¨ë‘ ë‹¹ì‹ ì˜ ì†ëì— ìˆìŠµë‹ˆë‹¤ --
ë‹¹ì‹ ì´ ìš°ë¦¬ì™€ í•¨ê»˜ ë¡œê·¸í•˜ê¸°ë¡œ ì„ íƒí•œ ê²ƒì— ì˜í•´ì„œë§Œ ì œí•œë©ë‹ˆë‹¤.

# ë‹¤ìŒì€ ë¬´ì—‡ì¸ê°€ìš”?
ë‹¤ìŒ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” W&B ëª¨ë¸ë¡œ ëª¨ë¸ ë³€ê²½ ì‚¬í•­ì„ ì†Œí†µí•˜ê³  ëª¨ë¸ ê°œë°œ ìƒëª…ì£¼ê¸°ë¥¼ ê´€ë¦¬í•˜ëŠ” ë°©ë²•ì„ ë°°ìš°ê²Œ ë©ë‹ˆë‹¤:

## ğŸ‘‰ [ëª¨ë¸ ê°œë°œ ìƒëª…ì£¼ê¸° ì¶”ì í•˜ê¸°](models)