---
menu:
  default:
    identifier: secure-storage-connector
    parent: data-security
title: Bring your own bucket (BYOB)
weight: 1
---

Bring your own bucket (BYOB) allows you to store W&B artifacts and other related sensitive data in your own cloud or on-prem infrastructure. In case of [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}) or [SaaS Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}), data that you store in your bucket is not copied to the W&B managed infrastructure.

{{% alert %}}
* Communication between W&B SDK / CLI / UI and your buckets occurs using [pre-signed URLs]({{< relref "./presigned-urls.md" >}}).
* W&B uses a garbage collection process to delete W&B Artifacts. For more information, see [Deleting Artifacts]({{< relref "/guides/core/artifacts/manage-data/delete-artifacts.md" >}}).
* You can specify a sub-path when configuring a bucket, to ensure that W&B does not store any files in a folder at the root of the bucket. It can help you better conform to your organzation's bucket governance policy.
{{% /alert %}}

## Data stored in the central database vs buckets

When using BYOB functionality, certain types of data will be stored in the W&B central database, and other types will be stored in your bucket. 

### Database

- Metadata for users, teams, artifacts, experiments, and projects
- Reports
- Experiment logs
- System metrics
- Console logs

### Buckets

- Experiment files and metrics
- Artifact files
- Media files
- Run files
- Exported history metrics and system events in Parquet format

## Configuration options
There are two scopes you can configure your storage bucket to: at the *Instance level* or at a *Team level*. 

- Instance level: Any user that has relevant permissions within your organization can access files stored in your instance level storage bucket.
- Team level:  Members of a W&B Team can access files stored in the bucket configured at the Team level. Team level storage buckets allow greater data access control and data isolation for teams with highly sensitive data or strict compliance requirements.

You can configure your bucket at both the instance level and separately for one or more teams within your organization.

For example, suppose you have a team called Kappa in your organization. Your organization (and Team Kappa) use the Instance level storage bucket by default. Next, you create a team called Omega. When you create Team Omega, you configure a Team level storage bucket for that team. Files generated by Team Omega are not accessible by Team Kappa. However, files created by Team Kappa are accessible by Team Omega. If you want to isolate data for Team Kappa, you must configure a Team level storage bucket for them as well.

{{% alert %}}
Team level storage bucket provides the same benefits for [Self-managed]({{< relref "/guides/hosting/hosting-options/self-managed.md" >}}) instances, especially when different business units and departments share an instance to efficiently utilize the infrastructure and administrative resources. This also applies to firms that have separate project teams managing AI workflows for separate customer engagements.
{{% /alert %}}

## Availability matrix
The following table shows the availability of BYOB across different W&B Server deployment types. An `X` means the feature is available on the specific deployment type.

| W&B Server deployment type | Instance level | Team level | Additional information |
|----------------------------|--------------------|----------------|------------------------|
| Dedicated cloud | X | X | Both the instance and team level BYOB are available for Amazon Web Services, Google Cloud Platform and Microsoft Azure. For the team-level BYOB, you can connect to a cloud-native storage bucket in the same or another cloud, or even a S3-compatible secure storage like [MinIO](https://github.com/minio/minio) hosted in your cloud or on-prem infrastructure. |
| SaaS Cloud | Not Applicable | X | The team level BYOB is available only for Amazon Web Services and Google Cloud Platform. W&B fully manages the default and only storage bucket for Microsoft Azure. |
| Self-managed | X | X | Instance level BYOB is the default since the instance is fully managed by you. If your self-managed instance is in cloud, you can connect to a cloud-native storage bucket in the same or another cloud for the team-level BYOB. You can also use S3-compatible secure storage like [MinIO](https://github.com/minio/minio) for either of instance or team-level BYOB. |

{{% alert color="secondary" %}}
Plan your storage bucket layout carefully. After you configure a storage bucket for W&B, migrating its data to another bucket is complex and requires the assistance of W&B. This applies to storage for Dedicated Cloud and Self-Managed, as well as team-level storage for SaaS Cloud. For questions, contact [support](mailto:support@wandb.com).
{{% /alert %}}

## Cross-cloud or S3-compatible storage for team-level BYOB

You can connect to a cloud-native storage bucket in another cloud or to an S3-compatible storage bucket like [MinIO](https://github.com/minio/minio) for team-level BYOB in your [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}) or [Self-managed]({{< relref "/guides/hosting/hosting-options/self-managed.md" >}}) instance.

To enable the use of cross-cloud or S3-compatible storage, specify the storage bucket including the relevant access key in one of the following formats, using the `GORILLA_SUPPORTED_FILE_STORES` environment variable for your W&B instance.

<details>
<summary>Configure an S3-compatible storage for team-level BYOB in Dedicated cloud or Self-managed instance</summary>

Specify the path using the following format:
```text
s3://<accessKey>:<secretAccessKey>@<url_endpoint>/<bucketName>?region=<region>&tls=true
```
The `region` parameter is mandatory, except for when your W&B instance is in AWS and the `AWS_REGION` configured on the W&B instance nodes matches the region configured for the S3-compatible storage.

</details>
<details>
<summary>Configure a cross-cloud native storage for team-level BYOB in Dedicated cloud or Self-managed instance</summary>

Specify the path in a format specific to the locations of your W&B instance and storage bucket:

From W&B instance in GCP or Azure to a bucket in AWS:
```text
s3://<accessKey>:<secretAccessKey>@<s3_regional_url_endpoint>/<bucketName>
```

From W&B instance in GCP or AWS to a bucket in Azure:
```text
az://:<urlEncodedAccessKey>@<storageAccountName>/<containerName>
```

From W&B instance in AWS or Azure to a bucket in GCP:
```text
gs://<serviceAccountEmail>:<urlEncodedPrivateKey>@<bucketName>
```

{{% alert %}}
Because it is hosted in GCP, [SaaS Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}) does not support connectivity to S3-compatible storage for team-level storage, including cross-cloud connectivity. SaaS Cloud does not have access to the access keys and environment variables used to configure [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}) and [Self-managed]({{< relref "/guides/hosting/hosting-options/self-managed.md" >}}) instances.
{{% /alert %}}
</details>


## Cloud storage in same cloud as W&B platform

Based on your use case, configure a storage bucket at the team or instance level. How a storage bucket is provisioned or configured is the same irrespective of the level it's configured at, except for the access mechanism in Azure. 

{{% alert %}}
W&B recommends that you use a Terraform module managed by W&B to provision a storage bucket along with the necessary access mechanism and related IAM permissions:

* [AWS](https://github.com/wandb/terraform-aws-wandb/tree/main/modules/secure_storage_connector)
* [GCP](https://github.com/wandb/terraform-google-wandb/tree/main/modules/secure_storage_connector)
* Azure - [Instance level BYOB](https://github.com/wandb/terraform-azurerm-wandb/tree/main/examples/byob) or [Team level BYOB](https://github.com/wandb/terraform-azurerm-wandb/tree/main/modules/secure_storage_connector)
{{% /alert %}}

{{< tabpane text=true >}}
{{% tab header="AWS" value="aws" %}}
1. Provision the KMS Key

    W&B requires you to provision a KMS Key to encrypt and decrypt the data on the S3 bucket. The key usage type must be `ENCRYPT_DECRYPT`. Assign the following policy to the key:

    ```json
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Sid" : "Internal",
          "Effect" : "Allow",
          "Principal" : { "AWS" : "<Your_Account_Id>" },
          "Action" : "kms:*",
          "Resource" : "<aws_kms_key.key.arn>"
        },
        {
          "Sid" : "External",
          "Effect" : "Allow",
          "Principal" : { "AWS" : "<aws_principal_and_role_arn>" },
          "Action" : [
            "kms:Decrypt",
            "kms:Describe*",
            "kms:Encrypt",
            "kms:ReEncrypt*",
            "kms:GenerateDataKey*"
          ],
          "Resource" : "<aws_kms_key.key.arn>"
        }
      ]
    }
    ```

    Replace `<Your_Account_Id>` and `<aws_kms_key.key.arn>` accordingly.

    If you are using [SaaS Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}) or [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), replace `<aws_principal_and_role_arn>` with the corresponding value:

    * For [SaaS Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}): `arn:aws:iam::725579432336:role/WandbIntegration`
    * For [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}): `arn:aws:iam::830241207209:root`

    This policy grants your AWS account full access to the key and also assigns the required permissions to the AWS account hosting the W&B Platform. Keep a record of the KMS Key ARN.

1. Provision the S3 Bucket

    Follow these steps to provision the S3 bucket in your AWS account:

    1. Create the S3 bucket with a name of your choice. Optionally create a folder which you can configure as sub-path to store all W&B files.
    1. Enable server side encryption, using the KMS key from the previous step.
    1. Configure CORS with the following policy:

        ```json
        [
          {
              "AllowedHeaders": [
                  "*"
              ],
              "AllowedMethods": [
                  "GET",
                  "HEAD",
                  "PUT"
              ],
              "AllowedOrigins": [
                  "*"
              ],
              "ExposeHeaders": [
                  "ETag"
              ],
              "MaxAgeSeconds": 3000
          }
        ]
        ```
        {{% alert %}}If data in your bucket expires due to a lifecycle policy, you can no longer read the history of your runs.{{% /alert %}}
    1. Grant the required S3 permissions to the AWS account hosting the W&B Platform, which requires these permissions to generate [pre-signed URLs]({{< relref "./presigned-urls.md" >}}) that AI workloads in your cloud infrastructure or user browsers utilize to access the bucket.

        ```json
        {
          "Version": "2012-10-17",
          "Id": "WandBAccess",
          "Statement": [
            {
              "Sid": "WAndBAccountAccess",
              "Effect": "Allow",
              "Principal": { "AWS": "<aws_principal_and_role_arn>" },
                "Action" : [
                  "s3:GetObject*",
                  "s3:GetEncryptionConfiguration",
                  "s3:ListBucket",
                  "s3:ListBucketMultipartUploads",
                  "s3:ListBucketVersions",
                  "s3:AbortMultipartUpload",
                  "s3:DeleteObject",
                  "s3:PutObject",
                  "s3:GetBucketCORS",
                  "s3:GetBucketLocation",
                  "s3:GetBucketVersioning"
                ],
              "Resource": [
                "arn:aws:s3:::<wandb_bucket>",
                "arn:aws:s3:::<wandb_bucket>/*"
              ]
            }
          ]
        }
        ```

        Replace `<wandb_bucket>` accordingly and keep a record of the bucket name. If you are using [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), share the bucket name with your W&B team in case of instance level BYOB. In case of team level BYOB on any deployment type, [configure the bucket while creating the team]({{< relref "#configure-byob-in-wb" >}}).

        If you are using [SaaS Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}) or [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), replace `<aws_principal_and_role_arn>` with the corresponding value.

        * For [SaaS Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}): `arn:aws:iam::725579432336:role/WandbIntegration`
        * For [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}): `arn:aws:iam::830241207209:root`
  
For more details, see the [AWS self-managed hosting guide]({{< relref "/guides/hosting/hosting-options/self-managed/install-on-public-cloud/aws-tf.md" >}}).
{{% /tab %}}

{{% tab header="GCP" value="gcp"%}}
1. Provision the GCS Bucket

    Follow these steps to provision the GCS bucket in your GCP project:

    1. Create the GCS bucket with a name of your choice. Optionally create a folder which you can configure as sub-path to store all W&B files.
    1. Set encryption type to `Google-managed`.
    1. Set the CORS policy with `gsutil`. This is not possible in the UI.

       1. Create a file called `cors-policy.json` locally.
       1. Copy the following CORS policy into the file and save it.

           ```json
           [
             {
               "origin": ["*"],
               "responseHeader": ["Content-Type"],
               "exposeHeaders": ["ETag"],
               "method": ["GET", "HEAD", "PUT"],
               "maxAgeSeconds": 3000
             }
           ]
           ```

          {{% alert %}}If data in your bucket expires due to a lifecycle policy, you can no longer read the history of your runs.{{% /alert %}}

      1. Replace `<bucket_name>` with the correct bucket name and run `gsutil`.

          ```bash
          gsutil cors set cors-policy.json gs://<bucket_name>
          ```

      1. Verify the bucket's policy. Replace `<bucket_name>` with the correct bucket name.
        
          ```bash
          gsutil cors get gs://<bucket_name>
          ```

1. If you are using [SaaS Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}) or [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), grant the `storage.admin` role to the GCP service account linked to the W&B Platform. W&B requires this role to check the bucket's CORS configuration and attributes, such as whether object versioning is enabled. If the service account does not have the `storage.admin` role, these checks result in a HTTP 403 error.

    * For [SaaS Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}), the account is: `wandb-integration@wandb-production.iam.gserviceaccount.com`
    * For [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}) the account is: `deploy@wandb-production.iam.gserviceaccount.com`

    Keep a record of the bucket name. If you are using [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), share the bucket name with your W&B team in case of instance level BYOB. In case of team level BYOB on any deployment type, [configure the bucket while creating the team]({{< relref "#configure-byob-in-wb" >}}).
{{% /tab %}}

{{% tab header="Azure" value="azure"%}}
1. Provision the Azure Blob Storage

    For the instance level BYOB, if you're not using [this Terraform module](https://github.com/wandb/terraform-azurerm-wandb/tree/main/examples/byob), follow the steps below to provision a Azure Blob Storage bucket in your Azure subscription:

    1. Create a bucket with a name of your choice. Optionally create a folder which you can configure as sub-path to store all W&B files.
    1. Configure the CORS policy on the bucket

        To set the CORS policy through the UI go to the blob storage, scroll down to `Settings/Resource Sharing (CORS)` and then set the following:

        | Parameter | Value |
        | --- | --- |
        | Allowed Origins | `*`  |
        | Allowed Methods | `GET`, `HEAD`, `PUT` |
        | Allowed Headers | `*` |
        | Exposed Headers | `*` |
        | Max Age | `3000` |

        {{% alert %}}If data in your bucket expires due to a lifecycle policy, you can no longer read the history of your runs.{{% /alert %}}
1. Generate a storage account access key, and keep a record of that along with the storage account name. If you are using [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), share the storage account name and access key with your W&B team using a secure sharing mechanism.

    For the team level BYOB, W&B recommends that you use [Terraform](https://github.com/wandb/terraform-azurerm-wandb/tree/main/modules/secure_storage_connector) to provision the Azure Blob Storage bucket along with the necessary access mechanism and permissions. If you use [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), provide the OIDC issuer URL for your instance. Make a note of details that you need to [configure the bucket while creating the team]({{< relref "#configure-byob-in-wb" >}}):

    * Storage account name
    * Storage container name
    * Managed identity client id
    * Azure tenant id
{{% /tab %}}
{{< /tabpane >}}

## Configure BYOB in W&B

{{< tabpane text=true >}}

{{% tab header="Team level" value="team" %}}
If you're connecting to a cloud-native storage bucket in another cloud or to an S3-compatible storage bucket like [MinIO](https://github.com/minio/minio) for team-level BYOB in your [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}) or [Self-managed]({{< relref "/guides/hosting/hosting-options/self-managed.md" >}}) instance, refer to [Cross-cloud or S3-compatible storage for team-level BYOB]({{< relref "#cross-cloud-or-s3-compatible-storage-for-team-level-byob" >}}). In such cases, you must specify the storage bucket using the `GORILLA_SUPPORTED_FILE_STORES` environment variable for your W&B instance, before you configure it for a team using the instructions below.

{{% alert %}}
Watch a [video demonstrating the secure storage connector in action](https://www.youtube.com/watch?v=uda6jIx6n5o) (9 min).
{{% /alert %}}

To configure a storage bucket at the team level when you create a W&B Team:

1. Provide a name for your team in the **Team Name** field. 
1. Select **External storage** for the **Storage type** option. 
1. Choose either **New bucket** from the dropdown or select an existing bucket.

    Multiple W&B Teams can use the same cloud storage bucket. To enable this, select an existing cloud storage bucket from the dropdown.

1. From the **Cloud provider** dropdown, select your cloud provider.
1. Provide the name of your storage bucket for the **Name** field. If you have a [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}) or [Self-managed]({{< relref "/guides/hosting/hosting-options/self-managed.md" >}}) instance on Azure, provide the values for **Account name** and **Container name** fields.
1. (Optional) Provide the bucket sub-path in the optional **Path** field. Do this if you would not like W&B to store any files in a folder at the root of the bucket.
1. (Optional if using AWS bucket) Provide the ARN of your KMS encryption key for the **KMS key ARN** field.
1. (Optional if using Azure bucket) Provide the values for the **Tenant ID** and the **Managed Identity Client ID** fields.
1. (Optional on [SaaS Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}})) Optionally invite team members when creating the team.
1. Press the **Create Team** button.

{{< img src="/images/hosting/prod_setup_secure_storage.png" alt="" >}}

An error or warning appears at the bottom of the page if there are issues accessing the bucket or the bucket has invalid settings.
{{% /tab %}}

{{% tab header="Instance level" value="instance"%}}
{{% alert %}}
Before changing the instance level bucket storage, ensure that all data is synced over from the previous instance level bucket. This gives the W&B Server access to all data it had access to before the change.

For [Dedicated Cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}) if you need to change the original bucket that the instance was deployed with, contact [support](mailto:support@wandb.com) for assistance with migrating data to the new bucket.
{{% /alert %}}

To make changes to the instance level bucket storage for your W&B Server:

1. Log in to W&B as a user with the `admin` role.
1. Click the user icon at the top, then click **System Console**.
1. Go to **Settings** > **System Connections**.
1. In the **Bucket Storage** section, ensure the identity in the **Identity** field is granted access to the new bucket.
1. Select the **Provider**.
1. Enter the new **Bucket Name**.
1. Optionally, enter the **Path** to use in the new bucket.
1. Click **Save**
{{% /tab %}}
{{< /tabpane >}}
