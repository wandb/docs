---
menu:
  default:
    identifier: weave
title: W&B Weave
weight: 4
---

{{< cta-button colabLink="http://wandb.me/weave_colab" >}}

Weave is a lightweight toolkit for tracking and evaluating LLM applications. Use W&B Weave to visualize and inspect the execution flow of your LLMs, analyze the inputs and outputs of your LLMs, view the intermediate results and securely store and manage your prompts and LLM chain configurations.

{{< img src="/images/weave/weave-hero.png" alt="" >}}

With W&B Weave, you can:
* Log and debug language model inputs, outputs, and traces
* Build rigorous, apples-to-apples evaluations for language model use cases
* Organize all the information generated across the LLM workflow, from experimentation to evaluations to production

{{% alert %}}
Looking for Weave docs? See the [W&B Weave Docs](https://weave-docs.wandb.ai/).
{{% /alert %}}

## How to get started 
Depending on your use case, explore the following resources to get started with W&B Weave:

* [Quickstart: Track inputs and outputs of LLM calls](https://wandb.github.io/weave/quickstart)
* [Build an Evaluation pipeline tutorial](https://wandb.github.io/weave/tutorial-eval)
* [Model-Based Evaluation of RAG applications tutorial](https://wandb.github.io/weave/tutorial-rag)
