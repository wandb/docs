---
title: PyTorch
menu:
  tutorials:
    identifier: ko-tutorials-integration-tutorials-pytorch
    parent: integration-tutorials
weight: 1
---

{{< cta-button colabLink="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Simple_PyTorch_Integration.ipynb" >}}

[Weights & Biases](https://wandb.com)λ¥Ό μ‚¬μ©ν•μ—¬ κΈ°κ³„ ν•™μµ μ‹¤ν— μ¶”μ , λ°μ΄ν„°μ…‹ λ²„μ „ κ΄€λ¦¬ λ° ν”„λ΅μ νΈ ν‘μ—…μ„ μν–‰ν•μ„Έμ”.

{{< img src="/images/tutorials/huggingface-why.png" alt="" >}}

## μ΄ λ…ΈνΈλ¶μ—μ„ λ‹¤λ£¨λ” λ‚΄μ©

Weights & Biases λ¥Ό PyTorch μ½”λ“μ™€ ν†µν•©ν•μ—¬ νμ΄ν”„λΌμΈμ— μ‹¤ν— μ¶”μ μ„ μ¶”κ°€ν•λ” λ°©λ²•μ„ λ³΄μ—¬μ¤λ‹λ‹¤.

{{< img src="/images/tutorials/pytorch.png" alt="" >}}

```python
# λΌμ΄λΈλ¬λ¦¬ κ°€μ Έμ¤κΈ°
import wandb

# μƒ μ‹¤ν— μ‹μ‘
wandb.init(project="new-sota-model")

# configλ΅ ν•μ΄νΌνλΌλ―Έν„° μ‚¬μ „μ„ μΊ΅μ²ν•©λ‹λ‹¤.
wandb.config = {"learning_rate": 0.001, "epochs": 100, "batch_size": 128}

# λ¨λΈ λ° λ°μ΄ν„° μ„¤μ •
model, dataloader = get_model(), get_data()

# μ„ νƒ μ‚¬ν•­: κ·Έλλ””μ–ΈνΈ μ¶”μ 
wandb.watch(model)

for batch in dataloader:
  metrics = model.training_step()
  # λ¨λΈ μ„±λ¥μ„ μ‹κ°ν™”ν•κΈ° μ„ν•΄ νΈλ μ΄λ‹ λ£¨ν”„ λ‚΄μ—μ„ λ©”νΈλ¦­μ„ κΈ°λ΅ν•©λ‹λ‹¤.
  wandb.log(metrics)

# μ„ νƒ μ‚¬ν•­: λ§μ§€λ§‰μ— λ¨λΈ μ €μ¥
model.to_onnx()
wandb.save("model.onnx")
```

[λΉ„λ””μ¤ νν† λ¦¬μ–Ό](http://wandb.me/pytorch-video)μ„ λ”°λΌν•μ„Έμ”.

**μ°Έκ³ **: _Step_μΌλ΅ μ‹μ‘ν•λ” μ„Ήμ…μ€ κΈ°μ΅΄ νμ΄ν”„λΌμΈμ— W&B λ¥Ό ν†µν•©ν•λ” λ° ν•„μ”ν• μ „λ¶€μ…λ‹λ‹¤. λ‚λ¨Έμ§€λ” λ°μ΄ν„°λ¥Ό λ΅λ“ν•κ³  λ¨λΈμ„ μ •μν•©λ‹λ‹¤.

## μ„¤μΉ, κ°€μ Έμ¤κΈ° λ° λ΅κ·ΈμΈ

```python
import os
import random

import numpy as np
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from tqdm.auto import tqdm

# κ²°μ •λ΅ μ  λ™μ‘ λ³΄μ¥
torch.backends.cudnn.deterministic = True
random.seed(hash("setting random seeds") % 2**32 - 1)
np.random.seed(hash("improves reproducibility") % 2**32 - 1)
torch.manual_seed(hash("by removing stochasticity") % 2**32 - 1)
torch.cuda.manual_seed_all(hash("so runs are repeatable") % 2**32 - 1)

# μ¥μΉ κµ¬μ„±
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# MNIST λ―Έλ¬ λ©λ΅μ—μ„ λλ¦° λ―Έλ¬ μ κ±°
torchvision.datasets.MNIST.mirrors = [mirror for mirror in torchvision.datasets.MNIST.mirrors
                                      if not mirror.startswith("http://yann.lecun.com")]
```

### 0οΈβƒ£ 0λ‹¨κ³„: W&B μ„¤μΉ

μ‹μ‘ν•λ ¤λ©΄ λΌμ΄λΈλ¬λ¦¬λ¥Ό κ°€μ Έμ™€μ•Ό ν•©λ‹λ‹¤.
`wandb`λ” `pip`λ¥Ό μ‚¬μ©ν•μ—¬ μ‰½κ² μ„¤μΉν•  μ μμµλ‹λ‹¤.

```python
!pip install wandb onnx -Uq
```

### 1οΈβƒ£ 1λ‹¨κ³„: W&B κ°€μ Έμ¤κΈ° λ° λ΅κ·ΈμΈ

λ°μ΄ν„°λ¥Ό μ›Ή μ„λΉ„μ¤μ— κΈ°λ΅ν•λ ¤λ©΄
λ΅κ·ΈμΈν•΄μ•Ό ν•©λ‹λ‹¤.

W&B λ¥Ό μ²μ μ‚¬μ©ν•λ” κ²½μ°
ν‘μ‹λλ” λ§ν¬μ—μ„ λ¬΄λ£ κ³„μ •μ— κ°€μ…ν•΄μ•Ό ν•©λ‹λ‹¤.

```
import wandb

wandb.login()
```

## μ‹¤ν— λ° νμ΄ν”„λΌμΈ μ •μ

### `wandb.init`λ΅ λ©”νƒ€λ°μ΄ν„° λ° ν•μ΄νΌνλΌλ―Έν„° μ¶”μ 

ν”„λ΅κ·Έλλ° λ°©μ‹μΌλ΅ κ°€μ¥ λ¨Όμ € ν•λ” μΌμ€ μ‹¤ν—μ„ μ •μν•λ” κ²ƒμ…λ‹λ‹¤.
ν•μ΄νΌνλΌλ―Έν„°λ” λ¬΄μ—‡μ…λ‹κΉ? μ΄ runκ³Ό κ΄€λ ¨λ λ©”νƒ€λ°μ΄ν„°λ” λ¬΄μ—‡μ…λ‹κΉ?

μ΄ μ •λ³΄λ¥Ό `config` μ‚¬μ „μ— μ €μ¥ν•λ” κ²ƒμ€ λ§¤μ° μΌλ°μ μΈ μ›ν¬ν”λ΅μ°μ…λ‹λ‹¤.
(λλ” μ μ‚¬ν• μ¤λΈμ νΈ)
κ·Έλ° λ‹¤μ ν•„μ”μ— λ”°λΌ μ—‘μ„Έμ¤ν•©λ‹λ‹¤.

μ΄ μμ—μ„λ” λ‡ κ°€μ§€ ν•μ΄νΌνλΌλ―Έν„°λ§ λ³€κ²½ν•λ„λ΅ ν•κ³ 
λ‚λ¨Έμ§€λ” μ§μ ‘ μ½”λ”©ν•©λ‹λ‹¤.
κ·Έλ¬λ‚ λ¨λΈμ λ¨λ“  λ¶€λ¶„μ΄ `config`μ μΌλ¶€κ°€ λ  μ μμµλ‹λ‹¤.

λν• μΌλ¶€ λ©”νƒ€λ°μ΄ν„°λ„ ν¬ν•¨ν•©λ‹λ‹¤. MNIST λ°μ΄ν„°μ…‹κ³Ό μ»¨λ³Όλ£¨μ…
μ•„ν‚¤ν…μ²λ¥Ό μ‚¬μ©ν•κ³  μμµλ‹λ‹¤. λ‚μ¤‘μ— λ™μΌν• projectμ—μ„ CIFARμ— λ€ν• μ™„μ „ μ—°κ²° μ•„ν‚¤ν…μ²λ΅ μ‘μ—…ν•λ” κ²½μ°
runμ„ λ¶„λ¦¬ν•λ” λ° λ„μ›€μ΄ λ©λ‹λ‹¤.

```python
config = dict(
    epochs=5,
    classes=10,
    kernels=[16, 32],
    batch_size=128,
    learning_rate=0.005,
    dataset="MNIST",
    architecture="CNN")
```

μ΄μ  μ „μ²΄ νμ΄ν”„λΌμΈμ„ μ •μν•΄ λ³΄κ² μµλ‹λ‹¤.
μ΄λ” λ¨λΈ νΈλ μ΄λ‹μ— λ§¤μ° μΌλ°μ μ…λ‹λ‹¤.

1. λ¨Όμ € λ¨λΈ, κ΄€λ ¨ λ°μ΄ν„° λ° μµν‹°λ§μ΄μ €λ¥Ό `make`ν• λ‹¤μ
2. λ¨λΈμ„ μ μ ν•κ² `train`ν•κ³  λ§μ§€λ§‰μΌλ΅
3. `test`ν•μ—¬ νΈλ μ΄λ‹μ΄ μ–΄λ–»κ² μ§„ν–‰λμ—λ”μ§€ ν™•μΈν•©λ‹λ‹¤.

μ•„λμ—μ„ μ΄λ¬ν• ν•¨μλ¥Ό κµ¬ν„ν•©λ‹λ‹¤.

```python
def model_pipeline(hyperparameters):

    # wandbμ—κ² μ‹μ‘ν•λΌκ³  μ•λ¦½λ‹λ‹¤.
    with wandb.init(project="pytorch-demo", config=hyperparameters):
      # wandb.configλ¥Ό ν†µν•΄ λ¨λ“  HPμ— μ—‘μ„Έμ¤ν•λ―€λ΅ λ΅κΉ…μ΄ μ‹¤ν–‰κ³Ό μΌμΉν•©λ‹λ‹¤.
      config = wandb.config

      # λ¨λΈ, λ°μ΄ν„° λ° μµμ ν™” λ¬Έμ  λ§λ“¤κΈ°
      model, train_loader, test_loader, criterion, optimizer = make(config)
      print(model)

      # λ¨λΈμ„ νΈλ μ΄λ‹ν•λ” λ° μ‚¬μ©ν•©λ‹λ‹¤.
      train(model, train_loader, criterion, optimizer, config)

      # μµμΆ… μ„±λ¥ ν…μ¤νΈ
      test(model, test_loader)

    return model
```

ν‘μ¤€ νμ΄ν”„λΌμΈκ³Όμ μ μΌν• μ°¨μ΄μ μ€
λ¨λ“  κ²ƒμ΄ `wandb.init` μ»¨ν…μ¤νΈ λ‚΄μ—μ„ λ°μƒν•λ‹¤λ” κ²ƒμ…λ‹λ‹¤.
μ΄ ν•¨μλ¥Ό νΈμ¶ν•λ©΄ μ½”λ“μ™€ μ„λ²„ κ°„μ ν†µμ‹  λΌμΈμ΄ μ„¤μ •λ©λ‹λ‹¤.

`config` μ‚¬μ „μ„ `wandb.init`μ— μ „λ‹¬ν•λ©΄
ν•΄λ‹Ή μ •λ³΄κ°€ μ¦‰μ‹ κΈ°λ΅λλ―€λ΅
μ‹¤ν—μ— μ‚¬μ©ν•  ν•μ΄νΌνλΌλ―Έν„° κ°’μ„ ν•­μƒ μ• μ μμµλ‹λ‹¤.

μ„ νƒν•κ³  κΈ°λ΅ν• κ°’μ΄ ν•­μƒ λ¨λΈμ—μ„ μ‚¬μ©λλ„λ΅ ν•λ ¤λ©΄
μ¤λΈμ νΈμ `wandb.config` λ³µμ‚¬λ³Έμ„ μ‚¬μ©ν•λ” κ²ƒμ΄ μΆ‹μµλ‹λ‹¤.
λ‡ κ°€μ§€ μλ¥Ό λ³΄λ ¤λ©΄ μ•„λ `make`μ μ •μλ¥Ό ν™•μΈν•μ„Έμ”.

> *μ°Έκ³ *: μ½”λ“λ¥Ό λ³„λ„μ ν”„λ΅μ„Έμ¤μ—μ„ μ‹¤ν–‰ν•λ„λ΅ μ£Όμν•©λ‹λ‹¤.
λ”°λΌμ„ λ‹Ήμ‚¬μ λ¬Έμ 
(μ: κ±°λ€ν• λ°”λ‹¤ κ΄΄λ¬Όμ΄ λ°μ΄ν„° μ„Όν„°λ¥Ό κ³µκ²©ν•λ” κ²½μ°)κ°€ μ½”λ“λ¥Ό μ¶©λμ‹ν‚¤μ§€ μ•μµλ‹λ‹¤.
ν¬λΌμΌ„μ΄ μ‹¬ν•΄λ΅ λμ•„κ° λ•μ™€ κ°™μ΄ λ¬Έμ κ°€ ν•΄κ²°λλ©΄
`wandb sync`λ΅ λ°μ΄ν„°λ¥Ό κΈ°λ΅ν•  μ μμµλ‹λ‹¤.

```python
def make(config):
    # λ°μ΄ν„° λ§λ“¤κΈ°
    train, test = get_data(train=True), get_data(train=False)
    train_loader = make_loader(train, batch_size=config.batch_size)
    test_loader = make_loader(test, batch_size=config.batch_size)

    # λ¨λΈ λ§λ“¤κΈ°
    model = ConvNet(config.kernels, config.classes).to(device)

    # μ†μ‹¤ λ° μµν‹°λ§μ΄μ € λ§λ“¤κΈ°
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(
        model.parameters(), lr=config.learning_rate)
    
    return model, train_loader, test_loader, criterion, optimizer
```

### λ°μ΄ν„° λ΅λ”© λ° λ¨λΈ μ •μ

μ΄μ  λ°μ΄ν„°λ¥Ό λ΅λ“ν•λ” λ°©λ²•κ³Ό λ¨λΈ λ¨μ–‘μ„ μ§€μ •ν•΄μ•Ό ν•©λ‹λ‹¤.

μ΄ λ¶€λ¶„μ€ λ§¤μ° μ¤‘μ”ν•μ§€λ§
`wandb`κ°€ μ—†μ–΄λ„ λ‘κ°™μΌλ―€λ΅
μμ„Έν μ„¤λ…ν•μ§€ μ•κ² μµλ‹λ‹¤.

```python
def get_data(slice=5, train=True):
    full_dataset = torchvision.datasets.MNIST(root=".",
                                              train=train, 
                                              transform=transforms.ToTensor(),
                                              download=True)
    #  [::slice]λ΅ μ¬λΌμ΄μ‹±ν•λ” κ²ƒκ³Ό λ™μΌ
    sub_dataset = torch.utils.data.Subset(
      full_dataset, indices=range(0, len(full_dataset), slice))
    
    return sub_dataset


def make_loader(dataset, batch_size):
    loader = torch.utils.data.DataLoader(dataset=dataset,
                                         batch_size=batch_size, 
                                         shuffle=True,
                                         pin_memory=True, num_workers=2)
    return loader
```

λ¨λΈμ„ μ •μν•λ” κ²ƒμ€ μΌλ°μ μΌλ΅ μ¬λ―Έμλ” λ¶€λ¶„μ…λ‹λ‹¤.

κ·Έλ¬λ‚ `wandb`μ—μ„λ” μ•„λ¬΄κ²ƒλ„ λ³€κ²½λμ§€ μ•μΌλ―€λ΅
ν‘μ¤€ ConvNet μ•„ν‚¤ν…μ²λ¥Ό κ³ μν•  κ²ƒμ…λ‹λ‹¤.

μ£Όμ €ν•μ§€ λ§κ³  μ΄λ¦¬μ €λ¦¬ λ§μ§€μ‘κ±°λ¦¬κ³  λ‡ κ°€μ§€ experimentsλ¥Ό μ‹λ„ν•΄ λ³΄μ„Έμ”.
λ¨λ“  κ²°κ³Όλ” [wandb.ai](https://wandb.ai)μ— κΈ°λ΅λ©λ‹λ‹¤.

```python
# κΈ°μ΅΄ λ° μ»¨λ³Όλ£¨μ… μ‹ κ²½λ§

class ConvNet(nn.Module):
    def __init__(self, kernels, classes=10):
        super(ConvNet, self).__init__()
        
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, kernels[0], kernel_size=5, stride=1, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer2 = nn.Sequential(
            nn.Conv2d(16, kernels[1], kernel_size=5, stride=1, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.fc = nn.Linear(7 * 7 * kernels[-1], classes)
        
    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.reshape(out.size(0), -1)
        out = self.fc(out)
        return out
```

### νΈλ μ΄λ‹ λ΅μ§ μ •μ

`model_pipeline`μ—μ„ κ³„μ† μ§„ν–‰ν•μ—¬ `train` λ°©λ²•μ„ μ§€μ •ν•  μ‹κ°„μ…λ‹λ‹¤.

μ—¬κΈ°μ„ λ‘ κ°μ `wandb` ν•¨μκ°€ μ‚¬μ©λ©λ‹λ‹¤. `watch` λ° `log`μ…λ‹λ‹¤.

## `wandb.watch`λ΅ κ·Έλλ””μ–ΈνΈλ¥Ό μ¶”μ ν•κ³  `wandb.log`λ΅ λ‹¤λ¥Έ λ¨λ“  κ²ƒμ„ μ¶”μ ν•©λ‹λ‹¤.

`wandb.watch`λ” λ¨λΈμ κ·Έλλ””μ–ΈνΈμ™€ νλΌλ―Έν„°λ¥Ό κΈ°λ΅ν•©λ‹λ‹¤.
νΈλ μ΄λ‹μ λ¨λ“  `log_freq` λ‹¨κ³„.

νΈλ μ΄λ‹μ„ μ‹μ‘ν•κΈ° μ „μ— νΈμ¶ν•κΈ°λ§ ν•λ©΄ λ©λ‹λ‹¤.

λ‚λ¨Έμ§€ νΈλ μ΄λ‹ μ½”λ“λ” λ™μΌν•κ² μ μ§€λ©λ‹λ‹¤.
μ—ν¬ν¬μ™€ λ°°μΉλ¥Ό λ°λ³µν•κ³ ,
forward λ° backward ν¨μ¤λ¥Ό μ‹¤ν–‰ν•κ³ 
`μµν‹°λ§μ΄μ €`λ¥Ό μ μ©ν•©λ‹λ‹¤.

```python
def train(model, loader, criterion, optimizer, config):
    # wandbμ—κ² λ¨λΈμ΄ λ¬΄μ—‡μ„ ν•λ”μ§€ κ°μ‹ν•λ„λ΅ μ§€μ‹ν•©λ‹λ‹¤. κ·Έλλ””μ–ΈνΈ, κ°€μ¤‘μΉ λ“±.
    wandb.watch(model, criterion, log="all", log_freq=10)

    # wandbλ΅ νΈλ μ΄λ‹μ„ μ‹¤ν–‰ν•κ³  μ¶”μ ν•©λ‹λ‹¤.
    total_batches = len(loader) * config.epochs
    example_ct = 0  # ν™•μΈλ μμ  μ
    batch_ct = 0
    for epoch in tqdm(range(config.epochs)):
        for _, (images, labels) in enumerate(loader):

            loss = train_batch(images, labels, model, optimizer, criterion)
            example_ct +=  len(images)
            batch_ct += 1

            # 25λ²μ§Έλ§λ‹¤ λ©”νΈλ¦­ λ³΄κ³ 
            if ((batch_ct + 1) % 25) == 0:
                train_log(loss, example_ct, epoch)


def train_batch(images, labels, model, optimizer, criterion):
    images, labels = images.to(device), labels.to(device)
    
    # Forward ν¨μ¤ β΅
    outputs = model(images)
    loss = criterion(outputs, labels)
    
    # Backward ν¨μ¤ β¬…
    optimizer.zero_grad()
    loss.backward()

    # μµν‹°λ§μ΄μ €λ΅ λ‹¨κ³„
    optimizer.step()

    return loss
```

μ μΌν• μ°¨μ΄μ μ€ λ΅κΉ… μ½”λ“μ— μμµλ‹λ‹¤.
μ΄μ „μ—λ” ν„°λ―Έλ„μ— μ¶λ ¥ν•μ—¬ λ©”νΈλ¦­μ„ λ³΄κ³ ν–μ„ μ μμ§€λ§
μ΄μ  λ™μΌν• μ •λ³΄λ¥Ό `wandb.log`μ— μ „λ‹¬ν•©λ‹λ‹¤.

`wandb.log`λ” ν‚¤λ΅ λ¬Έμμ—΄μ΄ μλ” μ‚¬μ „μ„ μμƒν•©λ‹λ‹¤.
μ΄λ¬ν• λ¬Έμμ—΄μ€ κΈ°λ΅λλ” μ¤λΈμ νΈλ¥Ό μ‹λ³„ν•λ©° κ°’μ„ κµ¬μ„±ν•©λ‹λ‹¤.
μ„ νƒμ μΌλ΅ νΈλ μ΄λ‹μ `step`μ„ κΈ°λ΅ν•  μλ„ μμµλ‹λ‹¤.

> *μ°Έκ³ *: λ¨λΈμ—μ„ ν™•μΈν• μμ  μλ¥Ό μ‚¬μ©ν•λ” κ²ƒμ„ μΆ‹μ•„ν•©λ‹λ‹¤.
μ΄λ ‡κ² ν•λ©΄ λ°°μΉ ν¬κΈ° κ°„μ— λ” μ‰½κ² λΉ„κµν•  μ μκΈ° λ•λ¬Έμ…λ‹λ‹¤.
κ·Έλ¬λ‚ μ›μ‹ λ‹¨κ³„ λλ” λ°°μΉ μλ¥Ό μ‚¬μ©ν•  μ μμµλ‹λ‹¤. νΈλ μ΄λ‹ runμ΄ λ” κΈ΄ κ²½μ° `epoch`λ³„λ΅ κΈ°λ΅ν•λ” κ²ƒμ΄ ν•©λ¦¬μ μΌ μλ„ μμµλ‹λ‹¤.

```python
def train_log(loss, example_ct, epoch):
    # μ—¬κΈ°μ„ λ§λ²•μ΄ μΌμ–΄λ‚©λ‹λ‹¤.
    wandb.log({"epoch": epoch, "loss": loss}, step=example_ct)
    print(f"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}")
```

### ν…μ¤νΈ λ΅μ§ μ •μ

λ¨λΈ νΈλ μ΄λ‹μ΄ μ™„λ£λλ©΄ ν…μ¤νΈν•κ³  μ‹¶μµλ‹λ‹¤.
ν”„λ΅λ•μ…μ—μ„ μΌλ¶€ μƒλ΅μ΄ λ°μ΄ν„°μ— λ€ν•΄ μ‹¤ν–‰ν•κ±°λ‚
μΌλ¶€ μ§μ ‘ νλ μ΄ν…λ μμ μ— μ μ©ν•©λ‹λ‹¤.

## (μ„ νƒ μ‚¬ν•­) `wandb.save` νΈμ¶

λ¨λΈμ μ•„ν‚¤ν…μ²λ¥Ό μ €μ¥ν•λ” κ²ƒλ„ μΆ‹μ€ μ‹κΈ°μ…λ‹λ‹¤.
κ·Έλ¦¬κ³  μµμΆ… νλΌλ―Έν„°λ¥Ό λ””μ¤ν¬μ— μ €μ¥ν•©λ‹λ‹¤.
μµλ€ν•μ νΈν™μ„±μ„ μ„ν•΄
[ONNX(Open Neural Network eXchange) ν•μ‹](https://onnx.ai/)μΌλ΅ λ¨λΈμ„ `export`ν•©λ‹λ‹¤.

ν•΄λ‹Ή νμΌ μ΄λ¦„μ„ `wandb.save`μ— μ „λ‹¬ν•λ©΄ λ¨λΈ νλΌλ―Έν„°κ°€
W&B μ„λ²„μ— μ €μ¥λ©λ‹λ‹¤. λ” μ΄μƒ `.h5` λλ” `.pb`κ°€
μ–΄λ–¤ νΈλ μ΄λ‹ runμ— ν•΄λ‹Ήν•λ”μ§€ μ¶”μ ν•  ν•„μ”κ°€ μ—†μµλ‹λ‹¤.

λ¨λΈ μ €μ¥, λ²„μ „ κ΄€λ¦¬ λ° λ°°ν¬λ¥Ό μ„ν• κ³ κΈ‰ `wandb` κΈ°λ¥μ— λ€ν• μμ„Έν• λ‚΄μ©μ€
[Artifacts ν΄](https://www.wandb.com/artifacts)μ„ ν™•μΈν•μ„Έμ”.

```python
def test(model, test_loader):
    model.eval()

    # μΌλ¶€ ν…μ¤νΈ μμ μ—μ„ λ¨λΈ μ‹¤ν–‰
    with torch.no_grad():
        correct, total = 0, 0
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        print(f"Accuracy of the model on the {total} " +
              f"test images: {correct / total:%}")
        
        wandb.log({"test_accuracy": correct / total})

    # κµν™ κ°€λ¥ν• ONNX ν•μ‹μΌλ΅ λ¨λΈ μ €μ¥
    torch.onnx.export(model, images, "model.onnx")
    wandb.save("model.onnx")
```

### νΈλ μ΄λ‹μ„ μ‹¤ν–‰ν•κ³  wandb.aiμ—μ„ μ‹¤μ‹κ°„μΌλ΅ λ©”νΈλ¦­μ„ ν™•μΈν•μ„Έμ”.

μ „μ²΄ νμ΄ν”„λΌμΈμ„ μ •μν•κ³ 
λ‡ μ¤„μ W&B μ½”λ“λ¥Ό μ¶”κ°€ν–μΌλ―€λ΅
μ™„μ „ν μ¶”μ λ experimentλ¥Ό μ‹¤ν–‰ν•  μ¤€λΉ„κ°€ λμ—μµλ‹λ‹¤.

λ‡ κ°€μ§€ λ§ν¬λ¥Ό λ³΄κ³ ν•©λ‹λ‹¤.
λ‹Ήμ‚¬μ λ¬Έμ„,
projectμ λ¨λ“  runμ„ κµ¬μ„±ν•λ” Project νμ΄μ§€,
μ΄ runμ κ²°κ³Όκ°€ μ €μ¥λ  Run νμ΄μ§€.

Run νμ΄μ§€λ΅ μ΄λ™ν•μ—¬ λ‹¤μ νƒ­μ„ ν™•μΈν•μ„Έμ”.

1. **Charts**: λ¨λΈ κ·Έλλ””μ–ΈνΈ, νλΌλ―Έν„° κ°’ λ° μ†μ‹¤μ΄ νΈλ μ΄λ‹ λ‚΄λ‚΄ κΈ°λ΅λ©λ‹λ‹¤.
2. **System**: λ””μ¤ν¬ I/O μ‚¬μ©λ¥ , CPU λ° GPU λ©”νΈλ¦­(μ¨λ„κ°€ μΉμ†λ” κ²ƒμ„ μ§€μΌλ³΄μ„Έμ” π”¥) λ“±μ„ ν¬ν•¨ν• λ‹¤μ–‘ν• μ‹μ¤ν… λ©”νΈλ¦­μ΄ ν¬ν•¨λμ–΄ μμµλ‹λ‹¤.
3. **Logs**: νΈλ μ΄λ‹ μ¤‘μ— ν‘μ¤€ μ¶λ ¥μΌλ΅ ν‘Έμ‹λ λ¨λ“  ν•­λ©μ μ‚¬λ³Έμ΄ μμµλ‹λ‹¤.
4. **Files**: νΈλ μ΄λ‹μ΄ μ™„λ£λλ©΄ `model.onnx`λ¥Ό ν΄λ¦­ν•μ—¬ [Netron λ¨λΈ λ·°μ–΄](https://github.com/lutzroeder/netron)λ΅ λ„¤νΈμ›ν¬λ¥Ό λ³Ό μ μμµλ‹λ‹¤.

runμ΄ μ™„λ£λλ©΄ `with wandb.init` λΈ”λ΅μ΄ μΆ…λ£λ  λ•
μ…€ μ¶λ ¥μ— κ²°κ³Ό μ”μ•½λ„ μ¶λ ¥ν•©λ‹λ‹¤.

```python
# νμ΄ν”„λΌμΈμΌλ΅ λ¨λΈ λΉλ“, νΈλ μ΄λ‹ λ° λ¶„μ„
model = model_pipeline(config)
```

### Sweepsλ΅ ν•μ΄νΌνλΌλ―Έν„° ν…μ¤νΈ

μ΄ μμ—μ„λ” λ‹¨μΌ ν•μ΄νΌνλΌλ―Έν„° μ„ΈνΈλ§ μ‚΄ν΄λ³΄μ•μµλ‹λ‹¤.
κ·Έλ¬λ‚ λ€λ¶€λ¶„μ ML μ›ν¬ν”λ΅μ°μ—μ„ μ¤‘μ”ν• λ¶€λ¶„μ€
μ—¬λ¬ ν•μ΄νΌνλΌλ―Έν„°λ¥Ό λ°λ³µν•λ” κ²ƒμ…λ‹λ‹¤.

Weights & Biases Sweepsλ¥Ό μ‚¬μ©ν•μ—¬ ν•μ΄νΌνλΌλ―Έν„° ν…μ¤νΈλ¥Ό μλ™ν™”ν•κ³  κ°€λ¥ν• λ¨λΈ λ° μµμ ν™” μ „λµ κ³µκ°„μ„ νƒμƒ‰ν•  μ μμµλ‹λ‹¤.

## [W&B Sweepsλ¥Ό μ‚¬μ©ν•μ—¬ PyTorchμ—μ„ ν•μ΄νΌνλΌλ―Έν„° μµμ ν™” ν™•μΈ](http://wandb.me/sweeps-colab)

Weights & Biasesλ΅ ν•μ΄νΌνλΌλ―Έν„° μ¤μ•μ„ μ‹¤ν–‰ν•λ” κ²ƒμ€ λ§¤μ° μ‰½μµλ‹λ‹¤. λ‹¤μκ³Ό κ°™μ€ 3κ°€μ§€ κ°„λ‹¨ν• λ‹¨κ³„κ°€ μμµλ‹λ‹¤.

1. **μ¤μ• μ •μ:** κ²€μƒ‰ν•  νλΌλ―Έν„°, κ²€μƒ‰ μ „λµ, μµμ ν™” λ©”νΈλ¦­ λ“±μ„ μ§€μ •ν•λ” μ‚¬μ „ λλ” [YAML νμΌ]({{< relref path="/guides/models/sweeps/define-sweep-configuration" lang="ko" >}})μ„ λ§λ“¤μ–΄ μν–‰ν•©λ‹λ‹¤.

2. **μ¤μ• μ΄κΈ°ν™”:**
`sweep_id = wandb.sweep(sweep_config)`

3. **μ¤μ• μ—μ΄μ „νΈ μ‹¤ν–‰:**
`wandb.agent(sweep_id, function=train)`

ν•μ΄νΌνλΌλ―Έν„° μ¤μ•μ„ μ‹¤ν–‰ν•λ” λ° ν•„μ”ν• μ „λ¶€μ…λ‹λ‹¤.

{{< img src="/images/tutorials/pytorch-2.png" alt="" >}}

## μμ  κ°¤λ¬λ¦¬

[κ°¤λ¬λ¦¬ β†’](https://app.wandb.ai/gallery)μ—μ„ W&Bλ΅ μ¶”μ ν•κ³  μ‹κ°ν™”ν• ν”„λ΅μ νΈμ μμ λ¥Ό ν™•μΈν•μ„Έμ”.

## κ³ κΈ‰ μ„¤μ •
1. [ν™κ²½ λ³€μ]({{< relref path="/guides/hosting/env-vars/" lang="ko" >}}): κ΄€λ¦¬ν• ν΄λ¬μ¤ν„°μ—μ„ νΈλ μ΄λ‹μ„ μ‹¤ν–‰ν•  μ μλ„λ΅ ν™κ²½ λ³€μμ— API ν‚¤λ¥Ό μ„¤μ •ν•©λ‹λ‹¤.
2. [μ¤ν”„λΌμΈ λ¨λ“]({{< relref path="/support/run_wandb_offline.md" lang="ko" >}}): `dryrun` λ¨λ“λ¥Ό μ‚¬μ©ν•μ—¬ μ¤ν”„λΌμΈμΌλ΅ νΈλ μ΄λ‹ν•κ³  λ‚μ¤‘μ— κ²°κ³Όλ¥Ό λ™κΈ°ν™”ν•©λ‹λ‹¤.
3. [On-prem]({{< relref path="/guides/hosting/hosting-options/self-managed" lang="ko" >}}): ν”„λΌμ΄λΉ— ν΄λΌμ°λ“ λλ” μμ²΄ μΈν”„λΌμ μ—μ–΄ κ°­ μ„λ²„μ— W&Bλ¥Ό μ„¤μΉν•©λ‹λ‹¤. λ‹Ήμ‚¬λ” ν•™κ³„μ—μ„ μ—”ν„°ν”„λΌμ΄μ¦ ν€μ— μ΄λ¥΄κΈ°κΉμ§€ λ¨λ“  μ‚¬λμ„ μ„ν• λ΅μ»¬ μ„¤μΉλ¥Ό μ κ³µν•©λ‹λ‹¤.
4. [Sweeps]({{< relref path="/guides/models/sweeps/" lang="ko" >}}): νλ‹μ„ μ„ν• κ²½λ‰ ν΄μ„ μ‚¬μ©ν•μ—¬ ν•μ΄νΌνλΌλ―Έν„° κ²€μƒ‰μ„ λΉ λ¥΄κ² μ„¤μ •ν•©λ‹λ‹¤.
