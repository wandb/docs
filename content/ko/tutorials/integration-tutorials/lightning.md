---
title: PyTorch Lightning
menu:
  tutorials:
    identifier: ko-tutorials-integration-tutorials-lightning
    parent: integration-tutorials
weight: 2
---

{{< cta-button colabLink="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch-lightning/Image_Classification_using_PyTorch_Lightning.ipynb" >}}
PyTorch Lightningì„ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•´ë´…ì‹œë‹¤. ì½”ë“œì˜ ê°€ë…ì„±ê³¼ ì¬í˜„ì„±ì„ ë†’ì´ê¸° ìœ„í•´ [ì´ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ](https://lightning.ai/docs/pytorch/stable/starter/style_guide.html)ë¥¼ ë”°ë¼ ì§„í–‰í•©ë‹ˆë‹¤. ê´€ë ¨ ì„¤ëª…ì„ [ì—¬ê¸°](https://wandb.ai/wandb/wandb-lightning/reports/Image-Classification-using-PyTorch-Lightning--VmlldzoyODk1NzY)ì—ì„œ í™•ì¸í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

## PyTorch Lightning ë° W&B í™˜ê²½ ì„¤ì •

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” PyTorch Lightningê³¼ W&Bê°€ í•„ìš”í•©ë‹ˆë‹¤.

```shell
pip install lightning -q
pip install wandb -qU
```

```python
import lightning.pytorch as pl

# ì¦ê²¨ ì‚¬ìš©í•˜ëŠ” ê¸°ê³„í•™ìŠµ ì¶”ì  íˆ´
from lightning.pytorch.loggers import WandbLogger

import torch
from torch import nn
from torch.nn import functional as F
from torch.utils.data import random_split, DataLoader

from torchmetrics import Accuracy

from torchvision import transforms
from torchvision.datasets import CIFAR10

import wandb
```

ì´ì œ wandb ê³„ì •ì— ë¡œê·¸ì¸í•´ì•¼ í•©ë‹ˆë‹¤.

```
wandb.login()
```

## DataModule - ìš°ë¦¬ê°€ ì›í•˜ë˜ ë°ì´í„° íŒŒì´í”„ë¼ì¸

DataModulesëŠ” LightningModuleë¡œë¶€í„° ë°ì´í„° ê´€ë ¨ í›…ì„ ë¶„ë¦¬í•´ì„œ ë°ì´í„°ì…‹ì— ë…ë¦½ì ì¸ ëª¨ë¸ì„ ê°œë°œí•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.

ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ í•˜ë‚˜ì˜ ê³µìœ  ê°€ëŠ¥í•œ, ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í´ë˜ìŠ¤ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤. datamoduleì€ PyTorchì—ì„œì˜ ë°ì´í„° ì²˜ë¦¬ì— í•„ìš”í•œ 5ê°€ì§€ ë‹¨ê³„ë¥¼ ëª¨ë‘ ìº¡ìŠí™”í•©ë‹ˆë‹¤:
- ë‹¤ìš´ë¡œë“œ / í† í°í™” / ì²˜ë¦¬.
- ë°ì´í„° ì •ë¦¬ ë° (í•„ìš”ì‹œ) ë””ìŠ¤í¬ ì €ì¥.
- Dataset ë‚´ë¶€ë¡œ ë¡œë“œ.
- ë³€í™˜(íšŒì „, í† í°í™” ë“±) ì ìš©.
- DataLoaderë¡œ ë˜í•‘.

datamoduleì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ë‹¤ë©´ [ì—¬ê¸°](https://lightning.ai/docs/pytorch/stable/data/datamodule.html)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”. ì´ì œ Cifar-10 ë°ì´í„°ì…‹ìš© datamoduleì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤.

```
class CIFAR10DataModule(pl.LightningDataModule):
    def __init__(self, batch_size, data_dir: str = './'):
        super().__init__()
        self.data_dir = data_dir
        self.batch_size = batch_size

        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
        
        self.num_classes = 10
    
    def prepare_data(self):
        CIFAR10(self.data_dir, train=True, download=True)
        CIFAR10(self.data_dir, train=False, download=True)
    
    def setup(self, stage=None):
        # dataloaderì—ì„œ ì‚¬ìš©í•  train/val ë°ì´í„°ì…‹ í• ë‹¹
        if stage == 'fit' or stage is None:
            cifar_full = CIFAR10(self.data_dir, train=True, transform=self.transform)
            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])

        # dataloaderì—ì„œ ì‚¬ìš©í•  test ë°ì´í„°ì…‹ í• ë‹¹
        if stage == 'test' or stage is None:
            self.cifar_test = CIFAR10(self.data_dir, train=False, transform=self.transform)
    
    def train_dataloader(self):
        return DataLoader(self.cifar_train, batch_size=self.batch_size, shuffle=True)

    def val_dataloader(self):
        return DataLoader(self.cifar_val, batch_size=self.batch_size)

    def test_dataloader(self):
        return DataLoader(self.cifar_test, batch_size=self.batch_size)
```

## ì½œë°±(Callback)

ì½œë°±ì€ í”„ë¡œì íŠ¸ ê°„ì— ì¬ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë…ë¦½ì ì¸ í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤. PyTorch Lightningì—ëŠ” ìì£¼ ì‚¬ìš©ë˜ëŠ” [ë¹ŒíŠ¸ì¸ ì½œë°±](https://lightning.ai/docs/pytorch/latest/extensions/callbacks.html#built-in-callbacks)ë“¤ì´ ìˆìŠµë‹ˆë‹¤. PyTorch Lightningì—ì„œì˜ ì½œë°±ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì€ [ì—¬ê¸°](https://lightning.ai/docs/pytorch/latest/extensions/callbacks.html)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

### ë¹ŒíŠ¸ì¸ ì½œë°±

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” [Early Stopping](https://lightning.ai/docs/pytorch/latest/api/lightning.pytorch.callbacks.EarlyStopping.html#lightning.callbacks.EarlyStopping)ê³¼ [Model Checkpoint](https://lightning.ai/docs/pytorch/latest/api/lightning.pytorch.callbacks.ModelCheckpoint.html#pytorch_lightning.callbacks.ModelCheckpoint) ë¹ŒíŠ¸ì¸ ì½œë°±ì„ ì‚¬ìš©í•  ì˜ˆì •ì…ë‹ˆë‹¤. ì´ ì½œë°±ë“¤ì€ `Trainer`ì— ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì»¤ìŠ¤í…€ ì½œë°±
Kerasì—ì„œ ì»¤ìŠ¤í…€ ì½œë°±ì„ ì‚¬ìš©í•´ë³´ì…¨ë‹¤ë©´, PyTorch íŒŒì´í”„ë¼ì¸ì—ì„œ ë˜‘ê°™ì´ ì“¸ ìˆ˜ ìˆë‹¤ëŠ” ì ì´ ì •ë§ ë°˜ê°€ìš¸ ê±°ì˜ˆìš”.

ì´ë²ˆ íŠœí† ë¦¬ì–¼ì˜ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‘ì—…ì—ì„œëŠ”, ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ì´ë¯¸ì§€ë¥¼ ìƒ˜í”Œë¡œ ì§ì ‘ ì‹œê°í™”í•˜ë©° í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ì½œë°± í˜•íƒœë¡œ í™œìš©í•˜ë©´ ëª¨ë¸ì„ ì´ˆê¸°ì— ë””ë²„ê¹…í•˜ëŠ”ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.

```
class ImagePredictionLogger(pl.callbacks.Callback):
    def __init__(self, val_samples, num_samples=32):
        super().__init__()
        self.num_samples = num_samples
        self.val_imgs, self.val_labels = val_samples
    
    def on_validation_epoch_end(self, trainer, pl_module):
        # í…ì„œë¥¼ CPUë¡œ ì´ë™
        val_imgs = self.val_imgs.to(device=pl_module.device)
        val_labels = self.val_labels.to(device=pl_module.device)
        # ëª¨ë¸ ì˜ˆì¸¡ê°’ ì–»ê¸°
        logits = pl_module(val_imgs)
        preds = torch.argmax(logits, -1)
        # ì´ë¯¸ì§€ë¥¼ wandb Imageë¡œ ë¡œê·¸ ê¸°ë¡
        trainer.logger.experiment.log({
            "examples":[wandb.Image(x, caption=f"Pred:{pred}, Label:{y}") 
                           for x, pred, y in zip(val_imgs[:self.num_samples], 
                                                 preds[:self.num_samples], 
                                                 val_labels[:self.num_samples])]
            })
        
```

## LightningModule - ì‹œìŠ¤í…œ ì •ì˜í•˜ê¸°

LightningModuleì€ ë‹¨ìˆœíˆ ëª¨ë¸ì´ ì•„ë‹Œ í•˜ë‚˜ì˜ ì‹œìŠ¤í…œì„ ì •ì˜í•©ë‹ˆë‹¤. ì¦‰, ê´€ë ¨ ì½”ë“œë¥¼ í•˜ë‚˜ì˜ í´ë˜ìŠ¤ë¡œ ë¬¶ì–´ ìê¸° ì™„ê²°ì ìœ¼ë¡œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. `LightningModule`ì€ PyTorch ì½”ë“œë¥¼ ë‹¤ì„¯ ì„¹ì…˜ìœ¼ë¡œ ë‚˜ëˆ  ì •ë¦¬í•´ì¤ë‹ˆë‹¤:
- ê³„ì‚°(`__init__`)
- íŠ¸ë ˆì´ë‹ ë£¨í”„(`training_step`)
- ê²€ì¦ ë£¨í”„(`validation_step`)
- í…ŒìŠ¤íŠ¸ ë£¨í”„(`test_step`)
- ì˜µí‹°ë§ˆì´ì € êµ¬ì„±(`configure_optimizers`)

ì´ë ‡ê²Œ ë°ì´í„°ì…‹ì— ë…ë¦½ì ì¸ ëª¨ë¸ì„ ì‰½ê²Œ ê³µìœ í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. Cifar-10 ë¶„ë¥˜ìš© ì‹œìŠ¤í…œì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤.

```
class LitModel(pl.LightningModule):
    def __init__(self, input_shape, num_classes, learning_rate=2e-4):
        super().__init__()
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê·¸ ê¸°ë¡
        self.save_hyperparameters()
        self.learning_rate = learning_rate
        
        self.conv1 = nn.Conv2d(3, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 32, 3, 1)
        self.conv3 = nn.Conv2d(32, 64, 3, 1)
        self.conv4 = nn.Conv2d(64, 64, 3, 1)

        self.pool1 = torch.nn.MaxPool2d(2)
        self.pool2 = torch.nn.MaxPool2d(2)
        
        n_sizes = self._get_conv_output(input_shape)

        self.fc1 = nn.Linear(n_sizes, 512)
        self.fc2 = nn.Linear(512, 128)
        self.fc3 = nn.Linear(128, num_classes)

        self.accuracy = Accuracy(task='multiclass', num_classes=num_classes)

    # conv ë¸”ë¡ì—ì„œ Linearë¡œ ë„˜ì–´ê°€ëŠ” ì¶œë ¥ í…ì„œ í¬ê¸° ë°˜í™˜
    def _get_conv_output(self, shape):
        batch_size = 1
        input = torch.autograd.Variable(torch.rand(batch_size, *shape))

        output_feat = self._forward_features(input) 
        n_size = output_feat.data.view(batch_size, -1).size(1)
        return n_size
        
    # conv ë¸”ë¡ì˜ íŠ¹ì§• í…ì„œ ë°˜í™˜
    def _forward_features(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool1(F.relu(self.conv2(x)))
        x = F.relu(self.conv3(x))
        x = self.pool2(F.relu(self.conv4(x)))
        return x
    
    # ì¶”ë¡  ì‹œ ì‚¬ìš©
    def forward(self, x):
       x = self._forward_features(x)
       x = x.view(x.size(0), -1)
       x = F.relu(self.fc1(x))
       x = F.relu(self.fc2(x))
       x = F.log_softmax(self.fc3(x), dim=1)
       
       return x
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        
        # íŠ¸ë ˆì´ë‹ ë©”íŠ¸ë¦­
        preds = torch.argmax(logits, dim=1)
        acc = self.accuracy(preds, y)
        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)
        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)
        
        return loss
    
    def validation_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)

        # ê²€ì¦ ë©”íŠ¸ë¦­
        preds = torch.argmax(logits, dim=1)
        acc = self.accuracy(preds, y)
        self.log('val_loss', loss, prog_bar=True)
        self.log('val_acc', acc, prog_bar=True)
        return loss
    
    def test_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        
        # ê²€ì¦ ë©”íŠ¸ë¦­
        preds = torch.argmax(logits, dim=1)
        acc = self.accuracy(preds, y)
        self.log('test_loss', loss, prog_bar=True)
        self.log('test_acc', acc, prog_bar=True)
        return loss
    
    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)
        return optimizer

```

## í•™ìŠµ ë° í‰ê°€

ì´ì œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì€ `DataModule`, ëª¨ë¸ ì•„í‚¤í…ì²˜ì™€ íŠ¸ë ˆì´ë‹ ë£¨í”„ëŠ” `LightningModule`ë¡œ êµ¬ì„±í–ˆìœ¼ë‹ˆ, PyTorch Lightningì˜ `Trainer`ê°€ ë‚˜ë¨¸ì§€ë¥¼ ìë™í™”í•´ì¤ë‹ˆë‹¤.

Trainerì˜ ìë™í™” í•­ëª©:
- ì—í¬í¬ ë° ë°°ì¹˜ ë°˜ë³µ
- `optimizer.step()`, `backward`, `zero_grad()` í˜¸ì¶œ
- `.eval()`í˜¸ì¶œ ë° grad ë™ì‘ ON/OFF ì„¤ì •
- ê°€ì¤‘ì¹˜ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸°
- W&B ë¡œê·¸ ê¸°ë¡
- ë©€í‹° GPU íŠ¸ë ˆì´ë‹ ì§€ì›
- TPU ì§€ì›
- 16ë¹„íŠ¸ íŠ¸ë ˆì´ë‹ ì§€ì›

```
dm = CIFAR10DataModule(batch_size=32)
# x_dataloaderë¥¼ ì—‘ì„¸ìŠ¤í•˜ë ¤ë©´ prepare_dataì™€ setupì„ í˜¸ì¶œí•´ì•¼ í•¨
dm.prepare_data()
dm.setup()

# ì»¤ìŠ¤í…€ ImagePredictionLogger ì½œë°±ì´ ì´ë¯¸ì§€ ì˜ˆì¸¡ì„ ê¸°ë¡í•˜ë ¤ë©´ ìƒ˜í”Œì´ í•„ìš”í•©ë‹ˆë‹¤.
val_samples = next(iter(dm.val_dataloader()))
val_imgs, val_labels = val_samples[0], val_samples[1]
val_imgs.shape, val_labels.shape
```

```
model = LitModel((3, 32, 32), dm.num_classes)

# wandb logger ì´ˆê¸°í™”
wandb_logger = WandbLogger(project='wandb-lightning', job_type='train')

# ì½œë°± ì´ˆê¸°í™”
early_stop_callback = pl.callbacks.EarlyStopping(monitor="val_loss")
checkpoint_callback = pl.callbacks.ModelCheckpoint()

# íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
trainer = pl.Trainer(max_epochs=2,
                     logger=wandb_logger,
                     callbacks=[early_stop_callback,
                                ImagePredictionLogger(val_samples),
                                checkpoint_callback],
                     )

# ëª¨ë¸ í•™ìŠµ
trainer.fit(model, dm)

# í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ëª¨ë¸ í‰ê°€ âš¡âš¡
trainer.test(dataloaders=dm.test_dataloader())

# wandb run ì¢…ë£Œ
run.finish()
```

## ë§ˆë¬´ë¦¬ ìƒê°
ì €ëŠ” TensorFlow/Keras ì—ì½”ì‹œìŠ¤í…œì—ì„œ ì‹œì‘í•´ì„œ, PyTorchê°€ ìš°ì•„í•œ í”„ë ˆì„ì›Œí¬ì„ì—ë„ ë‹¤ì†Œ ì–´ë µê²Œ ëŠê»´ì¡ŒìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ PyTorch Lightningì„ ì‚´í´ë³´ë©´ì„œ, PyTorchë¥¼ êº¼ë¦¬ê²Œ í–ˆë˜ ê±°ì˜ ëª¨ë“  ì´ìœ ê°€ í•´ê²°ëë‹¤ëŠ” ê±¸ ì•Œê²Œ ëì–´ìš”. ê°„ë‹¨íˆ ì •ë¦¬í•˜ìë©´ ì´ë ‡ìŠµë‹ˆë‹¤:
- ì˜ˆì „: ê¸°ì¡´ì˜ PyTorch ëª¨ë¸ ì •ì˜ëŠ” ì—¬ê¸°ì €ê¸°ì— í©ì–´ì ¸ ìˆì—ˆìŠµë‹ˆë‹¤. ëª¨ë¸ì€ ì–´ë–¤ `model.py` ìŠ¤í¬ë¦½íŠ¸ì—, íŠ¸ë ˆì´ë‹ ë£¨í”„ëŠ” `train.py` íŒŒì¼ì— ìˆê³ â€¦ íŒŒì´í”„ë¼ì¸ì„ ì´í•´í•˜ë ¤ë©´ ì™”ë‹¤ê°”ë‹¤ í•´ì•¼ í–ˆì£ . 
- ì§€ê¸ˆ: `LightningModule` ì•ˆì— ëª¨ë¸, `training_step`, `validation_step` ë“±ì´ ëª¨ë‘ ì •ì˜ë˜ì–´, í›¨ì”¬ ëª¨ë“ˆí™”ë˜ê³  ê³µìœ í•˜ê¸° ì¢‹ì•„ì¡ŒìŠµë‹ˆë‹¤.
- ì˜ˆì „: TensorFlow/Kerasì˜ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì´ ì •ë§ í¸í–ˆê³ , ë°ì´í„°ì…‹ ì¹´íƒˆë¡œê·¸ë„ ë‹¤ì–‘í–ˆìŠµë‹ˆë‹¤. PyTorchì˜ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì€ ëŠ˜ ê³ ë¯¼ê±°ë¦¬ì˜€ì–´ìš”. ì¼ë°˜ì ìœ¼ë¡œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ/ì „ì²˜ë¦¬ê°€ ì—¬ëŸ¬ íŒŒì¼ì— í©ì–´ì ¸ ìˆì—ˆì£ . 
- ì§€ê¸ˆ: DataModule ë•ë¶„ì— ëª¨ë“  ë°ì´í„° íŒŒì´í”„ë¼ì¸ ê³¼ì •ì„ ê³µìœ  ë° ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í•˜ë‚˜ì˜ í´ë˜ìŠ¤ë¡œ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. train/val/test dataloaderì™€ ë§¤ì¹­ë˜ëŠ” transforms, ë°ì´í„° ì²˜ë¦¬/ë‹¤ìš´ë¡œë“œ ì½”ë“œë¥¼ ì†ì‰½ê²Œ êµ¬ì„±í•  ìˆ˜ ìˆì£ .
- ì˜ˆì „: Kerasì—ì„œëŠ” `model.fit`ìœ¼ë¡œ ê°„ë‹¨íˆ í•™ìŠµì„ ì‹œì‘í•˜ê³ , `model.predict`ë¡œ ì¶”ë¡ í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. `model.evaluate`ë„ ì†ì‰½ê²Œ ì“¸ ìˆ˜ ìˆì—ˆêµ¬ìš”. PyTorchì—ì„œëŠ” ëŒ€ë¶€ë¶„ ë³„ë„ì˜ `train.py`, `test.py` íŒŒì¼ì—ì„œ ê°ì ìˆ˜í–‰í•˜ê³¤ í–ˆìŠµë‹ˆë‹¤. 
- ì§€ê¸ˆ: LightningModule ì²´ê³„ì—ì„œëŠ” Trainerê°€ ëª¨ë“  ê²ƒì„ ìë™í™”í•´ì¤ë‹ˆë‹¤. ê·¸ëƒ¥ `trainer.fit`, `trainer.test`ë§Œ í˜¸ì¶œí•˜ë©´ ë!
- ì˜ˆì „: TensorFlowëŠ” TPUë¥¼ ì•„ì£¼ ì˜ ì§€ì›í–ˆëŠ”ë°, PyTorchëŠ”...
- ì§€ê¸ˆ: PyTorch Lightning ë•ë¶„ì— ë™ì¼ ëª¨ë¸ì„ ì—¬ëŸ¬ GPU, ì‹¬ì§€ì–´ TPUì—ì„œë„ ë„ˆë¬´ ì‰½ê²Œ ëŒë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì˜ˆì „: Callbacksë¥¼ ë¬´ì²™ ì¢‹ì•„í•˜ê³  ì§ì ‘ ì‘ì„±í•˜ëŠ” ê±¸ ì„ í˜¸í•˜ëŠ”ë°, Early Stopping ê°™ì€ ê²ƒì¡°ì°¨ ì˜ˆì „ PyTorchì—ì„œëŠ” ê³ ë¯¼ê±°ë¦¬ì˜€ìŠµë‹ˆë‹¤.
- ì§€ê¸ˆ: PyTorch Lightningì€ Early Stopping, Model Checkpoint ë“± ì½œë°± í™œìš©ì´ ì •ë§ ì‰¬ì›Œì¡Œê³ , ì»¤ìŠ¤í…€ ì½œë°±ë„ ì–¼ë§ˆë“ ì§€ ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ¨ ì •ë¦¬ ë° ì°¸ê³  ìë£Œ

ì´ ë¦¬í¬íŠ¸ê°€ ë„ì›€ì´ ë˜ì—ˆê¸¸ ë°”ëë‹ˆë‹¤. ì½”ë“œë¡œ ì§ì ‘ ì‹¤í—˜í•´ë³´ê³ , ì›í•˜ëŠ” ë°ì´í„°ì…‹ìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°ë¥¼ íŠ¸ë ˆì´ë‹í•´ë³´ì‹œê¸¸ ì¶”ì²œí•©ë‹ˆë‹¤.

PyTorch Lightningì— ëŒ€í•´ ë” ë°°ìš°ê³  ì‹¶ë‹¤ë©´ ë‹¤ìŒ ìë£Œë¥¼ ì°¸ê³ í•´ ì£¼ì„¸ìš”:
- [ë‹¨ê³„ë³„ ê°€ì´ë“œ](https://lightning.ai/docs/pytorch/latest/starter/introduction.html): ê³µì‹ íŠœí† ë¦¬ì–¼ ì¤‘ í•˜ë‚˜ë¡œ, ë¬¸ì„œê°€ ë§¤ìš° ì˜ ì •ë¦¬ë˜ì–´ ìˆì–´ ì ê·¹ ì¶”ì²œí•©ë‹ˆë‹¤.
- [W&Bì™€ Pytorch Lightning í•¨ê»˜ ì‚¬ìš©í•˜ê¸°](https://wandb.me/lightning): W&Bì™€ PyTorch Lightningì„ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë°°ìš°ê³  ì‹¶ì€ ë¶„ê»˜ ì¢‹ì€ colab ì˜ˆì œì…ë‹ˆë‹¤.