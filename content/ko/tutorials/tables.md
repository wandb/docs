---
title: Visualize predictions with tables
menu:
  tutorials:
    identifier: ko-tutorials-tables
    parent: null
weight: 2
---

{{< cta-button colabLink="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/datasets-predictions/W&B_Tables_Quickstart.ipynb" >}}

ì´ ê°€ì´ë“œì—ì„œëŠ” MNIST ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ PyTorchë¡œ ëª¨ë¸ ì˜ˆì¸¡ì„ ì¶”ì , ì‹œê°í™” ë° ë¹„êµí•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ì„ ë°°ìš°ê²Œ ë©ë‹ˆë‹¤:
1. ëª¨ë¸ íŠ¸ë ˆì´ë‹ ë˜ëŠ” í‰ê°€ ì¤‘ì— `wandb.Table()`ì— ë©”íŠ¸ë¦­, ì´ë¯¸ì§€, í…ìŠ¤íŠ¸ ë“±ì„ ê¸°ë¡í•©ë‹ˆë‹¤.
2. ì´ëŸ¬í•œ í…Œì´ë¸”ì„ ë³´ê³ , ì •ë ¬í•˜ê³ , í•„í„°ë§í•˜ê³ , ê·¸ë£¹í™”í•˜ê³ , ì¡°ì¸í•˜ê³ , ëŒ€í™”ì‹ìœ¼ë¡œ ì¿¼ë¦¬í•˜ê³ , íƒìƒ‰í•©ë‹ˆë‹¤.
3. íŠ¹ì • ì´ë¯¸ì§€, í•˜ì´í¼íŒŒë¼ë¯¸í„°/ëª¨ë¸ ë²„ì „ ë˜ëŠ” ì‹œê°„ ë‹¨ê³„ì— ë”°ë¼ ëª¨ë¸ ì˜ˆì¸¡ ë˜ëŠ” ê²°ê³¼ë¥¼ ë™ì ìœ¼ë¡œ ë¹„êµí•©ë‹ˆë‹¤.

## Examples
### íŠ¹ì • ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ ì ìˆ˜ ë¹„êµ

[ë¼ì´ë¸Œ ì˜ˆì œ: 1 vs 5 ì—í¬í¬ì˜ íŠ¸ë ˆì´ë‹ í›„ ì˜ˆì¸¡ ë¹„êµ â†’](https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU#compare-predictions-after-1-vs-5-epochs)

{{< img src="/images/tutorials/tables-1.png" alt="1 epoch vs 5 epochs of training" >}}

íˆìŠ¤í† ê·¸ë¨ì€ ë‘ ëª¨ë¸ ê°„ì˜ í´ë˜ìŠ¤ë³„ ì ìˆ˜ë¥¼ ë¹„êµí•©ë‹ˆë‹¤. ê° íˆìŠ¤í† ê·¸ë¨ì˜ ë§¨ ìœ„ ë…¹ìƒ‰ ë§‰ëŒ€ëŠ” 1 ì—í¬í¬ë§Œ íŠ¸ë ˆì´ë‹ëœ ëª¨ë¸ "CNN-2, 1 epoch" (id 0)ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì•„ë˜ìª½ ë³´ë¼ìƒ‰ ë§‰ëŒ€ëŠ” 5 ì—í¬í¬ ë™ì•ˆ íŠ¸ë ˆì´ë‹ëœ ëª¨ë¸ "CNN-2, 5 epochs" (id 1)ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ë¯¸ì§€ëŠ” ëª¨ë¸ì´ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°ë¡œ í•„í„°ë§ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì²« ë²ˆì§¸ í–‰ì—ì„œ "4"ëŠ” 1 ì—í¬í¬ í›„ ê°€ëŠ¥í•œ ëª¨ë“  ìˆ«ìì— ëŒ€í•´ ë†’ì€ ì ìˆ˜ë¥¼ ì–»ì§€ë§Œ 5 ì—í¬í¬ í›„ì—ëŠ” ì˜¬ë°”ë¥¸ ë ˆì´ë¸”ì—ì„œ ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ì–»ê³  ë‚˜ë¨¸ì§€ëŠ” ë§¤ìš° ë‚®ì€ ì ìˆ˜ë¥¼ ì–»ìŠµë‹ˆë‹¤.

### ì‹œê°„ì— ë”°ë¥¸ ì£¼ìš” ì˜¤ë¥˜ì— ì§‘ì¤‘
[ë¼ì´ë¸Œ ì˜ˆì œ â†’](https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU#top-errors-over-time)

ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì˜ëª»ëœ ì˜ˆì¸¡("ì¶”ì¸¡" != "ì •ë‹µ"ì¸ í–‰ìœ¼ë¡œ í•„í„°ë§)ì„ í™•ì¸í•©ë‹ˆë‹¤. 1ë²ˆì˜ íŠ¸ë ˆì´ë‹ ì—í¬í¬ í›„ì—ëŠ” 229ê°œì˜ ì˜ëª»ëœ ì¶”ì¸¡ì´ ìˆì§€ë§Œ 5 ì—í¬í¬ í›„ì—ëŠ” 98ê°œë§Œ ìˆìŠµë‹ˆë‹¤.

{{< img src="/images/tutorials/tables-2.png" alt="side by side, 1 vs 5 epochs of training" >}}

### ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë° íŒ¨í„´ ì°¾ê¸°

[ë¼ì´ë¸Œ ì˜ˆì œì—ì„œ ì „ì²´ ì„¸ë¶€ ì •ë³´ ë³´ê¸° â†’](https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU#false-positives-grouped-by-guess)

ì •ë‹µì„ í•„í„°ë§í•˜ê³  ì¶”ì¸¡ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì˜ëª» ë¶„ë¥˜ëœ ì´ë¯¸ì§€ì˜ ì˜ˆì™€ ê¸°ë³¸ ë¶„í¬ë¥¼ í™•ì¸í•©ë‹ˆë‹¤(ë‘ ëª¨ë¸ì„ ë‚˜ë€íˆ ë¹„êµ). ë ˆì´ì–´ í¬ê¸°ì™€ í•™ìŠµë¥ ì´ 2ë°°ì¸ ëª¨ë¸ ë³€í˜•ì´ ì™¼ìª½ì— ìˆê³ , ë² ì´ìŠ¤ë¼ì¸ì´ ì˜¤ë¥¸ìª½ì— ìˆìŠµë‹ˆë‹¤. ë² ì´ìŠ¤ë¼ì¸ì€ ì¶”ì¸¡ëœ ê° í´ë˜ìŠ¤ì— ëŒ€í•´ ì•½ê°„ ë” ë§ì€ ì‹¤ìˆ˜ë¥¼ í•©ë‹ˆë‹¤.

{{< img src="/images/tutorials/tables-3.png" alt="grouped errors for baseline vs double variant" >}}

## ê°€ì… ë˜ëŠ” ë¡œê·¸ì¸

[ê°€ì… ë˜ëŠ” ë¡œê·¸ì¸](https://wandb.ai/login) í•˜ì—¬ W&Bì—ì„œ ë¸Œë¼ìš°ì €ë¡œ Experimentsë¥¼ ë³´ê³  ìƒí˜¸ ì‘ìš©í•˜ì‹­ì‹œì˜¤.

ì´ ì˜ˆì œì—ì„œëŠ” í¸ë¦¬í•œ í˜¸ìŠ¤íŒ… í™˜ê²½ìœ¼ë¡œ Google Colabì„ ì‚¬ìš©í•˜ê³  ìˆì§€ë§Œ, ì–´ë””ì„œë“  ìì²´ íŠ¸ë ˆì´ë‹ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  W&Bì˜ experiment ì¶”ì  íˆ´ì„ ì‚¬ìš©í•˜ì—¬ ë©”íŠ¸ë¦­ì„ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
!pip install wandb -qqq
```

ê³„ì •ì— ë¡œê·¸ì¸


```python

import wandb
wandb.login()

WANDB_PROJECT = "mnist-viz"
```

## 0. ì„¤ì •

ì¢…ì†ì„±ì„ ì„¤ì¹˜í•˜ê³ , MNISTë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³ , PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë ˆì´ë‹ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ë§Œë“­ë‹ˆë‹¤.

```python
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as T 
import torch.nn.functional as F


device = "cuda:0" if torch.cuda.is_available() else "cpu"

# create train and test dataloaders
def get_dataloader(is_train, batch_size, slice=5):
    "Get a training dataloader"
    ds = torchvision.datasets.MNIST(root=".", train=is_train, transform=T.ToTensor(), download=True)
    loader = torch.utils.data.DataLoader(dataset=ds, 
                                         batch_size=batch_size, 
                                         shuffle=True if is_train else False, 
                                         pin_memory=True, num_workers=2)
    return loader
```

## 1. ëª¨ë¸ ë° íŠ¸ë ˆì´ë‹ ìŠ¤ì¼€ì¤„ ì •ì˜

* ì‹¤í–‰í•  ì—í¬í¬ ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ê° ì—í¬í¬ëŠ” íŠ¸ë ˆì´ë‹ ë‹¨ê³„ì™€ ìœ íš¨ì„± ê²€ì‚¬(í…ŒìŠ¤íŠ¸) ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. í•„ìš”ì— ë”°ë¼ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ë‹¹ ê¸°ë¡í•  ë°ì´í„° ì–‘ì„ êµ¬ì„±í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ë°ëª¨ë¥¼ ë‹¨ìˆœí™”í•˜ê¸° ìœ„í•´ ì‹œê°í™”í•  ë°°ì¹˜ ìˆ˜ì™€ ë°°ì¹˜ë‹¹ ì´ë¯¸ì§€ ìˆ˜ê°€ ë‚®ê²Œ ì„¤ì •ë©ë‹ˆë‹¤.
* ê°„ë‹¨í•œ ì»¨ë³¼ë£¨ì…˜ ì‹ ê²½ë§ì„ ì •ì˜í•©ë‹ˆë‹¤([pytorch-tutorial](https://github.com/yunjey/pytorch-tutorial) ì½”ë“œì— ë”°ë¦„).
* PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë ˆì´ë‹ ë° í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.

```python
# Number of epochs to run
# Each epoch includes a training step and a test step, so this sets
# the number of tables of test predictions to log
EPOCHS = 1

# Number of batches to log from the test data for each test step
# (default set low to simplify demo)
NUM_BATCHES_TO_LOG = 10 #79

# Number of images to log per test batch
# (default set low to simplify demo)
NUM_IMAGES_PER_BATCH = 32 #128

# training configuration and hyperparameters
NUM_CLASSES = 10
BATCH_SIZE = 32
LEARNING_RATE = 0.001
L1_SIZE = 32
L2_SIZE = 64
# changing this may require changing the shape of adjacent layers
CONV_KERNEL_SIZE = 5

# define a two-layer convolutional neural network
class ConvNet(nn.Module):
    def __init__(self, num_classes=10):
        super(ConvNet, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, L1_SIZE, CONV_KERNEL_SIZE, stride=1, padding=2),
            nn.BatchNorm2d(L1_SIZE),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer2 = nn.Sequential(
            nn.Conv2d(L1_SIZE, L2_SIZE, CONV_KERNEL_SIZE, stride=1, padding=2),
            nn.BatchNorm2d(L2_SIZE),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.fc = nn.Linear(7*7*L2_SIZE, NUM_CLASSES)
        self.softmax = nn.Softmax(NUM_CLASSES)

    def forward(self, x):
        # uncomment to see the shape of a given layer:
        # ì£¼ì„ ì²˜ë¦¬ë¥¼ í•´ì œí•˜ì—¬ ì£¼ì–´ì§„ ë ˆì´ì–´ì˜ ëª¨ì–‘ì„ í™•ì¸í•©ë‹ˆë‹¤.
        #print("x: ", x.size())
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.reshape(out.size(0), -1)
        out = self.fc(out)
        return out

train_loader = get_dataloader(is_train=True, batch_size=BATCH_SIZE)
test_loader = get_dataloader(is_train=False, batch_size=2*BATCH_SIZE)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
```

## 2. íŠ¸ë ˆì´ë‹ì„ ì‹¤í–‰í•˜ê³  í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ì„ ê¸°ë¡í•©ë‹ˆë‹¤.

ëª¨ë“  ì—í¬í¬ì— ëŒ€í•´ íŠ¸ë ˆì´ë‹ ë‹¨ê³„ì™€ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ê° í…ŒìŠ¤íŠ¸ ë‹¨ê³„ë§ˆë‹¤ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ì„ ì €ì¥í•  `wandb.Table()`ì„ ë§Œë“­ë‹ˆë‹¤. ì´ëŠ” ë¸Œë¼ìš°ì €ì—ì„œ ì‹œê°í™”í•˜ê³ , ë™ì ìœ¼ë¡œ ì¿¼ë¦¬í•˜ê³ , ë‚˜ë€íˆ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
# âœ¨ W&B: ì´ ëª¨ë¸ì˜ íŠ¸ë ˆì´ë‹ì„ ì¶”ì í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ runì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
wandb.init(project="table-quickstart")

# âœ¨ W&B: configë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
cfg = wandb.config
cfg.update({"epochs" : EPOCHS, "batch_size": BATCH_SIZE, "lr" : LEARNING_RATE,
            "l1_size" : L1_SIZE, "l2_size": L2_SIZE,
            "conv_kernel" : CONV_KERNEL_SIZE,
            "img_count" : min(10000, NUM_IMAGES_PER_BATCH*NUM_BATCHES_TO_LOG)})

# ëª¨ë¸, ì†ì‹¤ ë° ì˜µí‹°ë§ˆì´ì €ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
model = ConvNet(NUM_CLASSES).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë°°ì¹˜ì˜ ì˜ˆì¸¡ì„ ê¸°ë¡í•˜ëŠ” í¸ë¦¬í•œ ê¸°ëŠ¥
def log_test_predictions(images, labels, outputs, predicted, test_table, log_counter):
  # ëª¨ë“  í´ë˜ìŠ¤ì— ëŒ€í•œ ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ì–»ìŠµë‹ˆë‹¤.
  scores = F.softmax(outputs.data, dim=1)
  log_scores = scores.cpu().numpy()
  log_images = images.cpu().numpy()
  log_labels = labels.cpu().numpy()
  log_preds = predicted.cpu().numpy()
  # ì´ë¯¸ì§€ ìˆœì„œì— ë”°ë¼ idë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
  _id = 0
  for i, l, p, s in zip(log_images, log_labels, log_preds, log_scores):
    # ë°ì´í„° í…Œì´ë¸”ì— í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    # id, ì´ë¯¸ì§€ í”½ì…€, ëª¨ë¸ì˜ ì¶”ì¸¡, ì‹¤ì œ ë ˆì´ë¸”, ëª¨ë“  í´ë˜ìŠ¤ì— ëŒ€í•œ ì ìˆ˜
    img_id = str(_id) + "_" + str(log_counter)
    test_table.add_data(img_id, wandb.Image(i), p, l, *s)
    _id += 1
    if _id == NUM_IMAGES_PER_BATCH:
      break

# ëª¨ë¸ì„ íŠ¸ë ˆì´ë‹í•©ë‹ˆë‹¤.
total_step = len(train_loader)
for epoch in range(EPOCHS):
    # íŠ¸ë ˆì´ë‹ ë‹¨ê³„
    for i, (images, labels) in enumerate(train_loader):
        images = images.to(device)
        labels = labels.to(device)
        # forward íŒ¨ìŠ¤
        outputs = model(images)
        loss = criterion(outputs, labels)
        # backward ë° ìµœì í™”
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
  
        # âœ¨ W&B: UI ë¼ì´ë¸Œì—ì„œ ì‹œê°í™”ëœ íŠ¸ë ˆì´ë‹ ë‹¨ê³„ì— ë”°ë¥¸ ì†ì‹¤ì„ ê¸°ë¡í•©ë‹ˆë‹¤.
        wandb.log({"loss" : loss})
        if (i+1) % 100 == 0:
            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'
                .format(epoch+1, EPOCHS, i+1, total_step, loss.item()))
            

    # âœ¨ W&B: ê° í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ì €ì¥í•  Tableì„ ë§Œë“­ë‹ˆë‹¤.
    columns=["id", "image", "guess", "truth"]
    for digit in range(10):
      columns.append("score_" + str(digit))
    test_table = wandb.Table(columns=columns)

    # ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
    model.eval()
    log_counter = 0
    with torch.no_grad():
        correct = 0
        total = 0
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            if log_counter < NUM_BATCHES_TO_LOG:
              log_test_predictions(images, labels, outputs, predicted, test_table, log_counter)
              log_counter += 1
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        acc = 100 * correct / total
        # âœ¨ W&B: UIì—ì„œ ì‹œê°í™”í•˜ê¸° ìœ„í•´ íŠ¸ë ˆì´ë‹ ì—í¬í¬ ì „ì²´ì—ì„œ ì •í™•ë„ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
        wandb.log({"epoch" : epoch, "acc" : acc})
        print('Test Accuracy of the model on the 10000 test images: {} %'.format(acc))

    # âœ¨ W&B: ì˜ˆì¸¡ í…Œì´ë¸”ì„ wandbì— ê¸°ë¡í•©ë‹ˆë‹¤.
    wandb.log({"test_predictions" : test_table})

# âœ¨ W&B: runì„ ì™„ë£Œëœ ê²ƒìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤(ë‹¤ì¤‘ ì…€ ë…¸íŠ¸ë¶ì— ìœ ìš©).
wandb.finish()
```

## ë‹¤ìŒ ë‹¨ê³„ëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?
ë‹¤ìŒ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” W&B Sweepsë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™”í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.
## ğŸ‘‰ [í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”]({{< relref path="sweeps.md" lang="ko" >}})
