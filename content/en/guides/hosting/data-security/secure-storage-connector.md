---
menu:
  default:
    identifier: secure-storage-connector
    parent: data-security
title: Bring your own bucket (BYOB)
weight: 1
---

## Overview
Bring your own bucket (BYOB) allows you to store W&B artifacts and other related sensitive data in your own cloud or on-prem infrastructure. In case of [Dedicated Cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}) or [Multi-tenant Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}), data that you store in your bucket is not copied to the W&B managed infrastructure.

{{% alert %}}
* Communication between W&B SDK / CLI / UI and your buckets occurs using [pre-signed URLs]({{< relref "./presigned-urls.md" >}}).
* W&B uses a garbage collection process to delete W&B Artifacts. For more information, see [Deleting Artifacts]({{< relref "/guides/core/artifacts/manage-data/delete-artifacts.md" >}}).
* You can specify a sub-path when configuring a bucket, to ensure that W&B does not store any files in a folder at the root of the bucket. It can help you better conform to your organzation's bucket governance policy.
{{% /alert %}}

### Data stored in the central database vs buckets
When using BYOB functionality, certain types of data will be stored in the W&B central database, and other types will be stored in your bucket. 

#### Database
- Metadata for users, teams, artifacts, experiments, and projects
- Reports
- Experiment logs
- System metrics
- Console logs

#### Buckets
- Experiment files and metrics
- Artifact files
- Media files
- Run files
- Exported history metrics and system events in Parquet format

### Bucket scopes
There are two scopes you can configure your storage bucket to:

| Scope          | Description |
|----------------|-------------|
| Instance level | In [Dedicated Cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud/" >}}) and [Self-Managed]({{< relref "/guides/hosting/hosting-options/self-managed.md" >}}), any user with the required permissions within your organization or instance can access files stored in your instance's storage bucket. Not applicable to [Multi-tenant Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}). |
| Team level     | If a W&B Team is configured to use a Team level storage bucket, team members can access files stored in it. Team level storage buckets allow greater data access control and data isolation for teams with highly sensitive data or strict compliance requirements.<br><br>Team level storage can help different business units or departments sharing an instance to efficiently use the infrastructure and administrative resources. It can also allow separate project teams to manage AI workflows for separate customer engagements. Available for all deployment types. You configure team level BYOB when setting up the team. |

This flexible design allows for many different storage topologies, depending on your organization's needs. For example:
- The same bucket can be used for the instance and one or more teams.
- Each team can use a separate bucket, some teams can choose to write to the instance bucket, or multiple teams can share a bucket by writing to subpaths.
- Buckets for different teams can be hosted in different cloud infrastructure environments or regions, and can be managed by different storage admin teams.

For example, suppose you have a team called Kappa in your organization. Your organization (and Team Kappa) use the Instance level storage bucket by default. Next, you create a team called Omega. When you create Team Omega, you configure a Team level storage bucket for that team. Files generated by Team Omega are not accessible by Team Kappa. However, files created by Team Kappa are accessible by Team Omega. If you want to isolate data for Team Kappa, you must configure a Team level storage bucket for them as well.

### Availability matrix
W&B can connect to the following storage providers:
- [CoreWeave AI Object Storage](https://docs.coreweave.com/docs/products/storage/object-storage) is a high-performance, S3-compatible object storage service optimized for AI workloads.
- [Amazon S3](https://aws.amazon.com/s3/) is an object storage service offering industry-leading scalability, data availability, security, and performance.
- [Google Cloud Storage](https://cloud.google.com/storage) is a managed service for storing unstructured data at scale.
- [Azure Blob Storage](https://azure.microsoft.com/products/storage/blobs) is a cloud-based object storage solution for storing massive amounts of unstructured data like text, binary data, images, videos, and logs.
- S3-compatible storage like [MinIO](https://github.com/minio/minio) hosted in your cloud or infrastructure on your premises.

The following table shows the availability of BYOB at each scope for each W&B deployment type.

| W&B deployment type | Instance level                         | Team level | Additional information |
|----------------------------|----------------------------------------|------------|------------------------|
| Dedicated Cloud            | &check;<sup><a href="footnote_1">1</a></sup> | &check;          | Instance and team level BYOB are supported for CoreWeave AI Object Storage, AWS S3, GCP Storage, Microsoft Azure Blob Storage, and S3-compatible storage like [MinIO](https://github.com/minio/minio) hosted in your cloud or on-prem infrastructure. |
| Multi-tenant Cloud                 | Not Applicable                         | &check;<sup><a href="footnote_1">1</a></sup> | Team level BYOB is supported for AWS S3, and GCP Storage. W&B fully manages the default and only storage bucket for Microsoft Azure. Team level BYOB for CoreWeave AI Object Storage is coming soon. |
| Self-Managed               | &check;<sup><a href="footnote_1">1</a></sup> | &check;          | Instance and team level BYOB are supported for CoreWeave AI Object Storage, AWS S3, GCP Storage, Microsoft Azure Blob Storage, and S3-compatible storage like [MinIO](https://github.com/minio/minio) hosted in your cloud or infrastructure on your premises. |

<sup><a id="footnote_1">1</a>.</sup> CoreWeave AI Object Storage is currently supported only for instance or team level BYOB on Dedicated Cloud and Self-Managed. Team level BYOB on Multi-tenant Cloud is coming soon.

## Set up BYOB
### 1. Provision your bucket {#provision-your-bucket}

After [verifying availability]({{< relref "#availability-matrix" >}}), you are ready to provision your storage bucket, including its access policy and CORS. Select a tab to continue.

{{< tabpane text=true >}}
{{% tab header="CoreWeave" value="coreweave" %}}
<a id="coreweave-requirements"></a>**Requirements**:
- **Dedicated Cloud** or **Self-Hosted** v0.70.0 or newer. Not yet available for Multi-tenant Cloud.
- A CoreWeave account with AI Object Storage enabled and with permission to create buckets, API access keys, and secret keys.
- Your W&B instance must be able to connect to CoreWeave network endpoints.

For details, see [Create a CoreWeave AI Object Storage bucket](https://docs.coreweave.com/docs/products/storage/object-storage/how-to/create-bucket) in the CoreWeave documentation.

1. Create the bucket with a name of your choice in your preferred CoreWeave availability zone. Optionally create a folder for W&B to use as a sub-path for all W&B files. Make a note of the bucket name, availability zone, API access key, secret key, and sub-path.
1. Set the following Cross-origin resource sharing (CORS) policy for the bucket:
    ```json
    [
      {
        "AllowedHeaders": [
          "*"
        ],
        "AllowedMethods": [
          "GET",
          "HEAD",
          "PUT"
        ],
        "AllowedOrigins": [
          "*"
        ],
        "ExposeHeaders": [
          "ETag"
        ],
        "MaxAgeSeconds": 3000
      }
    ]
    ```
    CoreWeave storage is S3-compatible. For details about CORS, refer to [Configuring cross-origin resource sharing (CORS)](https://docs.aws.amazon.com/AmazonS3/latest/userguide/enabling-cors-examples.html) in the AWS documentation.
1. Configure a bucket policy that grants the required permissions for your W&B deployment to access the bucket and generate [pre-signed URLs]({{< relref "./presigned-urls.md" >}}) that AI workloads in your cloud infrastructure or user browsers utilize to access the bucket. Refer to [Bucket Policy Reference](https://docs.coreweave.com/docs/products/storage/object-storage/reference/bucket-policy) in the CoreWeave documentation. <!--Select your deployment type to view an example bucket policy.-->

   <!--> <details>
      <a id="coreweave-dedicated-cloud-self-managed-bucket-policy"></a><summary><b>Dedicated Cloud</b> / <b>Self-Managed</b> bucket policy</summary>-->

    Replace:
      - In `Resource`, each instance of `<cw_bucket>` with the CoreWeave bucket name.
      - In `Principal`, each instance of `<cw_principal_and_role_arn>` with the CoreWeave principal and role ARN in the format `"arn:aws:iam:::user/<CW_ORG>:<CW_USER>"`. To apply the policy to all principals, replace the entire ARN with `*`. To apply the policy to all principals in your CoreWeave organization, replace `<CW_USER>` with `*`.

    ```json
    {
      "Version": "2012-10-17",
      "Id": "WandBAccess",
      "Statement": [
        {
          "Sid": "WAndBAccountAccess",
          "Effect": "Allow",
          "Principal": { "CW": "<cw_principal_and_role_arn>" },
            "Action" : [
              "s3:GetObject*",
              "s3:GetEncryptionConfiguration",
              "s3:ListBucket",
              "s3:ListBucketMultipartUploads",
              "s3:ListBucketVersions",
              "s3:AbortMultipartUpload",
              "s3:DeleteObject",
              "s3:PutObject",
              "s3:GetBucketCORS",
              "s3:GetBucketLocation",
              "s3:GetBucketVersioning"
            ],
          "Resource": [
            "arn:aws:s3:::<cw_bucket>",
            "arn:aws:s3:::<cw_bucket>/*"
          ]
        }
      ]
    }
    ```

    <!-- 
    </details>

    <details>
      <a id="coreweave-multi-tenant-cloud-bucket-policy"></a><summary><b>Multi-tenant Cloud</b> bucket policy</summary>

    **Multi-tenant Cloud only**:
    For team level storage in Multi-tenant Cloud, obtain your W&B organization ID, which is required in your bucket policy for team level storage:
      1. Log in to W&B as a user with the `admin` role.
      1. Click the icon at the top left to open the left navigation, then click **Create a team to collaborate**.
      1. Click **External storage**, then set **Cloud Provider** to **CoreWeave**.
      1. Near the bottom of the dialog, make a note of the **W&B organization ID**.
      1. Keep this page open. Later, you will use it to create the new team.
    
    Replace:
    - In `Resource`, each instance of `<cw_bucket>` with the CoreWeave bucket name.
    - In `Principal` and `Condition`, each instance of `<wb-org-id>` with your W&B organization ID.

    ```json
    {
      "Version": "2012-10-17",
      "Id": "WandBAccess",
      "Statement": [
        {
          "Sid": "WAndBAccountAccess",
          "Effect": "Allow",
          "Principal": { "CW": "arn:aws:iam::<wb-org-id>:*" },
            "Action" : [
              "s3:GetObject*",
              "s3:GetEncryptionConfiguration",
              "s3:ListBucket",
              "s3:ListBucketMultipartUploads",
              "s3:ListBucketVersions",
              "s3:AbortMultipartUpload",
              "s3:DeleteObject",
              "s3:PutObject",
              "s3:GetBucketCORS",
              "s3:GetBucketLocation",
              "s3:GetBucketVersioning"
            ],
            "Resource": [
              "arn:aws:s3:::<cw_bucket>",
              "arn:aws:s3:::<cw_bucket>/*"
            ],
            "Condition": {
			        "StringLike": {
				        "wandb:OrgID": [
					       "<wb-org-id>"
				        ]
			        }
		        }
        }
      ]
    }
    ```

    </details>
    -->


Keep a record of the bucket name and access credentials.

{{% /tab %}}
{{% tab header="AWS" value="aws" %}}
For details, see [Create an S3 bucket](https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-overview.html) in the AWS documentation.
1. Provision the KMS Key.

    W&B requires you to provision a KMS Key to encrypt and decrypt the data on the S3 bucket. The key usage type must be `ENCRYPT_DECRYPT`. Assign the following policy to the key:

    ```json
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Sid" : "Internal",
          "Effect" : "Allow",
          "Principal" : { "AWS" : "<Your_Account_Id>" },
          "Action" : "kms:*",
          "Resource" : "<aws_kms_key.key.arn>"
        },
        {
          "Sid" : "External",
          "Effect" : "Allow",
          "Principal" : { "AWS" : "<aws_principal_and_role_arn>" },
          "Action" : [
            "kms:Decrypt",
            "kms:Describe*",
            "kms:Encrypt",
            "kms:ReEncrypt*",
            "kms:GenerateDataKey*"
          ],
          "Resource" : "<aws_kms_key.key.arn>"
        }
      ]
    }
    ```

    Replace `<Your_Account_Id>` and `<aws_kms_key.key.arn>` accordingly.

    If you are using [Multi-tenant Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}) or [Dedicated Cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), replace `<aws_principal_and_role_arn>` with the corresponding value:

    * For [Multi-tenant Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}): `arn:aws:iam::725579432336:role/WandbIntegration`
    * For [Dedicated Cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}): `arn:aws:iam::830241207209:root`

    This policy grants your AWS account full access to the key and also assigns the required permissions to the AWS account hosting the W&B Platform. Keep a record of the KMS Key ARN.

1. Provision the S3 Bucket.

    Follow these steps to provision the S3 bucket in your AWS account:

    1. Create the S3 bucket with a name of your choice. Optionally create a folder which you can configure as sub-path to store all W&B files.
    1. Enable server side encryption, using the KMS key from the previous step.
    1. Configure CORS with the following policy:

        ```json
        [
          {
              "AllowedHeaders": [
                  "*"
              ],
              "AllowedMethods": [
                  "GET",
                  "HEAD",
                  "PUT"
              ],
              "AllowedOrigins": [
                  "*"
              ],
              "ExposeHeaders": [
                  "ETag"
              ],
              "MaxAgeSeconds": 3000
          }
        ]
        ```
        {{% alert %}}If data in your bucket expires due to an [object lifecycle management policy](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html), you may lose the ability to read the history of some runs.{{% /alert %}}
    1. Grant the required S3 permissions to the AWS account hosting the W&B Platform, which requires these permissions to generate [pre-signed URLs]({{< relref "./presigned-urls.md" >}}) that AI workloads in your cloud infrastructure or user browsers utilize to access the bucket.

        ```json
        {
          "Version": "2012-10-17",
          "Id": "WandBAccess",
          "Statement": [
            {
              "Sid": "WAndBAccountAccess",
              "Effect": "Allow",
              "Principal": { "AWS": "<aws_principal_and_role_arn>" },
                "Action" : [
                  "s3:GetObject*",
                  "s3:GetEncryptionConfiguration",
                  "s3:ListBucket",
                  "s3:ListBucketMultipartUploads",
                  "s3:ListBucketVersions",
                  "s3:AbortMultipartUpload",
                  "s3:DeleteObject",
                  "s3:PutObject",
                  "s3:GetBucketCORS",
                  "s3:GetBucketLocation",
                  "s3:GetBucketVersioning"
                ],
              "Resource": [
                "arn:aws:s3:::<wandb_bucket>",
                "arn:aws:s3:::<wandb_bucket>/*"
              ]
            }
          ]
        }
        ```

        Replace `<wandb_bucket>` accordingly and keep a record of the bucket name. Next, [configure W&B]({{< relref "#configure-byob" >}}).

        If you are using [Multi-tenant Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}) or [Dedicated Cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), replace `<aws_principal_and_role_arn>` with the corresponding value.

        * For [Multi-tenant Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}): `arn:aws:iam::725579432336:role/WandbIntegration`
        * For [Dedicated Cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}): `arn:aws:iam::830241207209:root`
  
For more details, see the [AWS self-managed hosting guide]({{< relref "/guides/hosting/hosting-options/self-managed/install-on-public-cloud/aws-tf.md" >}}).

{{% /tab %}}
{{% tab header="GCP" value="gcp"%}}
For details, see [Create a bucket](https://cloud.google.com/storage/docs/creating-buckets) in the GCP documentation.
1. Provision the GCS bucket.

    Follow these steps to provision the GCS bucket in your GCP project:

    1. Create the GCS bucket with a name of your choice. Optionally create a folder which you can configure as sub-path to store all W&B files.
    1. Set encryption type to `Google-managed`.
    1. Set the CORS policy with `gsutil`. This is not possible in the UI.

       1. Create a file called `cors-policy.json` locally.
       1. Copy the following CORS policy into the file and save it.

           ```json
           [
             {
               "origin": ["*"],
               "responseHeader": ["Content-Type"],
               "exposeHeaders": ["ETag"],
               "method": ["GET", "HEAD", "PUT"],
               "maxAgeSeconds": 3000
             }
           ]
           ```

          {{% alert %}}If data in your bucket expires due to an [object lifecycle management policy](https://cloud.google.com/storage/docs/lifecycle), you may lose the ability to read the history of some runs.{{% /alert %}}

      1. Replace `<bucket_name>` with the correct bucket name and run `gsutil`.

          ```bash
          gsutil cors set cors-policy.json gs://<bucket_name>
          ```

      1. Verify the bucket's policy. Replace `<bucket_name>` with the correct bucket name.
        
          ```bash
          gsutil cors get gs://<bucket_name>
          ```

1. If you are using [Multi-tenant Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}) or [Dedicated Cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), grant the `storage.admin` role to the GCP service account linked to the W&B Platform. W&B requires this role to check the bucket's CORS configuration and attributes, such as whether object versioning is enabled. If the service account does not have the `storage.admin` role, these checks result in a HTTP 403 error.

    * For [Multi-tenant Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}), the account is: `wandb-integration@wandb-production.iam.gserviceaccount.com`
    * For [Dedicated Cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}) the account is: `deploy@wandb-production.iam.gserviceaccount.com`

    Keep a record of the bucket name. Next, [configure W&B for BYOB]({{< relref "#configure-byob" >}}).
{{% /tab %}}

{{% tab header="Azure" value="azure" %}}
For details, see [Create a blob storage container](https://learn.microsoft.com/en-us/azure/storage/blobs/blob-containers-portal) in the Azure documentation.
1. Provision the Azure Blob Storage container.

    For the instance level BYOB, if you're not using [this Terraform module](https://github.com/wandb/terraform-azurerm-wandb/tree/main/examples/byob), follow the steps below to provision a Azure Blob Storage bucket in your Azure subscription:

    1. Create a bucket with a name of your choice. Optionally create a folder which you can configure as sub-path to store all W&B files.
    1. Configure the CORS policy on the bucket

        To set the CORS policy through the UI go to the blob storage, scroll down to `Settings/Resource Sharing (CORS)` and then set the following:

        | Parameter | Value |
        | --- | --- |
        | Allowed Origins | `*`  |
        | Allowed Methods | `GET`, `HEAD`, `PUT` |
        | Allowed Headers | `*` |
        | Exposed Headers | `*` |
        | Max Age | `3000` |

        {{% alert %}}If data in your bucket expires due to an [object lifecycle management policy](https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-policy-configure?tabs=azure-portal), you may lose the ability to read the history of some runs.{{% /alert %}}
1. Generate a storage account access key and make a note of its name and the storage account name. If you are using [Dedicated Cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), share the storage account name and access key with your W&B team using a secure sharing mechanism.

    For team level BYOB, W&B recommends that you use [Terraform](https://github.com/wandb/terraform-azurerm-wandb/tree/main/modules/secure_storage_connector) to provision the Azure Blob Storage bucket along with the necessary access mechanism and permissions. If you use [Dedicated Cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), provide the OIDC issuer URL for your instance. Make a note of the following details:

    * Storage account name
    * Storage container name
    * Managed identity client id
    * Azure tenant id

{{% /tab %}}
{{% tab header="S3-compatible" value="s3-compatible" %}}
Create your S3-compatible bucket. Make a note of:
- Access key
- Secret access key
- URL endpoint
- Bucket name
- Folder path, if applicable.
- Region

{{% /tab %}}
{{< /tabpane >}}

Next, [determine the storage address]({{< relref "#determine-the-storage-address" >}}).

### 2. Determine the storage address  {#determine-the-storage-address}
This section explains the syntax to use to connect W&B to a BYOB storage bucket. In the examples, replace placeholder values between angle brackets (`<>`) with your bucket's details.

Select a tab for detailed instructions.

{{< tabpane text=true >}}
{{% tab header="CoreWeave" value="coreweave" %}}
**Bucket format**:
```text
cw://<accessKey>:<secretAccessKey>@<coreweaveEndpoint>/<bucketName>?region=<region>&tls=true
```
or
```text
s3://<accessKey>:<secretAccessKey>@<coreweaveEndpoint>/<bucketName>?region=<region>&tls=true
```
- CoreWeave uses availability zones for AI Object Storage. In the bucket address, the `region` parameter is mandatory and must be set to the name of the CoreWeave availability zone that matches the CoreWeave bucket's location. Refer to [Regions and Availability Zones](https://docs.coreweave.com/docs/platform/regions) in the CoreWeave documentation. Click the **AI Object Storage** link for the region to verify the ability zone to use. For example, in region `US-EAST-01`, AI Object Storage is available in `US-EAST-01A`. 
- Replace `<coreweaveEndpoint>` with one of:
  - `cwobject.com`: Primary HTTPS endpoint, TLS 1.3 required.
  - `cwlota.com`: CoreWeave's [Local Object Transfer Accelerator (LOTA)](https://docs.coreweave.com/docs/products/storage/object-storage/concepts/lota) HTTP (not HTTPS) endpoint. LOTA is an intelligent proxy installed on every GPU Node in a CKS cluster to accelerate data transfer by providing an efficient local gateway to CoreWeave AI Object Storage on each node in the cluster for faster data transfer rates and decreased latency. Omit the `tls=true` parameter. 
  See the [CoreWeave documentation](https://docs.coreweave.com/docs/products/storage/object-storage/how-to/get-started-caios#3-create-a-bucket) for details.
- The `cw://` protocol specifier is preferred. However, CoreWeave buckets offer an optional S3-compatible mode when you use the `s3://` protocol specifier instead.
{{% /tab %}}
{{% tab header="AWS" value="aws" %}}
**Bucket format**:
```text
s3://<accessKey>:<secretAccessKey>@<s3_regional_url_endpoint>/<bucketName>?region=<region>
```
In the address, the `region` parameter is mandatory unless both your W&B instance and your storage bucket are deployed AWS, and the W&B instance's `AWS_REGION` matches the bucket's AWS S3 region.
{{% /tab %}}
{{% tab header="GCP" value="gcp" %}}
**Bucket format**:
```text
gs://<serviceAccountEmail>:<urlEncodedPrivateKey>@<bucketName>
```
{{% /tab %}}
{{% tab header="Azure" value="azure" %}}
**Bucket format**:
```text
az://:<urlEncodedAccessKey>@<storageAccountName>/<containerName>
```
{{% /tab %}}
{{% tab header="S3-compatible" value="s3-compatible" %}}
**Bucket format**:
```text
s3://<accessKey>:<secretAccessKey>@<url_endpoint>/<bucketName>?region=<region>&tls=true
```
In the address, the `region` parameter is mandatory.

{{% alert %}}
This section is for S3-compatible storage buckets that are not hosted in S3, like [MinIO](https://github.com/minio/minio) hosted on your premises. For storage buckets hosted in AWS S3, see the **AWS** tab instead.

For Cloud-native storage buckets with an optional S3-compatible mode, use the Cloud-native protocol specifier when possible. For example, use `cw://` for a CoreWeave bucket, rather than `s3://`.
{{% /alert %}}
{{% /tab %}}
{{< /tabpane >}}

After determining the storage address, you are ready to [configure instance level BYOB]({{< relref "#configure-instance-level-byob" >}}) or [configure team level BYOB]({{< relref "#configure-team-level-byob" >}}).

### 3. Configure W&B  {#configure-byob}
After you [provision your bucket]({{< relref "#provision-your-bucket" >}}) and [determine its address](#determine-the-storage-address), you are ready to configure BYOB at the [instance level]({{< relref "#instance-level-byob" >}}) or [team level]({{< relref "#team-level-byob" >}}).

{{% alert color="secondary" %}}
Plan your storage bucket layout carefully. After you configure a storage bucket for W&B, migrating its data to another bucket is complex and requires the assistance of W&B. This applies to storage for Dedicated Cloud and Self-Managed, as well as team-level storage for Multi-tenant Cloud. For questions, contact [support](mailto:support@wandb.com).
{{% /alert %}}

#### Instance level BYOB
{{% alert %}}
For Team Level BYOB, refer to [Team level BYOB]({{< relref "#team-level-byob" >}}) instead.
{{% /alert %}}

For **Dedicated Cloud**: Share the bucket details with your W&B team, who will configure your Dedicated Cloud instance.

For **Self-Managed**, you can configure instance level BYOB using the W&B App or the `GORILLA_SUPPORTED_FILE_STORES` environment variable. Select a tab to continue.

{{< tabpane text=true >}}
{{% tab header="W&B App" %}}

{{% alert %}}
For CoreWeave AI Object Storage at the instance level, contact [W&B support](mailto:support@wandb.com) instead of following these instructions. Self-service configuration is not yet supported.
{{% /alert %}}

To configure instance level BYOB:
1. Log in to W&B as a user with the `admin` role.
1. Click the user icon at the top, then click **System Console**.
1. Go to **Settings** > **System Connections**.
1. In the **Bucket Storage** section, ensure the identity in the **Identity** field is granted access to the new bucket.
1. Select the **Provider**.
1. Enter the new **Bucket Name**.
1. Optionally, enter the **Path** to use in the new bucket.
1. Click **Save**

{{% /tab %}}
{{% tab header="Environment variable" %}}

To configure instance level BYOB, set the `GORILLA_SUPPORTED_FILE_STORES` environment variable to the bucket location, then restart W&B. 
{{% /tab %}}
{{< /tabpane >}}

{{% alert %}}
For Self-Hosted, W&B recommends using the Terraform module managed by W&B to provision a storage bucket along with the necessary access mechanism and related IAM permissions:

* [AWS](https://github.com/wandb/terraform-aws-wandb/tree/main/modules/secure_storage_connector)
* [GCP](https://github.com/wandb/terraform-google-wandb/tree/main/modules/secure_storage_connector)
* Azure - [Instance level BYOB](https://github.com/wandb/terraform-azurerm-wandb/tree/main/examples/byob) or [Team level BYOB](https://github.com/wandb/terraform-azurerm-wandb/tree/main/modules/secure_storage_connector)
{{% /alert %}}

#### Team level BYOB
After you [determine the storage location](#determine-the-storage-location) for your bucket, you can use the W&B App to configure team level BYOB while creating a team.

{{% alert %}}
- After a team is created, its storage cannot be changed.
- For Instance level BYOB, refer to [Instance level BYOB]({{< relref "#instance-level-byob" >}}) instead.
- If you plan to configure CoreWeave storage for the team, contact [support](mailto:support@wandb.com) to verify that your bucket is configured correctly in CoreWeave and to validate your team's configuration, since the storage details cannot be changed after the team is created.
{{% /alert %}}

<!-- (Commented out until MT is supported) 1. If you are configuring CoreWeave storage for Multi-tenant Cloud, switch to the browser window where you previously began to create the new team to find the W&B organization ID previously. Otherwise, l -->
1. Log in to W&B as a user with the `admin` role, click the icon at the top left to open the left navigation, then click **Create a team to collaborate**.
1. Provide a name for the team.
1. Set **Storage Type** to **External storage**.

    {{% alert %}}To use the instance level storage for team storage (regardless of whether it is internal or external), leave **Storage Type** set to **Internal**, even if the instance level bucket is configured for BYOB. To use separate external storage for the team, set **Storage Type** for the team to **External** and configure the bucket details in the next step.{{% /alert %}}

1. Click **Bucket location**. Select an existing bucket or click **Add bucket** at the bottom to create a new bucket.
    To add a new bucket:
    1. Click **Cloud provider** and select **CoreWeave**, **AWS**, **GCP**, or **Azure**. CoreWeave is not yet available for teams on Multi-tenant Cloud.
    1. Provide a **Name** for the bucket.
        - For **CoreWeave**, provide only the bucket name.
        - For Azure on W&B Dedicated or Self-Managed, provide Account name and Container name. <!--(TODO verify UI)-->
    1. Provide the bucket path you [determined earlier](#determine-the-storage-address).
    1. Optional configuration:
        - If applicable, set **Path** to the bucket sub-path.
        - **CoreWeave**: Set **KMS key ARN** to the CoreWeave ARN.
        - **AWS**: Set **KMS key ARN** to the ARN of your KMS encryption key.
        - **Azure**: Set the **Account name** to the Azure account and **Container name** to the Azure blob storage container. If applicable, specify values for **Tenant ID** and **Managed Identity Client ID**. <!-- TODO: Is this supported on MT? Cross-cloud for DC? Asked in https://weightsandbiases.slack.com/archives/C04EUEA3P5Z/p1751061972096839 -->
        - **Multi-tenant Cloud**: Optionally invite members to the team. In **Invite team members**, specify a comma-separated list of email addresses. Otherwise, you can invite members to the team after it is created.

          For **Dedicated Cloud** or **Self-Managed**, you can invite members to the team after it is created. 
1. Click **Create team**.

    If W&B encounters errors accessing the bucket or detects invalid settings, an error or warning displays at the bottom of the page. Otherwise, the team is created.


## Troubleshooting
<details open>
<summary>Connecting to CoreWeave AI Object Storage</summary>

- **Connection errors**
  - Verify that your W&B instance can connect to CoreWeave network endpoints.
  - CoreWeave uses virtual-hosted style paths, where the bucket name is a subdomain at the beginning of the path. For example: `cw://bucket-name.cwobject.com` is correct, while `cw://cwobject.com/bucket-name/` is not.
  - Bucket names must not contain underscores (`_`) or other characters incompatible with DNS rules.
  - Bucket names must be globally unique among CoreWeave locations.
  - Bucket names must not begin with `cw-` or `vip-`, which are reserved prefixes.
- **CORS validation failures**
  - A CORS policy is required. CoreWeave is S3-compatible; for details about CORS, refer to [Configuring cross-origin resource sharing (CORS)](https://docs.aws.amazon.com/AmazonS3/latest/userguide/enabling-cors-examples.html) in the AWS documentation.
  - `AllowedMethods` must include methods `GET`, `PUT`, and `HEAD`.
  - `ExposeHeaders` must include `ETag.
  - W&B front-end domains must be included in the CORS policy's `AllowedOrigins`. The example CORS policies provided on this page include all domains using `*`.
- **LOTA endpoint issues**
  - LOTA endpoints use HTTP rather than HTTPS. Omit the `tls` parameter from the bucket's address, and use the `cw://` protocol specifier if possible.
  - Your W&B instance must be able to connect to `.cwlota.com`.
  - Use LOTA only when your workloads are running on CoreWeave GPU compute. LOTA is optimized for large file transfers within CoreWeave infrastructure.
- **Region errors**
  - CoreWeave uses availability zones for AI Object Storage.
    - In the bucket address, set `region` to the name of the CoreWeave availability zone that matches the CoreWeave bucket's location.
    - CoreWeave AI Object Storage is not available in all regions. Refer to [Regions and Availability Zones](https://docs.coreweave.com/docs/platform/regions) in the CoreWeave documentation. Click the **AI Object Storage** link for the region to verify the ability zone to use. For example, in region `S-EAST-01`, AI Object Storage is available in `US-EAST-01A`. 
- **Access key and permission errors**
  - Verify that your CoreWeave API Access Key is not expired.
  - Verify that your CoreWeave API Access Key and Secret Key have sufficient permissions `GetObject`, `PutObject`, `DeleteObject`, `ListBucket`. The examples in this page meet this requirement. Refer to [Create and Manage Access Keys](https://docs.coreweave.com/docs/products/storage/object-storage/how-to/manage-access-keys) in the CoreWeave documentation.

</details>