name: GPT Editor (CI version)

on:
  issue_comment:
    types: [created]

jobs:
  improve-docs:
    runs-on: ubuntu-latest
    # Only run on PR comments containing "gpt editor" (case insensitive)
    if: |
      github.event.issue.pull_request &&
      (contains(github.event.comment.body, 'gpt editor') || 
       contains(github.event.comment.body, 'GPT Editor') || 
       contains(github.event.comment.body, 'GPT editor') || 
       contains(github.event.comment.body, 'gpt Editor'))
    permissions:
      contents: read
      pull-requests: write
    
    steps:
      - name: Post initial comment
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PR_NUMBER: ${{ github.event.issue.number }}
          GITHUB_RUN_ID: ${{ github.run_id }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        run: |
          # Create link to current action run
          ACTION_URL="https://github.com/$GITHUB_REPOSITORY/actions/runs/$GITHUB_RUN_ID"
          
          # Determine if we're processing all lines or just changed lines
          COMMENT="${{ github.event.comment.body }}"
          if [[ "$COMMENT" == *"all lines"* ]] || [[ "$COMMENT" == *"ALL LINES"* ]] || [[ "$COMMENT" == *"All Lines"* ]] || [[ "$COMMENT" == *"All lines"* ]]; then
            MESSAGE="GPT Editor has begun analysis of ALL lines in the markdown files in this PR."
          else
            MESSAGE="GPT Editor has begun analysis of the markdown changes in this PR."
          fi
          
          # Create comment body with markdown link
          COMMENT_BODY="{\"body\":\"[$MESSAGE]($ACTION_URL)\"}"
          
          # Post comment using GitHub REST API
          curl -X POST \
            -H "Authorization: token $GITHUB_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            https://api.github.com/repos/$GITHUB_REPOSITORY/issues/$PR_NUMBER/comments \
            -d "$COMMENT_BODY"
      
      - name: Determine filtering mode
        id: filter-mode
        run: |
          COMMENT="${{ github.event.comment.body }}"
          echo "Comment: $COMMENT"
          
          if [[ "$COMMENT" == *"all lines"* ]] || [[ "$COMMENT" == *"ALL LINES"* ]] || [[ "$COMMENT" == *"All Lines"* ]] || [[ "$COMMENT" == *"All lines"* ]]; then
            echo "filter_by_changes=false" >> $GITHUB_OUTPUT
            echo "Processing ALL lines in files (not filtering by PR changes)"
          else
            echo "filter_by_changes=true" >> $GITHUB_OUTPUT
            echo "Processing only changed lines in PR"
          fi
      
      - name: Checkout code
        uses: actions/checkout@v5
        with:
          fetch-depth: 0  # Need full history to access PR changes
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          pip install openai weave
          
          # Install Vale
          curl -sL https://github.com/errata-ai/vale/releases/download/v3.9.6/vale_3.9.6_Linux_64-bit.tar.gz -o vale.tar.gz
          mkdir -p /tmp/vale
          tar -xzf vale.tar.gz -C /tmp/vale
          sudo mv /tmp/vale/vale /usr/local/bin/
          vale -v
      
      - name: Checkout PR
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          PR_NUMBER="${{ github.event.issue.number }}"
          echo "Checking out PR #$PR_NUMBER"
          
          # Configure git to fetch PRs
          git config --global --add remote.origin.fetch +refs/pull/*/head:refs/remotes/origin/pr/*
          git fetch origin
          
          # Check out the PR
          git checkout origin/pr/$PR_NUMBER
          
          echo "Current git status:"
          git status
      
      - name: Get changed markdown files
        id: changed-files
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PR_NUMBER: ${{ github.event.issue.number }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        run: |
          PR_NUMBER="${{ github.event.issue.number }}"
          
          # Find the merge base (common ancestor) with the target branch using API
          PR_INFO=$(curl -s -H "Authorization: token $GITHUB_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/$GITHUB_REPOSITORY/pulls/$PR_NUMBER")
          
          # Extract target branch properly using Python instead of grep
          TARGET_BRANCH=$(python3 -c "import json, sys; print(json.loads(sys.stdin.read())['base']['ref'])" <<< "$PR_INFO")
          echo "Target branch: $TARGET_BRANCH"
          
          if [ -z "$TARGET_BRANCH" ]; then
            echo "Error: Could not determine target branch"
            # Try to print the first part of PR_INFO for debugging
            echo "PR_INFO (truncated):"
            echo "$PR_INFO" | head -n 20
            exit 1
          fi
          
          # Get the merge base
          MERGE_BASE=$(git merge-base HEAD origin/$TARGET_BRANCH)
          echo "Merge base: $MERGE_BASE"
          
          # Get changed markdown files
          CHANGED_FILES=$(git diff --name-only $MERGE_BASE HEAD | grep '\.md$' || echo "")
          echo "Changed markdown files:"
          echo "$CHANGED_FILES"
          
          # Set output variables for use in next steps
          if [ -n "$CHANGED_FILES" ]; then
            echo "any_changed=true" >> $GITHUB_OUTPUT
            echo "all_changed_files<<EOF" >> $GITHUB_OUTPUT
            echo "$CHANGED_FILES" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          else
            echo "any_changed=false" >> $GITHUB_OUTPUT
            echo "No markdown files were found in the PR"
          fi
      
      - name: Process files with GPT and create suggestions
        if: steps.changed-files.outputs.any_changed == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PR_NUMBER: ${{ github.event.issue.number }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_RUN_ID: ${{ github.run_id }}
        run: |
          # Debug the files we're about to process
          echo "Processing the following files:"
          echo "${{ steps.changed-files.outputs.all_changed_files }}"
          
          # Create a Python script to process the markdown files
          cat > gpt_suggestions.py << 'EOF'
          import os
          import sys
          import subprocess
          import difflib
          import tempfile
          import json
          import re
          import re
          
          def process_file(file_path, filter_by_changes=True):
              """Process a markdown file with GPT editor and create suggestions for improvements"""
              print(f"Processing {file_path}")
              
              # Get the lines modified in the PR using git diff
              modified_line_ranges = []
              if filter_by_changes:
                  try:
                      # Find base branch reference to diff against
                      base_ref_result = subprocess.run(
                          ['git', 'merge-base', 'HEAD', 'origin/main'], 
                          capture_output=True, text=True, check=False
                      )
                      if base_ref_result.returncode != 0:
                          base_ref_result = subprocess.run(
                              ['git', 'merge-base', 'HEAD', 'origin/master'], 
                              capture_output=True, text=True, check=True
                          )
                      
                      base_ref = base_ref_result.stdout.strip()
                      
                      # Get PR modified lines
                      diff_result = subprocess.run(
                          ['git', 'diff', '--unified=0', base_ref, '--', file_path],
                          capture_output=True, text=True, check=True
                      )
                      
                      # Parse the diff for PR modified line ranges
                      for line in diff_result.stdout.splitlines():
                          if line.startswith('@@'):
                              parts = line.split(' ')
                              if len(parts) >= 3:
                                  added_part = parts[2]
                                  if added_part.startswith('+'):
                                      range_part = added_part[1:].split(',')
                                      start_line = int(range_part[0])
                                      num_lines = 1 if len(range_part) == 1 else int(range_part[1])
                                      if num_lines > 0:
                                          modified_line_ranges.append((start_line, start_line + num_lines - 1))
                      
                      print(f"Modified line ranges in PR: {modified_line_ranges}")
                  except Exception as e:
                      print(f"Error getting modified lines: {e}")
              
              # Save original content (the PR version)
              with open(file_path, 'r') as f:
                  original_content = f.read()
                  original_lines = original_content.splitlines()
              
              # Run gpt-editor.py to get improved content
              print("Running GPT editor (this may take a while)...")
              try:
                  # Don't capture output so it shows in CI logs
                  subprocess.run(['python', 'scripts/gpt-editor.py', file_path], check=True, capture_output=False)
                  print("GPT editor completed successfully")
              except Exception as e:
                  print(f"Error running GPT editor: {e}")
                  return
              
              # Read the improved content
              with open(file_path, 'r') as f:
                  improved_content = f.read()
                  improved_lines = improved_content.splitlines()
              
              # Create temporary files for git diff
              with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.md') as original_file:
                  original_file.write(original_content)
                  original_path = original_file.name
              
              with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.md') as improved_file:
                  improved_file.write(improved_content)
                  improved_path = improved_file.name
              
              # Restore the original content
              with open(file_path, 'w') as f:
                  f.write(original_content)
              
              # If no changes were made, exit
              if original_content == improved_content:
                  os.unlink(original_path)
                  os.unlink(improved_path)
                  return
              
              # Use git diff to find changes with exact line positions
              try:
                  # Get exact line changes with git diff
                  diff_cmd = ['git', 'diff', '--no-index', original_path, improved_path]
                  diff_result = subprocess.run(diff_cmd, capture_output=True, text=True, check=False)
                  diff_output = diff_result.stdout
                  
                  # Parse the diff for line changes
                  hunks = []
                  in_hunk = False
                  hunk_start = None
                  hunk_lines = []
                  hunk_original_lines = []
                  
                  lines = diff_output.splitlines()
                  i = 0
                  while i < len(lines):
                      line = lines[i]
                      
                      # Find hunk headers
                      if line.startswith('@@'):
                          # If we have a previous hunk, save it
                          if in_hunk and hunk_start is not None and hunk_lines:
                              hunks.append((hunk_start, hunk_original_lines, hunk_lines))
                          
                          # Start a new hunk
                          in_hunk = True
                          hunk_lines = []
                          hunk_original_lines = []
                          
                          # Parse the hunk header
                          # Example: "@@ -10,4 +10,5 @@"
                          match = re.search(r'@@ -(\d+)(?:,\d+)? \+(\d+)(?:,\d+)? @@', line)
                          if match:
                              # Get the starting line number in the new file
                              hunk_start = int(match.group(2))
                              i += 1
                              
                              # Process lines in this hunk
                              while i < len(lines) and not lines[i].startswith('@@'):
                                  if lines[i].startswith('+') and not lines[i].startswith('+++'):
                                      hunk_lines.append(lines[i][1:])  # Remove the '+' prefix
                                  elif lines[i].startswith('-') and not lines[i].startswith('---'):
                                      hunk_original_lines.append(lines[i][1:])  # Remove the '-' prefix
                                  i += 1
                              
                              # Back up one to handle the next hunk header in the outer loop
                              i -= 1
                          else:
                              in_hunk = False
                              i += 1
                      else:
                          i += 1
                  
                  # Don't forget the last hunk
                  if in_hunk and hunk_start is not None and hunk_lines:
                      hunks.append((hunk_start, hunk_original_lines, hunk_lines))
                  
                  # Process each hunk
                  for start_line, original_section, improved_section in hunks:
                      # Only consider hunks with actual improvements
                      if not improved_section:
                          continue
                          
                      # Skip hunks outside modified ranges if filtering
                      if filter_by_changes:
                          in_modified_range = any(
                              range_start <= start_line <= range_end or
                              (start_line <= range_start and start_line + len(improved_section) - 1 >= range_start)
                              for range_start, range_end in modified_line_ranges
                          )
                          
                          if not in_modified_range:
                              continue
                      
                      # Create a suggestion for this hunk
                      create_suggestion(file_path, start_line, original_section, improved_section)
              
              except Exception as e:
                  print(f"Error processing diff: {e}")
              
              # Clean up
              os.unlink(original_path)
              os.unlink(improved_path)
          
          def create_suggestion(file_path, line_number, original_section, improved_section):
              """Create a GitHub PR review comment with a suggestion"""
              # Get run ID and repository for the action URL
              run_id = os.environ.get('GITHUB_RUN_ID')
              repo = os.environ.get('GITHUB_REPOSITORY')
              action_url = f"https://github.com/{repo}/actions/runs/{run_id}"
              
              # Validate that the line numbers make sense
              if start_line < 1:
                  print(f"Warning: Invalid start line {start_line}, adjusting to 1")
                  start_line = 1
              
              # Format the suggestion with link to the action run
              body = f"```suggestion\n{chr(10).join(improved_section)}\n```\n\n*[Generated by GPT Editor]({action_url})*"
              
              pr_number = os.environ.get('PR_NUMBER')
              github_token = os.environ.get('GITHUB_TOKEN')
              
              # Debug output to help track line mappings
              print(f"Suggesting change for {file_path} lines {start_line}-{end_line}")
              print(f"Original ({len(original_section)} lines): {original_section[:1]}...")
              print(f"Improved ({len(improved_section)} lines): {improved_section[:1]}...")
              
              # Create a review comment using GitHub API
              try:
                  # First get the latest commit SHA on the PR
                  curl_cmd = [
                      'curl', '-s',
                      '-H', f'Authorization: token {github_token}',
                      '-H', 'Accept: application/vnd.github.v3+json',
                      f'https://api.github.com/repos/{repo}/pulls/{pr_number}'
                  ]
                  
                  pr_info_result = subprocess.run(curl_cmd, capture_output=True, text=True, check=True)
                  pr_info = json.loads(pr_info_result.stdout)
                  commit_id = pr_info['head']['sha']
                  
                  # Create a review comment
                  review_data = {
                      "commit_id": commit_id,
                      "path": file_path,
                      "body": body,
                      "line": line_number,
                      "side": "RIGHT"
                  }
                  
                  # Convert to JSON
                  review_json = json.dumps(review_data)
                  
                  # Create temp file for curl input
                  with tempfile.NamedTemporaryFile(mode='w', delete=False) as tmp:
                      tmp.write(review_json)
                      tmp_path = tmp.name
                  
                  # For GitHub suggestion comments, we need to create a review first
                  print(f"Creating comment for PR #{pr_number}, file {file_path}, line {line_number}")
                  
                  # First create a review
                  review_data = {
                      "commit_id": commit_id,
                      "body": "GPT Editor review",
                      "event": "COMMENT"
                  }
                  
                  with tempfile.NamedTemporaryFile(mode='w', delete=False) as tmp:
                      tmp.write(json.dumps(review_data))
                      tmp_path = tmp.name
                  
                  # Create the review
                  curl_review_cmd = [
                      'curl', '-v', '-X', 'POST',
                      '-H', f'Authorization: token {github_token}',
                      '-H', 'Accept: application/vnd.github.v3+json',
                      '-H', 'Content-Type: application/json',
                      f'https://api.github.com/repos/{repo}/pulls/{pr_number}/reviews',
                      '-d', f'@{tmp_path}'
                  ]
                  
                  review_result = subprocess.run(curl_review_cmd, capture_output=True, text=True)
                  
                  if review_result.returncode != 0:
                      print(f"Error creating review: {review_result.stderr}")
                      os.unlink(tmp_path)
                      return
                  
                  try:
                      review_response = json.loads(review_result.stdout)
                      review_id = review_response.get('id')
                      
                      if not review_id:
                          print("Failed to get review ID from response")
                          print(f"Response: {review_result.stdout[:200]}...")
                          os.unlink(tmp_path)
                          return
                      
                      # Now create a comment on the review using the GitHub REST API directly
                      os.unlink(tmp_path)  # Remove the old temp file
                      
                      # Create a PR comment using the API
                      comment_data = {
                          "body": body,
                          "path": file_path,
                          "line": line_number,
                          "side": "RIGHT"
                      }
                      
                      with tempfile.NamedTemporaryFile(mode='w', delete=False) as tmp:
                          tmp.write(json.dumps(comment_data))
                          tmp_path = tmp.name
                      
                      curl_comment_cmd = [
                          'curl', '-v', '-X', 'POST',
                          '-H', f'Authorization: token {github_token}',
                          '-H', 'Accept: application/vnd.github.v3+json',
                          '-H', 'Content-Type: application/json',
                          f'https://api.github.com/repos/{repo}/pulls/{pr_number}/comments',
                          '-d', f'@{tmp_path}'
                      ]
                      
                      comment_result = subprocess.run(curl_comment_cmd, capture_output=True, text=True)
                      
                      if comment_result.returncode == 0:
                          print("Successfully created suggestion comment")
                      else:
                          print(f"Error creating comment: {comment_result.stderr}")
                          print(f"Response: {comment_result.stdout}")
                  except json.JSONDecodeError:
                      print(f"Error parsing review response: {review_result.stdout[:200]}...")
                  
                  # Clean up temp file
                  os.unlink(tmp_path)
                  
                  print(f"Created suggestion for {file_path} line {line_number}")
              except Exception as e:
                  print(f"Error creating review comment: {e}")
          
          # Process all files passed on the command line
          if __name__ == "__main__":
              if len(sys.argv) < 2:
                  print("Usage: python gpt_suggestions.py <file_path> [filter_by_changes=true]")
                  sys.exit(1)
                  
              file_path = sys.argv[1]
              # Check if we should filter by changed lines
              filter_by_changes = True  # Default behavior
              if len(sys.argv) > 2:
                  filter_by_changes = sys.argv[2].lower() == "true"
              
              print(f"Processing {file_path} with filter_by_changes={filter_by_changes}")
              
              if file_path.endswith('.md'):
                  process_file(file_path, filter_by_changes)
          EOF
          
          # Add basic diagnostics
          echo "CURRENT DIRECTORY: $(pwd)"
          echo "CHECKING IF GPT EDITOR EXISTS:"
          if [ -f "scripts/gpt-editor.py" ]; then
            echo "‚úÖ GPT editor script exists"
          else
            echo "‚ùå GPT editor script NOT found at scripts/gpt-editor.py"
            find . -name "gpt-editor.py" -type f
            exit 1
          fi
          
          FILTER="${{ steps.filter-mode.outputs.filter_by_changes }}"
          
          # Save files to temporary file and read line by line
          echo "${{ steps.changed-files.outputs.all_changed_files }}" > changed_md_files.txt
          
          echo "STARTING TO PROCESS ACTUAL MARKDOWN FILES:"
          while IFS= read -r FILE; do
            if [ -n "$FILE" ] && [ -f "$FILE" ]; then
              echo "===================================================="
              echo "üîÑ PROCESSING FILE: $FILE"
              echo "===================================================="
              
              # 1. Print file content for debugging
              echo "FILE CONTENT PREVIEW (first 10 lines):"
              head -n 10 "$FILE" || echo "Cannot read file"
              
              # 2. Run the GPT editor script directly
              echo "RUNNING GPT EDITOR DIRECTLY:"
              python scripts/gpt-editor.py "$FILE"
              GPT_RESULT=$?
              
              echo "GPT EDITOR EXIT CODE: $GPT_RESULT"
              
              if [ $GPT_RESULT -eq 0 ]; then
                echo "‚úÖ GPT EDITOR COMPLETED SUCCESSFULLY"
                
                # 3. Now run our processing script
                echo "RUNNING SUGGESTION PROCESSOR:"
                python gpt_suggestions.py "$FILE" "$FILTER"
                echo "SUGGESTION PROCESSOR EXIT CODE: $?"
              else
                echo "‚ùå GPT EDITOR FAILED"
              fi
              
              echo "===================================================="
            fi
          done < changed_md_files.txt
      
      - name: Comment if no markdown files were changed
        if: steps.changed-files.outputs.any_changed != 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PR_NUMBER: ${{ github.event.issue.number }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        run: |
          # Create comment body
          COMMENT_BODY="{\"body\":\"No markdown files were changed in this PR, so the GPT editor has nothing to process.\"}"
          
          # Post comment using GitHub REST API
          curl -X POST \
            -H "Authorization: token $GITHUB_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            https://api.github.com/repos/$GITHUB_REPOSITORY/issues/$PR_NUMBER/comments \
            -d "$COMMENT_BODY"
