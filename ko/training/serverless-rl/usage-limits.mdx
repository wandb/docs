---
title: 사용 정보 및 한도
description: W&B Serverless RL의 요금, 사용 한도 및 계정 제한 사항을 알아봅니다
---

<div id="pricing">
  ## 요금
</div>

요금은 추론(inference), 학습(training), 스토리지(storage) 세 가지 구성 요소로 이루어져 있습니다. 구체적인 청구 단가는 [요금 페이지](https://wandb.ai/site/pricing/reinforcement-learning)에서 확인하세요.

<div id="inference">
  ### 추론(Inference)
</div>

Serverless RL 추론 요청에 대한 요금 체계는 W&amp;B Inference 요금과 동일합니다. 자세한 내용은 [모델별 비용](https://site.wandb.ai/pricing/reinforcement-learning)을 확인하세요. 크레딧 구매, 계정 등급, 사용 한도에 대해 더 알아보려면 [W&amp;B Inference 문서](/ko/inference/usage-limits#purchase-more-credits)를 참고하세요.

<div id="training">
  ### 학습
</div>

각 학습 단계마다 Serverless RL은 에이전트의 출력과 해당 보상(보상 함수로 계산됨)이 포함된 trajectory 배치를 수집합니다. 이렇게 모은 trajectory 배치는 해당 태스크에 맞게 기본 모델을 특화하는 LoRA 어댑터의 가중치를 업데이트하는 데 사용됩니다. 이러한 LoRA를 업데이트하는 학습 작업은 Serverless RL이 관리하는 전용 GPU 클러스터에서 실행됩니다.

공개 프리뷰 기간 동안 학습은 무료입니다.

<div id="model-storage">
  ### 모델 스토리지
</div>

Serverless RL은 학습한 LoRA의 체크포인트를 저장해 두었다가, 언제든지 평가하거나 서빙하거나 추가로 학습을 진행할 수 있도록 합니다. 스토리지는 전체 체크포인트 크기와 사용 중인 [요금제](https://wandb.ai/site/pricing)에 따라 월 단위로 과금됩니다. 모든 요금제에는 최소 5GB의 무료 스토리지가 포함되어 있으며, 이는 대략 LoRA 30개에 해당하는 용량입니다. 공간을 절약하려면 성능이 낮은 LoRA는 삭제하는 것을 권장합니다. 구체적인 방법은 [ART SDK](https://art.openpipe.ai/features/checkpoint-deletion)를 참고하세요.

<div id="limits">
  ## 제한 사항
</div>

* **Inference 동시 처리 한도**: 기본적으로 Serverless RL은 현재 사용자당 최대 2000개, 프로젝트당 최대 6000개의 동시 요청을 지원합니다. 동시 처리 한도를 초과하면 Inference API는 `429 Concurrency limit reached for requests` 응답을 반환합니다. 이 오류를 피하려면 학습 작업 또는 프로덕션 워크로드에서 한 번에 전송하는 동시 요청 수를 줄이십시오. 더 높은 동시 처리 한도가 필요한 경우 support@wandb.com으로 요청할 수 있습니다.

* **지리적 제한**: Serverless RL은 지원되는 일부 지역에서만 사용할 수 있습니다. 자세한 내용은 [서비스 약관](https://site.wandb.ai/terms/)을 참조하십시오.