---
title: 통합 개요
description: "Weave의 자동 패칭을 통해 30개 이상의 프로바이더와 프레임워크 전반에서 LLM 호출을 끊김 없이 추적 및 모니터링하며, 코드 변경 없이 OpenAI, Anthropic, Google AI 및 주요 오케스트레이션 도구를 지원합니다."
---

<div id="integrations">
  # 통합
</div>

Weave는 지원되는 모든 통합에 대해 기본적으로 **자동 암시적 패칭(implicit patching)** 을 제공합니다:

**암시적 패칭(자동):** 라이브러리는 언제 import되었는지에 상관없이 자동으로 패치됩니다.

```python lines
# 옵션 1: weave.init() 이전에 import
import openai
import weave
weave.init('my-project')  # OpenAI가 자동으로 패치됩니다!

# 옵션 2: weave.init() 이후에 import
import weave
weave.init('my-project')
import anthropic  # import 훅을 통해 자동으로 패치됩니다!
```

**암시적 패칭 비활성화:** 보다 명시적으로 제어하고 싶다면 자동 패칭을 비활성화할 수 있습니다.

```python lines
import weave

# 옵션 1: settings 매개변수를 통해
weave.init('my-project', settings={'implicitly_patch_integrations': False})

# 옵션 2: 환경 변수를 통해
# 스크립트 실행 전에 WEAVE_IMPLICITLY_PATCH_INTEGRATIONS=false로 설정하세요

# 암묵적 패칭이 비활성화된 경우, 통합을 명시적으로 패치해야 합니다
import openai
weave.patch_openai()  # OpenAI 추적에 이제 필수입니다
```

**명시적 패치(수동):** 세밀한 제어를 위해 통합을 직접 패치할 수 있습니다.

```python lines
import weave
weave.init('my-project')
weave.integrations.patch_openai()  # OpenAI 추적 활성화
weave.integrations.patch_anthropic()  # Anthropic 추적 활성화
```

W&amp;B Weave는 주요 LLM 제공자 및 오케스트레이션 프레임워크와의 로깅 통합을 제공합니다. 이러한 통합을 통해 다양한 라이브러리를 통해 이루어지는 호출을 원활하게 추적하여 AI 애플리케이션을 더욱 효과적으로 모니터링하고 분석할 수 있습니다.

<div id="llm-providers">
  ## LLM 공급자
</div>

LLM 공급자는 예측을 생성할 수 있도록 대규모 언어 모델에 대한 접근을 제공하는 서비스/벤더입니다. Weave는 이러한 공급자와 통합되어 해당 API와의 상호작용을 로깅하고 추적합니다:

* **[W&amp;B Inference Service](https://docs.wandb.ai/inference/)**
* **[Amazon Bedrock](/ko/weave/guides/integrations/bedrock)**
* **[Anthropic](/ko/weave/guides/integrations/anthropic)**
* **[Cerebras](/ko/weave/guides/integrations/cerebras)**
* **[Cohere](/ko/weave/guides/integrations/cohere)**
* **[Google](/ko/weave/guides/integrations/google)**
* **[Groq](/ko/weave/guides/integrations/groq)**
* **[Hugging Face Hub](/ko/weave/guides/integrations/huggingface)**
* **[LiteLLM](/ko/weave/guides/integrations/litellm)**
* **[Microsoft Azure](/ko/weave/guides/integrations/azure)**
* **[MistralAI](/ko/weave/guides/integrations/mistral)**
* **[NVIDIA NIM](/ko/weave/guides/integrations/nvidia_nim)**
* **[OpenAI](/ko/weave/guides/integrations/openai)**
* **[OpenRouter](/ko/weave/guides/integrations/openrouter)**
* **[Together AI](/ko/weave/guides/integrations/together_ai)**

**[Local Models](/ko/weave/guides/integrations/local_models)**: 자체 인프라에서 모델을 직접 실행할 때 사용합니다.

<div id="frameworks">
  ## 프레임워크
</div>

프레임워크는 AI 애플리케이션에서 실제 실행 파이프라인을 구성하고 관리하는 데 도움을 줍니다. 복잡한 워크플로를 구축하기 위한 도구와 추상화를 제공합니다. Weave는 전체 파이프라인을 추적하기 위해 이러한 프레임워크와 통합합니다:

* **[OpenAI Agents SDK](/ko/weave/guides/integrations/openai_agents)**
* **[LangChain](/ko/weave/guides/integrations/langchain)**
* **[LlamaIndex](/ko/weave/guides/integrations/llamaindex)**
* **[DSPy](/ko/weave/guides/integrations/dspy)**
* **[Instructor](/ko/weave/guides/integrations/instructor)**
* **[CrewAI](/ko/weave/guides/integrations/crewai)**
* **[Smolagents](/ko/weave/guides/integrations/smolagents)**
* **[PydanticAI](/ko/weave/guides/integrations/pydantic_ai)**
* **[Google Agent Development Kit (ADK)](/ko/weave/guides/integrations/google_adk)**
* **[AutoGen](/ko/weave/guides/integrations/autogen)**
* **[Verdict](/ko/weave/guides/integrations/verdict)**
* **[TypeScript SDK](/ko/weave/guides/integrations/js)**
* **[Agno](/ko/weave/guides/integrations/agno)**
* **[Koog](/ko/weave/guides/integrations/koog)**

<div id="rl-frameworks">
  ## 강화 학습(RL) 프레임워크
</div>

* **[Verifiers](/ko/weave/guides/integrations/verifiers)**

<div id="protocols">
  ## 프로토콜
</div>

Weave는 AI 애플리케이션과 이를 지원하는 서비스 간의 통신을 가능하게 하는 표준화된 프로토콜과 통합을 지원합니다:

* **[Model Context Protocol (MCP)](/ko/weave/guides/integrations/mcp)**

위 목록에서 원하는 통합을 선택해 선호하는 LLM 제공자, 프레임워크 또는 프로토콜과 함께 Weave를 사용하는 방법을 자세히 알아보세요. 직접 LLM API를 호출하든, 복잡한 파이프라인을 구축하든, 표준화된 프로토콜을 사용하든, Weave는 AI 애플리케이션을 효과적으로 추적하고 분석할 수 있는 도구를 제공합니다.