---
title: "모델로 애플리케이션 버전 추적하기"
description: "데이터와 코드를 결합한 구조화된 모델로 애플리케이션의 버전을 추적하세요."
---

`Model`은 구성(config), 학습된 모델 가중치, 기타 정보 등을 포함할 수 있는 데이터와, 모델이 동작하는 방식을 정의하는 코드의 조합입니다. 코드를 이 API와 호환되도록 구조화하면, 애플리케이션을 체계적인 방식으로 버전 관리할 수 있어 실험을 더 조직적으로 추적할 수 있습니다.

<Tabs>
  <Tab title="Python">
    Weave에서 모델을 생성하려면 다음이 필요합니다:

    * `weave.Model`을 상속하는 클래스
    * 모든 매개변수에 대한 타입 정의
    * `@weave.op()` 데코레이터가 붙은 타입 지정 `predict` 함수

    ```python lines
    from weave import Model
    import weave

    class YourModel(Model):
        attribute1: str
        attribute2: int

        @weave.op()
        def predict(self, input_data: str) -> dict:
            # 모델 로직을 여기에 작성합니다
            prediction = self.attribute1 + ' ' + input_data
            return {'pred': prediction}
    ```

    모델은 일반적으로 다음과 같이 호출할 수 있습니다:

    ```python lines
    import weave
    weave.init('intro-example')

    model = YourModel(attribute1='hello', attribute2=5)
    model.predict('world')
    ```

    이렇게 하면 `predict`를 호출할 때마다 입력 및 출력과 함께 모델 설정이 추적됩니다.

    ## 모델의 자동 버전 관리

    모델을 정의하는 매개변수나 코드를 변경하면, 이러한 변경 사항이 기록되고 버전이 업데이트됩니다.
    이를 통해 서로 다른 버전의 모델 간 예측을 비교할 수 있습니다. 이를 활용해 프롬프트를 반복적으로 개선하거나 최신 LLM을 시도하고, 서로 다른 설정 간 예측을 비교하세요.

    예를 들어, 여기서는 새 모델을 생성합니다:

    ```python lines
    import weave
    weave.init('intro-example')

    model = YourModel(attribute1='howdy', attribute2=10)
    model.predict('world')
    ```

    이를 호출한 후 UI에서 이 `Model`의 버전이 두 개이며, 각각 서로 다른 호출 내역이 추적되어 있는 것을 확인할 수 있습니다.

    ## 모델 서빙

    모델을 서빙하려면 다음을 실행하여 FastAPI 서버를 손쉽게 띄울 수 있습니다:

    ```bash
    weave serve <your model ref>
    ```

    자세한 내용은 [serve](/ko/weave/guides/tools/serve)를 참조하세요.

    ## 프로덕션 호출 추적

    프로덕션 호출을 구분하기 위해, 예측에 추가 attribute를 넣어 UI나 API에서 쉽게 필터링할 수 있도록 할 수 있습니다.

    ```python lines
    with weave.attributes({'env': 'production'}):
        model.predict('world')
    ```
  </Tab>

  <Tab title="TypeScript">
    ```plaintext
    이 기능은 아직 TypeScript에서는 사용할 수 없습니다. 추후 지원을 기다려 주세요!
    ```
  </Tab>
</Tabs>