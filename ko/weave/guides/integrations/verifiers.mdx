---
title: Verifiers
description: "Weave를 사용해 Verifiers RL 환경과 LLM 에이전트 학습을 추적·디버깅하여 멀티 라운드 대화, 평가 롤아웃, 모델 성능 지표를 포착하고 강화 학습 워크플로에 대한 종합적인 가시성을 확보합니다."
---

[Verifiers](https://github.com/willccbb/verifiers)는 강화 학습(RL) 환경을 생성하고 LLM 에이전트를 학습하기 위한 모듈식 컴포넌트 라이브러리입니다. Verifiers로 구축한 환경은 LLM 평가, 합성 데이터 파이프라인, 어떤 OpenAI 호환 엔드포인트에도 사용할 수 있는 에이전트 하네스, 그리고 RL 학습에 활용할 수 있습니다.

학습 지표를 기록하기 위해 W&amp;B를 사용하는 것과 더불어, Weave를 Verifiers RL 워크플로에 통합해 학습 중 모델이 어떻게 동작하는지 관측할 수 있습니다. Weave는 각 단계의 입력, 출력, 타임스탬프를 기록하므로, 매 단계에서 데이터가 어떻게 변환되는지 살펴보고, 복잡한 멀티 라운드 대화를 디버깅하며, 학습 결과를 최적화할 수 있습니다.

또한 Weave와 Verifiers를 함께 사용해 Evaluation을 수행할 수도 있습니다.

이 가이드는 Verifiers, W&amp;B, Weave를 설치하는 방법을 보여 주고, Verifiers를 Weave 및 W&amp;B와 함께 사용하는 두 가지 예제를 제공합니다.

![verifiers wandb run page](/images/weave/verifiers.gif)

<div id="getting-started">
  ## 시작하기
</div>

Verifiers를 Weave와 통합하려면 먼저 `uv`를 사용해 Verifiers 라이브러리를 설치하세요 ([라이브러리 작성자가 권장하는 방법](https://github.com/willccbb/verifiers?tab=readme-ov-file#setup)). 다음 명령어 중 하나를 사용해 라이브러리를 설치합니다:

```bash
# 로컬 개발 및 API 기반 모델을 위한 핵심 라이브러리 설치
uv add verifiers

# PyTorch 및 GPU 지원을 포함한 모든 선택적 종속성이 포함된 전체 버전 라이브러리 설치
uv add 'verifiers[all]' && uv pip install flash-attn --no-build-isolation

# 아직 출시되지 않은 최신 기능 및 수정 사항을 포함하여 GitHub에서 직접 최신 버전 라이브러리 설치
uv add verifiers @ git+https://github.com/willccbb/verifiers.git
```

그다음 Weave와 W&amp;B를 설치하세요:

```bash
uv pip install weave wandb
```

Weave는 기본적으로 라이브러리에 대해 [암시적 패칭](/ko/weave/guides/integrations#automatic-implicit-patching)을 활성화합니다. 이를 통해 별도의 호출 패치 함수를 명시적으로 사용하지 않고도 Verifiers와 함께 Weave를 사용할 수 있습니다.

<div id="trace-rollouts-and-evaluate">
  ### rollout 추적 및 평가
</div>

필요한 라이브러리를 설치한 후에는 Weave와 Verifiers를 함께 사용하여 호출을 추적하고 평가를 실행할 수 있습니다.

다음 예제 스크립트는 Verifiers로 평가를 실행하고 결과를 Weave에 로그로 기록하는 방법을 보여줍니다. 이 스크립트는 [GSM8K 데이터셋](https://huggingface.co/datasets/openai/gsm8k)을 사용해 LLM이 수학 문제를 푸는 능력을 테스트합니다. GPT-4에게 두 개의 수학 문제를 풀도록 요청한 뒤 각 응답에서 숫자 값을 추출하고, Verifiers를 평가 프레임워크로 사용해 시도를 채점합니다.

예제를 실행한 후 Weave에서 결과를 확인하세요:

```python lines
import os
from openai import OpenAI
import verifiers as vf
import weave

os.environ["OPENAI_API_KEY"] = "<YOUR-OPENAI-API-KEY>"

# Weave 초기화
weave.init("verifiers_demo")

# 최소 단일 턴 환경
dataset = vf.load_example_dataset("gsm8k", split="train").select(range(2))
parser = vf.ThinkParser()

def correct_answer(parser, completion, answer):
    parsed = parser.parse_answer(completion) or ""
    return 1.0 if parsed.strip() == answer.strip() else 0.0

rubric = vf.Rubric(funcs=[correct_answer, parser.get_format_reward_func()], weights=[1.0, 0.2])

env = vf.SingleTurnEnv(
    dataset=dataset,
    system_prompt="Think step-by-step, then answer.",
    parser=parser,
    rubric=rubric,
)

client = OpenAI()
results = env.evaluate(
    client, "gpt-4.1-mini", num_examples=2, rollouts_per_example=2, max_concurrent=8
)
```

<div id="fine-tune-a-model-with-experiment-tracking-and-tracing">
  ### 실험 추적 및 트레이싱을 활용한 모델 파인튜닝
</div>

Weave는 학습 중 모델이 어떻게 동작하는지에 대한 인사이트를 제공하여 RL 파인튜닝 워크플로에서 강력한 도구가 될 수 있습니다. W&amp;B와 함께 사용하면 포괄적인 모니터링과 가시성을 확보할 수 있습니다. W&amp;B는 학습 지표와 성능 차트를 추적하고, Weave는 학습 과정 동안 각 상호작용에 대한 상세한 트레이스를 기록합니다.

`verifiers` 리포지토리에는 시작하는 데 도움이 되는 즉시 실행 가능한 [예제](https://github.com/willccbb/verifiers/tree/main/examples/grpo)가 포함되어 있습니다.

다음 예시 RL 학습 파이프라인은 로컬 추론 서버를 실행하고 GSM8K 데이터셋을 사용해 모델을 학습합니다. 모델은 수학 문제에 대한 답을 생성하고, 학습 루프는 출력에 점수를 매긴 뒤 그에 따라 모델을 업데이트합니다. W&amp;B는 loss, reward, accuracy와 같은 학습 지표를 로그하고, Weave는 입력, 출력, 추론 과정, 점수 정보를 캡처합니다.

이 파이프라인을 사용하려면:

1. 소스 코드에서 프레임워크를 설치합니다. 다음 명령은 GitHub에서 Verifiers 라이브러리와 필요한 의존성을 설치합니다:

```bash
git clone https://github.com/willccbb/verifiers
cd verifiers
uv sync --all-extras && uv pip install flash-attn --no-build-isolation
```

2. 사전 구성된 환경을 설치합니다. 다음 명령은 사전 구성된 GSM8K 학습 환경을 설치합니다:

```bash
vf-install gsm8k --from-repo
```

3. 모델을 학습합니다. 다음 명령들은 각각 추론 서버와 학습 루프를 실행합니다. 이 예시 워크플로우에서는 기본값으로 `report_to=wandb`가 설정되어 있어, 별도로 `wandb.init`를 호출할 필요가 없습니다. 이 머신이 W&amp;B에 메트릭을 기록할 수 있도록 인증하라는 프롬프트가 표시됩니다.

```bash
# 추론 서버 실행
CUDA_VISIBLE_DEVICES=0 vf-vllm --model willcb/Qwen3-0.6B --enforce-eager --disable-log-requests

# 학습 루프 실행
CUDA_VISIBLE_DEVICES=1 accelerate launch --num-processes 1 --config-file configs/zero3.yaml examples/grpo/train_gsm8k.py
```

<Note>
  이 예제는 2개의 H100 GPU에서 성공적으로 테스트했으며, 안정성을 높이기 위해 다음 환경 변수를 설정했습니다:

  ```bash
  # 실행을 시작하기 전에 server와 trainer용 두 셸 모두에서 설정
  export NCCL_CUMEM_ENABLE=0
  export NCCL_CUMEM_HOST_ENABLE=0
  ```

  이 변수들은 디바이스 메모리 할당 시 CUDA Unified Memory(CuMem)를 비활성화합니다.
</Note>

학습이 시작되면, 실행 중에 UI에 기록된 트레이스를 [트레이스 보기](/ko/weave/guides/tools/weave-in-workspaces)에서 확인할 수 있습니다.

트레이스에는 `Environment.a_generate` 및 `Rubric.score_rollouts` 메서드의 `logprobs`가 포함되지 않습니다. 이렇게 하면 페이로드 크기를 줄이면서도 학습을 위해 원본은 그대로 유지할 수 있습니다.

<div id="see-also">
  ## 같이 보기
</div>

Verifiers는 W&amp;B Models와 긴밀하게 통합되어 있습니다. 자세한 내용은 [Monitoring](https://verifiers.readthedocs.io/en/latest/training.html#monitoring)을 참고하세요.