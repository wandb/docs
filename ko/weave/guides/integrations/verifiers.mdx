---
title: Verifiers
description: Weave를 사용하여 Verifiers 강화학습(reinforcement learning) 환경과 LLM 에이전트 트레이닝을
  추적하고 디버깅하세요. 다회차 대화, 평가 롤아웃, 모델 성능 메트릭을 캡처하여 강화학습(reinforcement learning) 워크플로우에
  대한 포괄적인 관측성을 제공합니다.
---

[Verifiers](https://github.com/willccbb/verifiers)는 강화학습(RL) 환경을 구축하고 LLM 에이전트를 트레이닝하기 위한 모듈형 컴포넌트 라이브러리입니다. Verifiers로 구축된 환경은 LLM 평가, 합성 데이터 파이프라인, 모든 OpenAI 호환 엔드포인트를 위한 에이전트 하네스, 그리고 RL 트레이닝에 활용될 수 있습니다.

W&B를 사용하여 트레이닝 메트릭을 기록하는 것과 더불어, Weave를 Verifiers RL 워크플로우에 통합하면 트레이닝 중 모델이 어떻게 작동하는지에 대한 가시성(observability)을 확보할 수 있습니다. Weave는 각 단계의 입력, 출력, 타임스탬프를 기록하여 데이터가 매 순간 어떻게 변환되는지 검사하고, 복잡한 다중 라운드 대화를 디버깅하며, 트레이닝 결과를 최적화할 수 있도록 돕습니다.

또한 Weave와 Verifiers를 함께 사용하여 평가를 수행할 수도 있습니다.

이 가이드는 Verifiers, W&B, Weave를 설치하는 방법을 설명하고, Verifiers를 Weave 및 W&B와 함께 사용하는 두 가지 예시를 제공합니다.

![verifiers wandb run page](/images/weave/verifiers.gif)

## 시작하기

Verifiers를 Weave와 통합하려면 우선 `uv`를 사용하여 Verifiers 라이브러리를 설치합니다([라이브러리 작성자가 권장하는 방식](https://github.com/willccbb/verifiers?tab=readme-ov-file#setup)입니다). 다음 코맨드 중 하나를 사용하여 라이브러리를 설치하세요.

```bash
# 로컬 개발 및 API 기반 모델을 위한 코어 라이브러리 설치
uv add verifiers

# PyTorch 및 GPU 지원을 포함한 모든 선택적 종속성이 포함된 풀 버전 설치
uv add 'verifiers[all]' && uv pip install flash-attn --no-build-isolation

# 최신 미출시 기능 및 수정을 포함하여 GitHub에서 직접 최신 버전 설치
uv add verifiers @ git+https://github.com/willccbb/verifiers.git
```

그 다음 Weave와 W&B를 설치합니다.

```bash
uv pip install weave wandb
```

Weave는 기본적으로 이 라이브러리에 대해 [암시적 패칭(implicit patching)](/weave/guides/integrations#automatic-implicit-patching)을 활성화합니다. 이를 통해 명시적인 콜 패치 함수 없이도 Verifiers와 함께 Weave를 사용할 수 있습니다.

### Trace rollout 및 평가

필요한 라이브러리를 설치한 후, Weave와 Verifiers를 함께 사용하여 호출을 추적(trace)하고 평가를 실행할 수 있습니다.

다음 예시 스크립트는 Verifiers로 평가를 실행하고 결과를 Weave에 로그하는 방법을 보여줍니다. 이 스크립트는 [GSM8K 데이터셋](https://huggingface.co/datasets/openai/gsm8k)을 사용하여 수학 문제를 해결하는 LLM의 능력을 테스트합니다. GPT-4에 두 개의 수학 문제를 풀도록 요청하고, 각 응답에서 수치 값을 추출한 다음, Verifiers를 평가 프레임워크로 사용하여 시도를 채점합니다.

예시를 실행하고 Weave에서 결과를 확인해 보세요.

```python lines
import os
from openai import OpenAI
import verifiers as vf
import weave

os.environ["OPENAI_API_KEY"] = "<YOUR-OPENAI-API-KEY>"

# Weave 초기화
weave.init("verifiers_demo")

# 최소한의 단일 턴(single-turn) 환경
dataset = vf.load_example_dataset("gsm8k", split="train").select(range(2))
parser = vf.ThinkParser()

def correct_answer(parser, completion, answer):
    parsed = parser.parse_answer(completion) or ""
    return 1.0 if parsed.strip() == answer.strip() else 0.0

rubric = vf.Rubric(funcs=[correct_answer, parser.get_format_reward_func()], weights=[1.0, 0.2])

env = vf.SingleTurnEnv(
    dataset=dataset,
    system_prompt="Think step-by-step, then answer.",
    parser=parser,
    rubric=rubric,
)

client = OpenAI()
results = env.evaluate(
    client, "gpt-4.1-mini", num_examples=2, rollouts_per_example=2, max_concurrent=8
)
```

### 실험 추적 및 트레이싱을 통한 모델 파인튜닝

Weave는 트레이닝 중 모델이 어떻게 수행되고 있는지에 대한 통찰력을 제공함으로써 RL 파인튜닝 워크플로우에서 강력한 툴이 될 수 있습니다. W&B와 함께 사용하면 종합적인 가시성을 얻을 수 있습니다. W&B는 트레이닝 메트릭과 성능 차트를 추적하고, Weave는 트레이닝 프로세스 중 각 상호작용의 상세한 추적(trace)을 캡처합니다.

`verifiers` 레포지토리에는 시작을 돕기 위해 즉시 실행 가능한 [예시](https://github.com/willccbb/verifiers/tree/main/examples/grpo)들이 포함되어 있습니다.

다음 RL 트레이닝 파이프라인 예시는 로컬 추론 서버를 실행하고 GSM8K 데이터셋을 사용하여 모델을 트레이닝합니다. 모델은 수학 문제에 대한 답을 내놓고, 트레이닝 루프는 출력을 채점하고 그에 따라 모델을 업데이트합니다. W&B는 손실(loss), 보상(reward), 정확도와 같은 트레이닝 메트릭을 로그하며, Weave는 입력, 출력, 추론 과정 및 채점 결과를 캡처합니다.

이 파이프라인을 사용하려면:

1. 소스에서 프레임워크를 설치합니다. 다음 코맨드는 GitHub에서 Verifiers 라이브러리와 필요한 종속성을 설치합니다.

```bash
git clone https://github.com/willccbb/verifiers
cd verifiers
uv sync --all-extras && uv pip install flash-attn --no-build-isolation
```

2. 기성(off-the-shelf) 환경을 설치합니다. 다음 코맨드는 사전 설정된 GSM8K 트레이닝 환경을 설치합니다.

```bash
vf-install gsm8k --from-repo
```

3. 모델을 트레이닝합니다. 다음 코맨드는 각각 추론 서버와 트레이닝 루프를 시작합니다. 이 예시 워크플로우는 기본적으로 `report_to=wandb`로 설정되어 있으므로 `wandb.init`을 별도로 호출할 필요가 없습니다. W&B에 메트릭을 로그하기 위해 이 머신을 인증하라는 안내가 표시됩니다.


```bash
# 추론 서버 실행
CUDA_VISIBLE_DEVICES=0 vf-vllm --model willcb/Qwen3-0.6B --enforce-eager --disable-log-requests

# 트레이닝 루프 실행
CUDA_VISIBLE_DEVICES=1 accelerate launch --num-processes 1 --config-file configs/zero3.yaml examples/grpo/train_gsm8k.py
```

<Note>
이 예시는 2xH100 환경에서 테스트를 성공적으로 마쳤으며, 안정성을 높이기 위해 다음과 같은 환경 변수를 설정했습니다.

```bash
# 시작 전 두 쉘(서버 및 트레이너) 모두에서 설정
export NCCL_CUMEM_ENABLE=0
export NCCL_CUMEM_HOST_ENABLE=0
```

이 변수들은 디바이스 메모리 할당을 위한 CUDA 통합 메모리(CuMem)를 비활성화합니다.
</Note>

트레이닝이 시작되면 UI에서 run 중에 로그된 [trace를 확인](/weave/guides/tools/weave-in-workspaces)할 수 있습니다.

Trace는 `Environment.a_generate` 및 `Rubric.score_rollouts` 메소드에 대한 `logprobs`를 제외합니다. 이는 페이로드 크기를 작게 유지하면서 트레이닝을 위한 원본 데이터는 그대로 보존하기 위함입니다.

## 참고 항목

Verifiers는 W&B Models와 뛰어난 인테그레이션을 제공합니다. 자세한 내용은 [Monitoring](https://verifiers.readthedocs.io/en/latest/training.html#monitoring)을 참조하세요.