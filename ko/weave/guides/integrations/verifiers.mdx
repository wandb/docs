---
title: Verifiers
description: "Weave를 사용해 Verifiers RL 환경과 LLM 에이전트 트레이닝을 추적·디버깅하여, 여러 라운드의 대화, 평가 롤아웃, 모델 성능 메트릭을 캡처하고 강화 학습 워크플로에 대한 종합적인 관측 가능성을 확보합니다."
---

[Verifiers](https://github.com/willccbb/verifiers)는 강화 학습(Reinforcement Learning, RL) 환경을 만들고 LLM 에이전트를 트레이닝하기 위한 모듈형 컴포넌트 라이브러리입니다. Verifiers로 구축한 환경은 LLM 평가, 합성 데이터 파이프라인, OpenAI 호환 엔드포인트용 에이전트 하네스, 그리고 RL 트레이닝에 사용할 수 있습니다.

트레이닝 메트릭을 기록하기 위해 W&amp;B를 사용하는 것과 함께, Verifiers RL 워크플로에 Weave를 통합하면 모델이 트레이닝 중에 어떻게 동작하는지 관측할 수 있습니다. Weave는 각 단계의 입력, 출력, 타임스탬프를 기록하므로, 매 단계에서 데이터가 어떻게 변환되는지 살펴보고, 복잡한 다중 라운드 대화를 디버깅하며, 트레이닝 결과를 최적화할 수 있습니다.

또한 Weave와 Verifiers를 함께 사용해 평가를 수행할 수도 있습니다.

이 가이드에서는 Verifiers, W&amp;B, Weave를 설치하는 방법을 설명하고, Verifiers를 Weave와 W&amp;B와 함께 사용하는 두 가지 예제를 제공합니다.

![verifiers wandb run 페이지](/images/weave/verifiers.gif)

<div id="getting-started">
  ## 시작하기
</div>

Verifiers를 Weave와 통합하려면, 먼저 `uv`를 사용해 Verifiers 라이브러리를 설치하세요([라이브러리 작성자들이 권장하는 방법](https://github.com/willccbb/verifiers?tab=readme-ov-file#setup)). 다음 명령어 중 하나로 라이브러리를 설치하세요:

```bash
# 로컬 개발 및 API 기반 모델을 위한 핵심 라이브러리 설치
uv add verifiers

# PyTorch 및 GPU 지원을 포함한 모든 선택적 의존성이 포함된 전체 버전 라이브러리 설치
uv add 'verifiers[all]' && uv pip install flash-attn --no-build-isolation

# 아직 출시되지 않은 최신 기능 및 수정 사항을 포함하여 GitHub에서 직접 최신 버전 라이브러리 설치
uv add verifiers @ git+https://github.com/willccbb/verifiers.git
```

그런 다음 Weave와 W&amp;B를 설치합니다:

```bash
uv pip install weave wandb
```

Weave는 기본적으로 이 라이브러리에 대해 [암시적 패칭](/ko/weave/guides/integrations#automatic-implicit-patching)을 활성화합니다. 이를 통해 패치 함수를 명시적으로 호출하지 않고도 Verifiers와 함께 Weave를 사용할 수 있습니다.

<div id="trace-rollouts-and-evaluate">
  ### 롤아웃 추적 및 평가하기
</div>

필요한 라이브러리를 설치했다면 이제 Weave와 Verifiers를 함께 사용해 호출을 추적하고 평가를 수행할 수 있습니다.

다음 예제 스크립트는 Verifiers로 평가를 실행하고 결과를 Weave에 로깅하는 방법을 보여줍니다. 이 스크립트는 [GSM8K 데이터셋](https://huggingface.co/datasets/openai/gsm8k)을 사용해 LLM의 수학 문제 풀이 능력을 테스트합니다. GPT-4에게 두 개의 수학 문제를 풀도록 요청하고, 각 응답에서 숫자 값을 추출한 다음 Verifiers를 평가 프레임워크로 사용해 답안을 채점합니다.

예제를 실행하고 Weave에서 결과를 확인하세요:

```python lines
import os
from openai import OpenAI
import verifiers as vf
import weave

os.environ["OPENAI_API_KEY"] = "<YOUR-OPENAI-API-KEY>"

# Weave 초기화
weave.init("verifiers_demo")

# 최소 단일 턴 환경
dataset = vf.load_example_dataset("gsm8k", split="train").select(range(2))
parser = vf.ThinkParser()

def correct_answer(parser, completion, answer):
    parsed = parser.parse_answer(completion) or ""
    return 1.0 if parsed.strip() == answer.strip() else 0.0

rubric = vf.Rubric(funcs=[correct_answer, parser.get_format_reward_func()], weights=[1.0, 0.2])

env = vf.SingleTurnEnv(
    dataset=dataset,
    system_prompt="Think step-by-step, then answer.",
    parser=parser,
    rubric=rubric,
)

client = OpenAI()
results = env.evaluate(
    client, "gpt-4.1-mini", num_examples=2, rollouts_per_example=2, max_concurrent=8
)
```

<div id="fine-tune-a-model-with-experiment-tracking-and-tracing">
  ### 실험 추적과 트레이싱으로 모델 파인튜닝하기
</div>

Weave는 트레이닝 중 모델이 어떤 성능을 내고 있는지에 대한 인사이트를 제공하여 RL 파인튜닝 워크플로에서 강력한 도구가 될 수 있습니다. W&amp;B와 함께 사용하면 포괄적인 관측이 가능합니다. W&amp;B는 트레이닝 메트릭과 성능 차트를 추적하고, Weave는 트레이닝 과정에서 각 상호작용에 대한 상세한 트레이스를 캡처합니다.

`verifiers` 리포지토리에는 바로 실행해 볼 수 있는 [예제](https://github.com/willccbb/verifiers/tree/main/examples/grpo)가 포함되어 있어 시작하는 데 도움이 됩니다.

다음 예제 RL 트레이닝 파이프라인은 로컬 추론 서버를 실행하고 GSM8K 데이터셋을 사용해 모델을 트레이닝합니다. 모델은 수학 문제에 대한 답을 생성하고, 트레이닝 루프는 출력에 점수를 매긴 뒤 그에 따라 모델을 업데이트합니다. W&amp;B는 loss, reward, accuracy와 같은 트레이닝 메트릭을 로깅하고, Weave는 입력, 출력, 추론 과정과 점수를 캡처합니다.

이 파이프라인을 사용하려면:

1. 소스에서 프레임워크를 설치합니다. 다음 명령은 GitHub에서 Verifiers 라이브러리와 필요한 의존성을 설치합니다:

```bash
git clone https://github.com/willccbb/verifiers
cd verifiers
uv sync --all-extras && uv pip install flash-attn --no-build-isolation
```

2. 기성 환경을 설치합니다. 다음 명령은 사전 구성된 GSM8K 트레이닝 환경을 설치합니다.

```bash
vf-install gsm8k --from-repo
```

3. 모델을 트레이닝합니다. 다음 명령은 각각 추론 서버와 트레이닝 루프를 실행합니다. 이 예시 워크플로는 기본적으로 `report_to=wandb`로 설정되어 있으므로 별도로 `wandb.init`을 호출할 필요가 없습니다. 이 머신이 W&amp;B에 메트릭을 기록할 수 있도록 인증하라는 메시지가 표시됩니다.

```bash
# 추론 서버 실행
CUDA_VISIBLE_DEVICES=0 vf-vllm --model willcb/Qwen3-0.6B --enforce-eager --disable-log-requests

# 트레이닝 루프 실행
CUDA_VISIBLE_DEVICES=1 accelerate launch --num-processes 1 --config-file configs/zero3.yaml examples/grpo/train_gsm8k.py
```

<Note>
  이 예제는 2xH100 환경에서 성공적으로 테스트되었으며, 안정성을 높이기 위해 다음 환경 변수를 설정했습니다:

  ```bash
  # 실행하기 전에 두 셸(서버와 트레이너) 모두에서 실행
  export NCCL_CUMEM_ENABLE=0
  export NCCL_CUMEM_HOST_ENABLE=0
  ```

  이 변수들은 디바이스 메모리 할당에 대해 CUDA Unified Memory(CuMem)를 비활성화합니다.
</Note>

트레이닝이 시작되면, run 동안 기록된 트레이스를 UI에서 [확인할 수 있습니다](/ko/weave/guides/tools/weave-in-workspaces).

트레이스는 `Environment.a_generate` 및 `Rubric.score_rollouts` 메서드에 대해서는 `logprobs`를 기록하지 않습니다. 이렇게 하면 페이로드 크기를 줄이면서, 트레이닝을 위해 원본은 그대로 유지할 수 있습니다.

<div id="see-also">
  ## 함께 보기
</div>

Verifiers는 W&amp;B Models와 일급 인테그레이션을 제공합니다. 자세한 내용은 [Monitoring](https://verifiers.readthedocs.io/en/latest/training.html#monitoring)을 참고하세요.