---
title: "Cerebras"
description: "Weave를 사용해 Cerebras Cloud SDK로 수행되는 LLM 호출을 추적하고 로깅합니다"
---

Weave는 [Cerebras Cloud SDK](https://inference-docs.cerebras.ai/introduction)를 통해 수행되는 LLM 호출을 자동으로 추적하고 로깅합니다.

<div id="traces">
  ## 트레이스
</div>

LLM 호출 추적은 디버깅과 성능 모니터링에 매우 중요합니다. Weave는 Cerebras Cloud SDK용 트레이스를 자동으로 캡처하여 이를 도와줍니다.

다음은 Weave를 Cerebras와 함께 사용하는 예입니다:

```python lines
import os
import weave
from cerebras.cloud.sdk import Cerebras

# weave 프로젝트 초기화
weave.init("cerebras_speedster")

# 평소와 같이 Cerebras SDK 사용
api_key = os.environ["CEREBRAS_API_KEY"]
model = "llama3.1-8b"  # Cerebras 모델

client = Cerebras(api_key=api_key)

response = client.chat.completions.create(
    model=model,
    messages=[{"role": "user", "content": "What's the fastest land animal?"}],
)

print(response.choices[0].message.content)
```

Weave는 이제 Cerebras SDK를 통해 이루어지는 모든 LLM 호출을 추적하고 기록합니다. Weave 웹 인터페이스에서 토큰 사용량, 응답 시간 등의 세부 정보를 포함한 트레이스를 확인할 수 있습니다.

[![cerebras\_calls.png](/weave/guides/integrations/imgs/cerebras_calls.png)](https://wandb.ai/capecape/cerebras_speedster/weave/traces)

<div id="wrapping-with-your-own-ops">
  ## 사용자 정의 op으로 래핑하기
</div>

Weave ops는 실험의 재현성과 추적 가능성을 강화하는 강력한 방법을 제공합니다. 코드를 자동으로 버저닝하고 입력과 출력을 캡처합니다. 다음은 Cerebras SDK에서 Weave ops를 활용하는 방법의 예시입니다:

```python lines
import os
import weave
from cerebras.cloud.sdk import Cerebras

# weave 프로젝트 초기화
weave.init("cerebras_speedster")

client = Cerebras(api_key=os.environ["CEREBRAS_API_KEY"])

# Weave가 이 함수의 입력, 출력 및 코드를 추적합니다
@weave.op
def animal_speedster(animal: str, model: str) -> str:
    "동물이 얼마나 빨리 달릴 수 있는지 알아보기"
    
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": f"How fast can a {animal} run?"}],
    )
    return response.choices[0].message.content

animal_speedster("cheetah", "llama3.1-8b")
animal_speedster("ostrich", "llama3.1-8b")
animal_speedster("human", "llama3.1-8b")
```

<div id="create-a-model-for-easier-experimentation">
  ## 더 쉽게 실험하기 위한 `Model` 생성
</div>

Weave의 [Model](/ko/weave/guides/core-types/models) 클래스는 앱의 다양한 버전을 체계적으로 관리하고 서로 비교하는 데 도움이 됩니다. 이는 특히 Cerebras 모델을 실험할 때 유용합니다. 예시는 다음과 같습니다:

```python lines
import os
import weave
from cerebras.cloud.sdk import Cerebras

# weave 프로젝트 초기화
weave.init("cerebras_speedster")

client = Cerebras(api_key=os.environ["CEREBRAS_API_KEY"])

class AnimalSpeedModel(weave.Model):
    model: str
    temperature: float

    @weave.op
    def predict(self, animal: str) -> str:
        "동물의 최고 속도를 예측합니다"        

        response = client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": f"What's the top speed of a {animal}?"}],
            temperature=self.temperature
        )
        return response.choices[0].message.content

speed_model = AnimalSpeedModel(
    model="llama3.1-8b",
    temperature=0.7
)
result = speed_model.predict(animal="cheetah")
print(result)
```

이 구성을 통해 다양한 모델과 파라미터를 손쉽게 실험하면서, Cerebras로 구동되는 추론도 모두 추적할 수 있습니다!

[![cerebras\_model.png](/weave/guides/integrations/imgs/cerebras_model.png)](https://wandb.ai/capecape/cerebras_speedster/weave/traces)
