---
title: LlamaIndex
description: "Weaveë¥¼ ì‚¬ìš©í•´ LlamaIndex ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ëª¨ë“  LLM í˜¸ì¶œ, RAG íŒŒì´í”„ë¼ì¸, ì—ì´ì „íŠ¸ ë‹¨ê³„, ê·¸ë¦¬ê³  í‰ê°€ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì í•˜ê³  ë””ë²„ê¹…í•˜ì—¬ ë°ì´í„°ì™€ ì—°ê²°ëœ AI ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•œ ì¢…í•©ì ì¸ ê°€ì‹œì„±ì„ ì œê³µí•©ë‹ˆë‹¤."
---

WeaveëŠ” [LlamaIndex Python ë¼ì´ë¸ŒëŸ¬ë¦¬](https://github.com/run-llama/llama_index)ë¥¼ í†µí•´ ì´ë£¨ì–´ì§€ëŠ” ëª¨ë“  í˜¸ì¶œì˜ ì¶”ì ê³¼ ë¡œê¹…ì„ ê°„ì†Œí™”í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

LLMì„ ì‚¬ìš©í•  ë•Œ ë””ë²„ê¹…ì€ í”¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ í˜¸ì¶œì´ ì‹¤íŒ¨í•˜ê±°ë‚˜, ì¶œë ¥ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆê±°ë‚˜, ì¤‘ì²©ëœ ëª¨ë¸ í˜¸ì¶œì´ í˜¼ë€ì„ ì•¼ê¸°í•˜ëŠ” ê²½ìš° ë¬¸ì œì˜ ì›ì¸ì„ ì •í™•íˆ ì°¾ëŠ” ê²ƒì€ ì‰½ì§€ ì•ŠìŠµë‹ˆë‹¤. [LlamaIndex](https://docs.llamaindex.ai/en/stable/) ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì—¬ëŸ¬ ë‹¨ê³„ì™€ ë‹¤ìˆ˜ì˜ LLM í˜¸ì¶œë¡œ êµ¬ì„±ë˜ëŠ” ê²½ìš°ê°€ ë§ê¸° ë•Œë¬¸ì—, ì²´ì¸ê³¼ ì—ì´ì „íŠ¸ì˜ ë‚´ë¶€ ë™ì‘ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.

WeaveëŠ” LlamaIndex ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ íŠ¸ë ˆì´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ìº¡ì²˜í•˜ì—¬ ì´ ê³¼ì •ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆìœ¼ë©°, LLM ì›Œí¬í”Œë¡œë¥¼ ë””ë²„ê¹…í•˜ê³  ìµœì í™”í•˜ê¸°ê°€ ë” ì‰¬ì›Œì§‘ë‹ˆë‹¤. ë˜í•œ WeaveëŠ” í‰ê°€ ì›Œí¬í”Œë¡œì—ë„ ë„ì›€ì„ ì¤ë‹ˆë‹¤.

<div id="getting-started">
  ## ì‹œì‘í•˜ê¸°
</div>

ì‹œì‘í•˜ë ¤ë©´ ìŠ¤í¬ë¦½íŠ¸ì˜ ë§¨ ì²˜ìŒì— `weave.init()`ë§Œ í˜¸ì¶œí•˜ë©´ ë©ë‹ˆë‹¤. `weave.init()`ì— ì „ë‹¬í•˜ëŠ” ì¸ìˆ˜ëŠ” íŠ¸ë ˆì´ìŠ¤ë¥¼ ì •ë¦¬í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” í”„ë¡œì íŠ¸ ì´ë¦„ì…ë‹ˆë‹¤.

```python lines {5}
import weave
from llama_index.core.chat_engine import SimpleChatEngine

# í”„ë¡œì íŠ¸ ì´ë¦„ìœ¼ë¡œ Weave ì´ˆê¸°í™”
weave.init("llamaindex_demo")

chat_engine = SimpleChatEngine.from_defaults()
response = chat_engine.chat(
    "Say something profound and romantic about fourth of July"
)
print(response)
```

ìœ„ ì˜ˆì‹œì—ì„œëŠ” ë‚´ë¶€ì ìœ¼ë¡œ OpenAI í˜¸ì¶œì„ ìˆ˜í–‰í•˜ëŠ” ê°„ë‹¨í•œ LlamaIndex ì±— ì—”ì§„ì„ ìƒì„±í•©ë‹ˆë‹¤. ì•„ë˜ íŠ¸ë ˆì´ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”:

[![simple\_llamaindex.png](/weave/guides/integrations/imgs/simple_llamaindex.png)](https://wandb.ai/wandbot/test-llamaindex-weave/weave/calls/b6b5d898-2df8-4e14-b553-66ce84661e74)

<div id="tracing">
  ## íŠ¸ë ˆì´ì‹±
</div>

LlamaIndexëŠ” ë°ì´í„°ë¥¼ LLMê³¼ ì‰½ê²Œ ì—°ê²°í•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ì˜ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ RAG ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì„ë² ë”© ë‹¨ê³„, ê²€ìƒ‰ ë‹¨ê³„, ê·¸ë¦¬ê³  ì‘ë‹µ í•©ì„± ë‹¨ê³„ë¥¼ ê±°ì¹©ë‹ˆë‹¤. ë³µì¡ì„±ì´ ì¦ê°€í• ìˆ˜ë¡ ê°œë°œ ë° í”„ë¡œë•ì…˜ í™˜ê²½ ëª¨ë‘ì—ì„œ ê° ë‹¨ê³„ì˜ íŠ¸ë ˆì´ìŠ¤ë¥¼ ì¤‘ì•™ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•´ì§‘ë‹ˆë‹¤.

ì´ëŸ¬í•œ íŠ¸ë ˆì´ìŠ¤ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë””ë²„ê¹…í•˜ê³  ê°œì„ í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤. WeaveëŠ” LlamaIndex ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ìˆ˜í–‰ë˜ëŠ” ëª¨ë“  í˜¸ì¶œ(í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿, LLM í˜¸ì¶œ, ë„êµ¬, ì—ì´ì „íŠ¸ ë‹¨ê³„ í¬í•¨)ì„ ìë™ìœ¼ë¡œ ì¶”ì í•©ë‹ˆë‹¤. Weave ì›¹ ì¸í„°í˜ì´ìŠ¤ì—ì„œ ì´ íŠ¸ë ˆì´ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì•„ë˜ëŠ” LlamaIndexì˜ [Starter Tutorial (OpenAI)](https://docs.llamaindex.ai/en/stable/getting_started/starter_example/)ì— ë‚˜ì˜¤ëŠ” ê°„ë‹¨í•œ RAG íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œì…ë‹ˆë‹¤:

```python lines {5}
import weave
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader

# í”„ë¡œì íŠ¸ ì´ë¦„ìœ¼ë¡œ Weaveë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤
weave.init("llamaindex_demo")

# `data` ë””ë ‰í† ë¦¬ì— `.txt` íŒŒì¼ì´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤
documents = SimpleDirectoryReader("data").load_data()
index = VectorStoreIndex.from_documents(documents)

query_engine = index.as_query_engine()
response = query_engine.query("What did the author do growing up?")
print(response)
```

íŠ¸ë ˆì´ìŠ¤ íƒ€ì„ë¼ì¸ì€ &quot;ì´ë²¤íŠ¸&quot;ë¥¼ ê¸°ë¡í•  ë¿ë§Œ ì•„ë‹ˆë¼, ê°€ëŠ¥í•œ ê²½ìš° ì‹¤í–‰ ì‹œê°„, ë¹„ìš©, í† í° ìˆ˜ê¹Œì§€ í•¨ê»˜ ìº¡ì²˜í•©ë‹ˆë‹¤. íŠ¸ë ˆì´ìŠ¤ë¥¼ ë“œë¦´ë‹¤ìš´í•˜ì—¬ ê° ë‹¨ê³„ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ í™•ì¸í•˜ì„¸ìš”.

[![llamaindex\_rag.png](/weave/guides/integrations/imgs/llamaindex_rag.png)](https://wandb.ai/wandbot/test-llamaindex-weave/weave/calls?filter=%7B%22traceRootsOnly%22%3Atrue%7D\&peekPath=%2Fwandbot%2Ftest-llamaindex-weave%2Fcalls%2F6ac53407-1bb7-4c38-b5a3-c302bd877a11%3Ftracetree%3D1)

<div id="one-click-observability">
  ## ì›í´ë¦­ observability ğŸ”­
</div>

LlamaIndexëŠ” í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì›ì¹™ì— ê¸°ë°˜í•œ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ [ì›í´ë¦­ observability ğŸ”­](https://docs.llamaindex.ai/en/stable/module_guides/observability/)ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ì´ ì¸í…Œê·¸ë ˆì´ì…˜ì€ LlamaIndexì˜ ì´ ê¸°ëŠ¥ì„ í™œìš©í•´ [`WeaveCallbackHandler()`](https://github.com/wandb/weave/blob/master/weave/integrations/llamaindex/llamaindex.py)ë¥¼ `llama_index.core.global_handler`ë¡œ ìë™ ì„¤ì •í•©ë‹ˆë‹¤. ë”°ë¼ì„œ LlamaIndexì™€ Weaveë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, Weave runë§Œ ì´ˆê¸°í™”í•˜ë©´ ë©ë‹ˆë‹¤: `weave.init(<name-of-project>)`

<div id="create-a-model-for-easier-experimentation">
  ## ë” ì‰¬ìš´ ì‹¤í—˜ì„ ìœ„í•œ `Model` ìƒì„±
</div>

ë‹¤ì–‘í•œ ì‚¬ìš© ì‚¬ë¡€ì— ë§ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ LLMì„ êµ¬ì„±í•˜ê³  í‰ê°€í•˜ëŠ” ì‘ì—…ì€ í”„ë¡¬í”„íŠ¸, ëª¨ë¸ ì„¤ì •, ì¶”ë¡  íŒŒë¼ë¯¸í„° ë“± ì—¬ëŸ¬ êµ¬ì„± ìš”ì†Œê°€ ì–½í˜€ ìˆì–´ ì–´ë µìŠµë‹ˆë‹¤. [`weave.Model`](/ko/weave/guides/core-types/models)ì„ ì‚¬ìš©í•˜ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë‚˜ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ê³¼ ê°™ì€ ì‹¤í—˜ ê´€ë ¨ ì„¸ë¶€ ì •ë³´ë¥¼ ìº¡ì²˜í•˜ê³  ì •ë¦¬í•˜ì—¬, ì„œë¡œ ë‹¤ë¥¸ ë°˜ë³µ ë²„ì „ì„ ë” ì‰½ê²Œ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‹¤ìŒ ì˜ˆì‹œëŠ” [weave/data](https://github.com/wandb/weave/tree/master/data) í´ë”ì— ìˆëŠ” ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ `WeaveModel` ì•ˆì— LlamaIndex ì¿¼ë¦¬ ì—”ì§„ì„ ë¹Œë“œí•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤:

```python lines {16,52,61}
import weave

from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
from llama_index.core.node_parser import SentenceSplitter
from llama_index.llms.openai import OpenAI
from llama_index.core import PromptTemplate


PROMPT_TEMPLATE = """
You are given with relevant information about Paul Graham. Answer the user query only based on the information provided. Don't make up stuff.

User Query: {query_str}
Context: {context_str}
Answer:
"""

class SimpleRAGPipeline(weave.Model):
    chat_llm: str = "gpt-4"
    temperature: float = 0.1
    similarity_top_k: int = 2
    chunk_size: int = 256
    chunk_overlap: int = 20
    prompt_template: str = PROMPT_TEMPLATE

    def get_llm(self):
        return OpenAI(temperature=self.temperature, model=self.chat_llm)

    def get_template(self):
        return PromptTemplate(self.prompt_template)

    def load_documents_and_chunk(self, data):
        documents = SimpleDirectoryReader(data).load_data()
        splitter = SentenceSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
        )
        nodes = splitter.get_nodes_from_documents(documents)
        return nodes

    def get_query_engine(self, data):
        nodes = self.load_documents_and_chunk(data)
        index = VectorStoreIndex(nodes)

        llm = self.get_llm()
        prompt_template = self.get_template()

        return index.as_query_engine(
            similarity_top_k=self.similarity_top_k,
            llm=llm,
            text_qa_template=prompt_template,
        )

    @weave.op()
    def predict(self, query: str):
        query_engine = self.get_query_engine(
            # ì´ ë°ì´í„°ëŠ” weave ì €ì¥ì†Œì˜ data/paul_graham ê²½ë¡œì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
            "data/paul_graham",
        )
        response = query_engine.query(query)
        return {"response": response.response}

weave.init("test-llamaindex-weave")

rag_pipeline = SimpleRAGPipeline()
response = rag_pipeline.predict("What did the author do growing up?")
print(response)
```

`weave.Model`ì—ì„œ ìƒì†í•œ ì´ `SimpleRAGPipeline` í´ë˜ìŠ¤ëŠ” ì´ RAG íŒŒì´í”„ë¼ì¸ì˜ í•µì‹¬ íŒŒë¼ë¯¸í„°ë“¤ì„ í•œë° ëª¨ì•„ ê´€ë¦¬í•©ë‹ˆë‹¤. `query` ë©”ì„œë“œì— `weave.op()` ë°ì½”ë ˆì´í„°ë¥¼ ì ìš©í•˜ë©´ íŠ¸ë ˆì´ì‹±ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

[![llamaindex\_model.png](/weave/guides/integrations/imgs/llamaindex_model.png)](https://wandb.ai/wandbot/test-llamaindex-weave/weave/calls?filter=%7B%22traceRootsOnly%22%3Atrue%7D\&peekPath=%2Fwandbot%2Ftest-llamaindex-weave%2Fcalls%2Fa82afbf4-29a5-43cd-8c51-603350abeafd%3Ftracetree%3D1)

<div id="doing-evaluation-with-weaveevaluation">
  ## `weave.Evaluation`ìœ¼ë¡œ í‰ê°€ ìˆ˜í–‰í•˜ê¸°
</div>

í‰ê°€ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. [`weave.Evaluation`](/ko/weave/guides/core-types/evaluations) í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë©´ íŠ¹ì • ì‘ì—…ì´ë‚˜ ë°ì´í„°ì…‹ì—ì„œ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì˜ ë™ì‘í•˜ëŠ”ì§€ ê¸°ë¡í•  ìˆ˜ ìˆì–´, ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ê³¼ ì• í”Œë¦¬ì¼€ì´ì…˜ ì´í„°ë ˆì´ì…˜ì„ ë” ì‰½ê²Œ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì˜ˆì œëŠ” ìš°ë¦¬ê°€ ìƒì„±í•œ ëª¨ë¸ì„ ì–´ë–»ê²Œ í‰ê°€í•˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤:

```python lines {25,32,36}
import asyncio
from llama_index.core.evaluation import CorrectnessEvaluator

eval_examples = [
    {
        "id": "0",
        "query": "What programming language did Paul Graham learn to teach himself AI when he was in college?",
        "ground_truth": "Paul Graham learned Lisp to teach himself AI when he was in college.",
    },
    {
        "id": "1",
        "query": "What was the name of the startup Paul Graham co-founded that was eventually acquired by Yahoo?",
        "ground_truth": "The startup Paul Graham co-founded that was eventually acquired by Yahoo was called Viaweb.",
    },
    {
        "id": "2",
        "query": "What is the capital city of France?",
        "ground_truth": "I cannot answer this question because no information was provided in the text.",
    },
]

llm_judge = OpenAI(model="gpt-4", temperature=0.0)
evaluator = CorrectnessEvaluator(llm=llm_judge)

@weave.op()
def correctness_evaluator(query: str, ground_truth: str, output: dict):
    result = evaluator.evaluate(
        query=query, reference=ground_truth, response=output["response"]
    )
    return {"correctness": float(result.score)}

evaluation = weave.Evaluation(dataset=eval_examples, scorers=[correctness_evaluator])

rag_pipeline = SimpleRAGPipeline()

asyncio.run(evaluation.evaluate(rag_pipeline))
```

ì´ í‰ê°€ëŠ” ì´ì „ ì„¹ì…˜ì˜ ì˜ˆì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. `weave.Evaluation`ì„ ì‚¬ìš©í•´ í‰ê°€í•˜ë ¤ë©´ í‰ê°€ìš© ë°ì´í„°ì…‹, ìŠ¤ì½”ì–´ëŸ¬ í•¨ìˆ˜, ê·¸ë¦¬ê³  `weave.Model`ì´ í•„ìš”í•©ë‹ˆë‹¤. ì•„ë˜ëŠ” ì´ ì„¸ ê°€ì§€ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ì— ëŒ€í•œ ëª‡ ê°€ì§€ ìœ ì˜ ì‚¬í•­ì…ë‹ˆë‹¤:

* í‰ê°€ ìƒ˜í”Œ dictì˜ í‚¤ê°€ ìŠ¤ì½”ì–´ëŸ¬ í•¨ìˆ˜ì˜ ì¸ìì™€ `weave.Model`ì˜ `predict` ë©”ì„œë“œ ì¸ìì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
* `weave.Model`ì—ëŠ” `predict`, `infer`, `forward` ì¤‘ í•˜ë‚˜ì˜ ì´ë¦„ì„ ê°€ì§„ ë©”ì„œë“œê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ì´ ë©”ì„œë“œì—ëŠ” íŠ¸ë ˆì´ì‹±ì„ ìœ„í•´ `weave.op()` ë°ì½”ë ˆì´í„°ë¥¼ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
* ìŠ¤ì½”ì–´ëŸ¬ í•¨ìˆ˜ ì—­ì‹œ `weave.op()` ë°ì½”ë ˆì´í„°ë¥¼ ì ìš©í•´ì•¼ í•˜ë©°, `output`ì„ ì´ë¦„ ìˆëŠ” ì¸ìë¡œ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.

[![llamaindex\_evaluation.png](/weave/guides/integrations/imgs/llamaindex_evaluation.png)](https://wandb.ai/wandbot/llamaindex-weave/weave/calls?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fwandbot%2Fllamaindex-weave%2Fop%2FEvaluation.predict_and_score%3ANmwfShfFmgAhDGLXrF6Xn02T9MIAsCXBUcifCjyKpOM%22%5D%2C%22parentId%22%3A%2233491e66-b580-47fa-9d43-0cd6f1dc572a%22%7D\&peekPath=%2Fwandbot%2Fllamaindex-weave%2Fcalls%2F33491e66-b580-47fa-9d43-0cd6f1dc572a%3Ftracetree%3D1)

Weaveë¥¼ LlamaIndexì™€ ì¸í…Œê·¸ë ˆì´ì…˜í•˜ë©´ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì— ëŒ€í•œ í¬ê´„ì ì¸ ë¡œê¹…ê³¼ ëª¨ë‹ˆí„°ë§ì„ êµ¬ì„±í•  ìˆ˜ ìˆì–´, í‰ê°€ë¥¼ í†µí•´ ë””ë²„ê¹…ê³¼ ì„±ëŠ¥ ìµœì í™”ë¥¼ ë” ì‰½ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
