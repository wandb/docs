---
title: LlamaIndex
description: "Weaveë¥¼ ì‚¬ìš©í•´ LlamaIndex ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìë™ìœ¼ë¡œ íŠ¸ë ˆì´ì‹±í•˜ê³  ë””ë²„ê¹…í•˜ë©´ì„œ, ëª¨ë“  LLM í˜¸ì¶œ, RAG íŒŒì´í”„ë¼ì¸, ì—ì´ì „íŠ¸ ë‹¨ê³„, í‰ê°€ë¥¼ ìº¡ì²˜í•´ ë°ì´í„° ì—°ë™í˜• AI ì›Œí¬í”Œë¡œì˜ ê´€ì¸¡ ê°€ëŠ¥ì„±ì„ í¬ê´„ì ìœ¼ë¡œ í™•ë³´í•©ë‹ˆë‹¤."
---

WeaveëŠ” [LlamaIndex Python ë¼ì´ë¸ŒëŸ¬ë¦¬](https://github.com/run-llama/llama_index)ë¥¼ í†µí•´ ì´ë£¨ì–´ì§€ëŠ” ëª¨ë“  í˜¸ì¶œì˜ ì¶”ì  ë° ë¡œê¹…ì„ ë‹¨ìˆœí™”í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

LLMì„ ì‚¬ìš©í•  ë•Œ ë””ë²„ê¹…ì€ í”¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ í˜¸ì¶œì´ ì‹¤íŒ¨í•˜ê±°ë‚˜ ì¶œë ¥ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆê±°ë‚˜, ì¤‘ì²©ëœ ëª¨ë¸ í˜¸ì¶œì´ í˜¼ë€ì„ ì•¼ê¸°í•˜ëŠ” ë“± ë¬¸ì œë¥¼ ì •í™•íˆ ì°¾ì•„ë‚´ëŠ” ì¼ì€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. [LlamaIndex](https://docs.llamaindex.ai/en/stable/) ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ë³´í†µ ì—¬ëŸ¬ ë‹¨ê³„ì™€ ë‹¤ìˆ˜ì˜ LLM í˜¸ì¶œë¡œ êµ¬ì„±ë˜ê¸° ë•Œë¬¸ì—, ì²´ì¸ê³¼ ì—ì´ì „íŠ¸ì˜ ë‚´ë¶€ ë™ì‘ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.

WeaveëŠ” LlamaIndex ì• í”Œë¦¬ì¼€ì´ì…˜ì— ëŒ€í•œ íŠ¸ë ˆì´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ìº¡ì²˜í•˜ì—¬ ì´ ê³¼ì •ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆì–´, LLM ì›Œí¬í”Œë¡œë¥¼ ë” ì‰½ê²Œ ë””ë²„ê¹…í•˜ê³  ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. WeaveëŠ” í‰ê°€ ì›Œí¬í”Œë¡œì—ë„ ë„ì›€ì´ ë©ë‹ˆë‹¤.

<div id="getting-started">
  ## ì‹œì‘í•˜ê¸°
</div>

ì‹œì‘í•˜ë ¤ë©´ ìŠ¤í¬ë¦½íŠ¸ì˜ ë§¨ ì•ë¶€ë¶„ì—ì„œ `weave.init()`ì„ í˜¸ì¶œí•˜ë©´ ë©ë‹ˆë‹¤. `weave.init()`ì˜ ì¸ìˆ˜ëŠ” íŠ¸ë ˆì´ìŠ¤ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” í”„ë¡œì íŠ¸ ì´ë¦„ì…ë‹ˆë‹¤.

```python lines {5}
import weave
from llama_index.core.chat_engine import SimpleChatEngine

# í”„ë¡œì íŠ¸ ì´ë¦„ìœ¼ë¡œ Weave ì´ˆê¸°í™”
weave.init("llamaindex_demo")

chat_engine = SimpleChatEngine.from_defaults()
response = chat_engine.chat(
    "Say something profound and romantic about fourth of July"
)
print(response)
```

ìœ„ ì˜ˆì œì—ì„œëŠ” ë‚´ë¶€ì ìœ¼ë¡œ OpenAI í˜¸ì¶œì„ ìˆ˜í–‰í•˜ëŠ” ê°„ë‹¨í•œ LlamaIndex ì±„íŒ… ì—”ì§„ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•„ë˜ íŠ¸ë ˆì´ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”:

[![simple\_llamaindex.png](/weave/guides/integrations/imgs/simple_llamaindex.png)](https://wandb.ai/wandbot/test-llamaindex-weave/weave/calls/b6b5d898-2df8-4e14-b553-66ce84661e74)

<div id="tracing">
  ## íŠ¸ë ˆì´ì‹±
</div>

LlamaIndexëŠ” ë°ì´í„°ë¥¼ LLMê³¼ ì‰½ê²Œ ì—°ê²°í•  ìˆ˜ ìˆëŠ” ê²ƒìœ¼ë¡œ ì˜ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ RAG ì• í”Œë¦¬ì¼€ì´ì…˜ì—ëŠ” ì„ë² ë”© ë‹¨ê³„, ê²€ìƒ‰ ë‹¨ê³„, ì‘ë‹µ í•©ì„± ë‹¨ê³„ê°€ í¬í•¨ë©ë‹ˆë‹¤. ë³µì¡ì„±ì´ ì¦ê°€í•¨ì— ë”°ë¼ ê°œë°œ ë° ìš´ì˜ í™˜ê²½ ëª¨ë‘ì—ì„œ ê° ë‹¨ê³„ì˜ íŠ¸ë ˆì´ìŠ¤ë¥¼ ì¤‘ì•™ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•´ì§‘ë‹ˆë‹¤.

ì´ëŸ¬í•œ íŠ¸ë ˆì´ìŠ¤ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë””ë²„ê¹…í•˜ê³  ê°œì„ í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤. WeaveëŠ” LlamaIndex ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ì´ë£¨ì–´ì§€ëŠ” ëª¨ë“  í˜¸ì¶œì„ ìë™ìœ¼ë¡œ ì¶”ì í•˜ë©°, ì—¬ê¸°ì—ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿, LLM í˜¸ì¶œ, ë„êµ¬, ì—ì´ì „íŠ¸ ë‹¨ê³„ê°€ í¬í•¨ë©ë‹ˆë‹¤. Weave ì›¹ ì¸í„°í˜ì´ìŠ¤ì—ì„œ ì´ëŸ¬í•œ íŠ¸ë ˆì´ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì•„ë˜ëŠ” LlamaIndexì˜ [Starter Tutorial (OpenAI)](https://docs.llamaindex.ai/en/stable/getting_started/starter_example/)ì— ë‚˜ì˜¤ëŠ” ê°„ë‹¨í•œ RAG íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œì…ë‹ˆë‹¤:

```python lines {5}
import weave
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader

# í”„ë¡œì íŠ¸ ì´ë¦„ìœ¼ë¡œ Weave ì´ˆê¸°í™”
weave.init("llamaindex_demo")

# `data` ë””ë ‰í† ë¦¬ì— `.txt` íŒŒì¼ì´ ìˆë‹¤ê³  ê°€ì •
documents = SimpleDirectoryReader("data").load_data()
index = VectorStoreIndex.from_documents(documents)

query_engine = index.as_query_engine()
response = query_engine.query("What did the author do growing up?")
print(response)
```

íŠ¸ë ˆì´ìŠ¤ íƒ€ì„ë¼ì¸ì€ ë‹¨ìˆœíˆ &quot;ì´ë²¤íŠ¸&quot;ë§Œ ê¸°ë¡í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, í•´ë‹¹ë˜ëŠ” ê²½ìš° ì‹¤í–‰ ì‹œê°„, ë¹„ìš©, í† í° ìˆ˜ê¹Œì§€ í•¨ê»˜ ê¸°ë¡í•©ë‹ˆë‹¤. íŠ¸ë ˆì´ìŠ¤ë¥¼ ì„¸ë¶€ì ìœ¼ë¡œ íƒìƒ‰í•´ ê° ë‹¨ê³„ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ í™•ì¸í•˜ì„¸ìš”.

[![llamaindex\_rag.png](/weave/guides/integrations/imgs/llamaindex_rag.png)](https://wandb.ai/wandbot/test-llamaindex-weave/weave/calls?filter=%7B%22traceRootsOnly%22%3Atrue%7D\&peekPath=%2Fwandbot%2Ftest-llamaindex-weave%2Fcalls%2F6ac53407-1bb7-4c38-b5a3-c302bd877a11%3Ftracetree%3D1)

<div id="one-click-observability">
  ## ì›í´ë¦­ observability ğŸ”­
</div>

LlamaIndexëŠ” í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì›ì¹™ì— ê¸°ë°˜í•œ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ [ì›í´ë¦­ observability ğŸ”­](https://docs.llamaindex.ai/en/stable/module_guides/observability/) ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

ì´ë²ˆ í†µí•©ì—ì„œëŠ” LlamaIndexì˜ ì´ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ [`WeaveCallbackHandler()`](https://github.com/wandb/weave/blob/master/weave/integrations/llamaindex/llamaindex.py)ë¥¼ `llama_index.core.global_handler`ë¡œ ìë™ ì„¤ì •í•©ë‹ˆë‹¤. ë”°ë¼ì„œ LlamaIndexì™€ Weaveë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, ì‚¬ìš©ìê°€ í•´ì•¼ í•  ì¼ì€ Weave ì‹¤í–‰ì„ ì´ˆê¸°í™”í•˜ëŠ” ê²ƒë¿ì…ë‹ˆë‹¤: `weave.init(<name-of-project>)`

<div id="create-a-model-for-easier-experimentation">
  ## ë” ì‰¬ìš´ ì‹¤í—˜ì„ ìœ„í•œ `Model` ìƒì„±
</div>

ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ë‹¤ì–‘í•œ ì‚¬ìš© ì‚¬ë¡€ì— ë§ê²Œ LLMì„ êµ¬ì„±í•˜ê³  í‰ê°€í•˜ëŠ” ì¼ì€ í”„ë¡¬í”„íŠ¸, ëª¨ë¸ êµ¬ì„±, ì¶”ë¡  íŒŒë¼ë¯¸í„° ë“± ì—¬ëŸ¬ êµ¬ì„± ìš”ì†Œë¡œ ì¸í•´ ë³µì¡í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. [`weave.Model`](/ko/weave/guides/core-types/models)ì„ ì‚¬ìš©í•˜ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë‚˜ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ê³¼ ê°™ì€ ì‹¤í—˜ ì„¸ë¶€ ì •ë³´ë¥¼ ê¸°ë¡í•˜ê³  ì •ë¦¬í•  ìˆ˜ ìˆì–´, ì„œë¡œ ë‹¤ë¥¸ ë²„ì „ì„ ë” ì‰½ê²Œ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‹¤ìŒ ì˜ˆì œëŠ” [weave/data](https://github.com/wandb/weave/tree/master/data) í´ë”ì— ìˆëŠ” ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ `WeaveModel`ì—ì„œ LlamaIndex ì¿¼ë¦¬ ì—”ì§„ì„ êµ¬ì„±í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤:

```python lines {16,52,61}
import weave

from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
from llama_index.core.node_parser import SentenceSplitter
from llama_index.llms.openai import OpenAI
from llama_index.core import PromptTemplate


PROMPT_TEMPLATE = """
You are given with relevant information about Paul Graham. Answer the user query only based on the information provided. Don't make up stuff.

User Query: {query_str}
Context: {context_str}
Answer:
"""

class SimpleRAGPipeline(weave.Model):
    chat_llm: str = "gpt-4"
    temperature: float = 0.1
    similarity_top_k: int = 2
    chunk_size: int = 256
    chunk_overlap: int = 20
    prompt_template: str = PROMPT_TEMPLATE

    def get_llm(self):
        return OpenAI(temperature=self.temperature, model=self.chat_llm)

    def get_template(self):
        return PromptTemplate(self.prompt_template)

    def load_documents_and_chunk(self, data):
        documents = SimpleDirectoryReader(data).load_data()
        splitter = SentenceSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
        )
        nodes = splitter.get_nodes_from_documents(documents)
        return nodes

    def get_query_engine(self, data):
        nodes = self.load_documents_and_chunk(data)
        index = VectorStoreIndex(nodes)

        llm = self.get_llm()
        prompt_template = self.get_template()

        return index.as_query_engine(
            similarity_top_k=self.similarity_top_k,
            llm=llm,
            text_qa_template=prompt_template,
        )

    @weave.op()
    def predict(self, query: str):
        query_engine = self.get_query_engine(
            # ì´ ë°ì´í„°ëŠ” weave ì €ì¥ì†Œì˜ data/paul_graham ê²½ë¡œì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
            "data/paul_graham",
        )
        response = query_engine.query(query)
        return {"response": response.response}

weave.init("test-llamaindex-weave")

rag_pipeline = SimpleRAGPipeline()
response = rag_pipeline.predict("What did the author do growing up?")
print(response)
```

`weave.Model`ì„ ìƒì†ë°›ì€ ì´ `SimpleRAGPipeline` í´ë˜ìŠ¤ëŠ” ì´ RAG íŒŒì´í”„ë¼ì¸ì˜ ì£¼ìš” íŒŒë¼ë¯¸í„°ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤. `query` ë©”ì„œë“œì— `weave.op()`ë¥¼ ë°ì½”ë ˆì´í„°ë¡œ ì§€ì •í•˜ë©´ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

[![llamaindex\_model.png](/weave/guides/integrations/imgs/llamaindex_model.png)](https://wandb.ai/wandbot/test-llamaindex-weave/weave/calls?filter=%7B%22traceRootsOnly%22%3Atrue%7D\&peekPath=%2Fwandbot%2Ftest-llamaindex-weave%2Fcalls%2Fa82afbf4-29a5-43cd-8c51-603350abeafd%3Ftracetree%3D1)

<div id="doing-evaluation-with-weaveevaluation">
  ## `weave.Evaluation`ìœ¼ë¡œ Evaluation ìˆ˜í–‰í•˜ê¸°
</div>

Evaluationì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. [`weave.Evaluation`](/ko/weave/guides/core-types/evaluations) í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì´ íŠ¹ì • ì‘ì—…ì´ë‚˜ ë°ì´í„°ì…‹ì—ì„œ ì–¼ë§ˆë‚˜ ì˜ ë™ì‘í•˜ëŠ”ì§€ ì¸¡ì •í•˜ê³  ê¸°ë¡í•  ìˆ˜ ìˆì–´, ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ê³¼ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì—¬ëŸ¬ ë²„ì „ì„ ë” ì‰½ê²Œ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì˜ˆì‹œëŠ” ì•ì—ì„œ ë§Œë“  ëª¨ë¸ì— Evaluationì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ ì¤ë‹ˆë‹¤.

```python lines {25,32,36}
import asyncio
from llama_index.core.evaluation import CorrectnessEvaluator

eval_examples = [
    {
        "id": "0",
        "query": "What programming language did Paul Graham learn to teach himself AI when he was in college?",
        "ground_truth": "Paul Graham learned Lisp to teach himself AI when he was in college.",
    },
    {
        "id": "1",
        "query": "What was the name of the startup Paul Graham co-founded that was eventually acquired by Yahoo?",
        "ground_truth": "The startup Paul Graham co-founded that was eventually acquired by Yahoo was called Viaweb.",
    },
    {
        "id": "2",
        "query": "What is the capital city of France?",
        "ground_truth": "I cannot answer this question because no information was provided in the text.",
    },
]

llm_judge = OpenAI(model="gpt-4", temperature=0.0)
evaluator = CorrectnessEvaluator(llm=llm_judge)

@weave.op()
def correctness_evaluator(query: str, ground_truth: str, output: dict):
    result = evaluator.evaluate(
        query=query, reference=ground_truth, response=output["response"]
    )
    return {"correctness": float(result.score)}

evaluation = weave.Evaluation(dataset=eval_examples, scorers=[correctness_evaluator])

rag_pipeline = SimpleRAGPipeline()

asyncio.run(evaluation.evaluate(rag_pipeline))
```

ì´ë²ˆ í‰ê°€ëŠ” ì•ì„  ì„¹ì…˜ì˜ ì˜ˆì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. `weave.Evaluation`ì„ ì‚¬ìš©í•´ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ë ¤ë©´ í‰ê°€ ë°ì´í„°ì…‹, scorer í•¨ìˆ˜, ê·¸ë¦¬ê³  `weave.Model`ì´ í•„ìš”í•©ë‹ˆë‹¤. ì•„ë˜ëŠ” ì´ ì„¸ ê°€ì§€ í•µì‹¬ êµ¬ì„± ìš”ì†Œì— ëŒ€í•œ ëª‡ ê°€ì§€ ìœ ì˜ì‚¬í•­ì…ë‹ˆë‹¤:

* í‰ê°€ ìƒ˜í”Œ dictì˜ í‚¤ê°€ scorer í•¨ìˆ˜ì˜ ë§¤ê°œë³€ìˆ˜ì™€ `weave.Model`ì˜ `predict` ë©”ì„œë“œ ë§¤ê°œë³€ìˆ˜ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
* `weave.Model`ì—ëŠ” `predict` ë˜ëŠ” `infer` ë˜ëŠ” `forward`ë¼ëŠ” ì´ë¦„ì˜ ë©”ì„œë“œê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ì´ ë©”ì„œë“œì—ëŠ” ì¶”ì ì„ ìœ„í•´ `weave.op()` ë°ì½”ë ˆì´í„°ë¥¼ ì ìš©í•˜ì„¸ìš”.
* scorer í•¨ìˆ˜ëŠ” `weave.op()`ë¡œ ë°ì½”ë ˆì´íŠ¸ë˜ì–´ì•¼ í•˜ë©°, `output`ì´ë¼ëŠ” ì´ë¦„ì˜ í‚¤ì›Œë“œ ì¸ìë¥¼ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.

[![llamaindex\_evaluation.png](/weave/guides/integrations/imgs/llamaindex_evaluation.png)](https://wandb.ai/wandbot/llamaindex-weave/weave/calls?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fwandbot%2Fllamaindex-weave%2Fop%2FEvaluation.predict_and_score%3ANmwfShfFmgAhDGLXrF6Xn02T9MIAsCXBUcifCjyKpOM%22%5D%2C%22parentId%22%3A%2233491e66-b580-47fa-9d43-0cd6f1dc572a%22%7D\&peekPath=%2Fwandbot%2Fllamaindex-weave%2Fcalls%2F33491e66-b580-47fa-9d43-0cd6f1dc572a%3Ftracetree%3D1)

Weaveë¥¼ LlamaIndexì™€ í†µí•©í•˜ë©´ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì— ëŒ€í•´ í¬ê´„ì ì¸ ë¡œê¹…ê³¼ ëª¨ë‹ˆí„°ë§ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìœ¼ë©°, Evaluationì„ í™œìš©í•´ ë””ë²„ê¹…ê³¼ ì„±ëŠ¥ ìµœì í™”ë¥¼ ë” ì‰½ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
