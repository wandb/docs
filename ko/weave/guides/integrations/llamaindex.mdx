---
title: LlamaIndex
description: Weaveë¥¼ ì‚¬ìš©í•˜ì—¬ LlamaIndex ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìë™ìœ¼ë¡œ íŠ¸ë ˆì´ìŠ¤í•˜ê³  ë””ë²„ê¹…í•˜ì„¸ìš”. ëª¨ë“  LLM í˜¸ì¶œ, RAG íŒŒì´í”„ë¼ì¸,
  ì—ì´ì „íŠ¸ ë‹¨ê³„ ë° í‰ê°€ë¥¼ ìº¡ì²˜í•˜ì—¬ ë°ì´í„°ì™€ ì—°ê²°ëœ AI ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•œ í¬ê´„ì ì¸ ê°€ì‹œì„±(observability)ì„ ì œê³µí•©ë‹ˆë‹¤.
---

Weave ëŠ” [LlamaIndex Python ë¼ì´ë¸ŒëŸ¬ë¦¬](https://github.com/run-llama/llama_index)ë¥¼ í†µí•´ ì´ë£¨ì–´ì§€ëŠ” ëª¨ë“  í˜¸ì¶œì˜ ì¶”ì  ë° ë¡œê·¸ ê¸°ë¡ì„ ê°„ì†Œí™”í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

LLM ìœ¼ë¡œ ì‘ì—…í•  ë•Œ ë””ë²„ê¹…ì€ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ëª¨ë¸ í˜¸ì¶œì´ ì‹¤íŒ¨í•˜ê±°ë‚˜, ì¶œë ¥ì´ ì˜ëª»ëœ í˜•ì‹ìœ¼ë¡œ ë‚˜ì˜¤ê±°ë‚˜, ì¤‘ì²©ëœ ëª¨ë¸ í˜¸ì¶œì´ í˜¼ë€ì„ ì•¼ê¸°í•  ë•Œ ë¬¸ì œì˜ ì›ì¸ì„ ì •í™•íˆ ì§šì–´ë‚´ëŠ” ê²ƒì€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. [LlamaIndex](https://docs.llamaindex.ai/en/stable/) ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì¢…ì¢… ì—¬ëŸ¬ ë‹¨ê³„ì™€ LLM í˜¸ì¶œ ì¸ë³´ì¼€ì´ì…˜ìœ¼ë¡œ êµ¬ì„±ë˜ë¯€ë¡œ, ì²´ì¸ê³¼ ì—ì´ì „íŠ¸ì˜ ë‚´ë¶€ ì‘ë™ ë°©ì‹ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.

Weave ëŠ” LlamaIndex ì• í”Œë¦¬ì¼€ì´ì…˜ì— ëŒ€í•œ íŠ¸ë ˆì´ìŠ¤(trace)ë¥¼ ìë™ìœ¼ë¡œ ìº¡ì²˜í•˜ì—¬ ì´ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆìœ¼ë©°, LLM ì›Œí¬í”Œë¡œìš°ë¥¼ ë” ì‰½ê²Œ ë””ë²„ê¹…í•˜ê³  ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ Weave ëŠ” í‰ê°€ ì›Œí¬í”Œë¡œìš°ì—ë„ ë„ì›€ì„ ì¤ë‹ˆë‹¤.

## ì‹œì‘í•˜ê¸°

ì‹œì‘í•˜ë ¤ë©´ ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ ë¶€ë¶„ì—ì„œ `weave.init()`ì„ í˜¸ì¶œí•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤. `weave.init()`ì˜ ì¸ìˆ˜ëŠ” íŠ¸ë ˆì´ìŠ¤ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” í”„ë¡œì íŠ¸ ì´ë¦„ì…ë‹ˆë‹¤.

```python lines {5}
import weave
from llama_index.core.chat_engine import SimpleChatEngine

# í”„ë¡œì íŠ¸ ì´ë¦„ìœ¼ë¡œ Weave ì´ˆê¸°í™”
weave.init("llamaindex_demo")

chat_engine = SimpleChatEngine.from_defaults()
response = chat_engine.chat(
    "Say something profound and romantic about fourth of July"
)
print(response)
```

ìœ„ì˜ ì˜ˆì‹œì—ì„œëŠ” ë‚´ë¶€ì ìœ¼ë¡œ OpenAI í˜¸ì¶œì„ ìˆ˜í–‰í•˜ëŠ” ê°„ë‹¨í•œ LlamaIndex ì±„íŒ… ì—”ì§„ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ íŠ¸ë ˆì´ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”:

[![simple_llamaindex.png](/weave/guides/integrations/imgs/simple_llamaindex.png)](https://wandb.ai/wandbot/test-llamaindex-weave/weave/calls/b6b5d898-2df8-4e14-b553-66ce84661e74)

## íŠ¸ë ˆì´ì‹± (Tracing)

LlamaIndex ëŠ” ë°ì´í„°ì™€ LLM ì„ ì‰½ê²Œ ì—°ê²°í•´ ì£¼ëŠ” ê²ƒìœ¼ë¡œ ì˜ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ RAG ì• í”Œë¦¬ì¼€ì´ì…˜ì—ëŠ” ì„ë² ë”© ë‹¨ê³„, ë¦¬íŠ¸ë¦¬ë²Œ(retrieval) ë‹¨ê³„, ê·¸ë¦¬ê³  ì‘ë‹µ í•©ì„± ë‹¨ê³„ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë³µì¡ì„±ì´ ì¦ê°€í•¨ì— ë”°ë¼, ê°œë°œ ë° í”„ë¡œë•ì…˜ ë‹¨ê³„ ëª¨ë‘ì—ì„œ ê°œë³„ ë‹¨ê³„ì˜ íŠ¸ë ˆì´ìŠ¤ë¥¼ ì¤‘ì•™ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•´ì§‘ë‹ˆë‹¤.

ì´ëŸ¬í•œ íŠ¸ë ˆì´ìŠ¤ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë””ë²„ê¹…í•˜ê³  ê°œì„ í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤. Weave ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿, LLM í˜¸ì¶œ, íˆ´, ì—ì´ì „íŠ¸ ë‹¨ê³„ë¥¼ í¬í•¨í•˜ì—¬ LlamaIndex ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ì´ë£¨ì–´ì§€ëŠ” ëª¨ë“  í˜¸ì¶œì„ ìë™ìœ¼ë¡œ ì¶”ì í•©ë‹ˆë‹¤. Weave ì›¹ ì¸í„°í˜ì´ìŠ¤ì—ì„œ íŠ¸ë ˆì´ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‹¤ìŒì€ LlamaIndex ì˜ [ì‹œì‘ íŠœí† ë¦¬ì–¼ (OpenAI)](https://docs.llamaindex.ai/en/stable/getting_started/starter_example/)ì— ë‚˜ì˜¤ëŠ” ê°„ë‹¨í•œ RAG íŒŒì´í”„ë¼ì¸ì˜ ì˜ˆì‹œì…ë‹ˆë‹¤.

```python lines {5}
import weave
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader

# í”„ë¡œì íŠ¸ ì´ë¦„ìœ¼ë¡œ Weave ì´ˆê¸°í™”
weave.init("llamaindex_demo")

# `data` ë””ë ‰í† ë¦¬ì— `.txt` íŒŒì¼ì´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
documents = SimpleDirectoryReader("data").load_data()
index = VectorStoreIndex.from_documents(documents)

query_engine = index.as_query_engine()
response = query_engine.query("What did the author do growing up?")
print(response)
```

íŠ¸ë ˆì´ìŠ¤ íƒ€ì„ë¼ì¸ì€ ë‹¨ìˆœíˆ "ì´ë²¤íŠ¸"ë§Œ ìº¡ì²˜í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì‹¤í–‰ ì‹œê°„, ë¹„ìš© ë° í•´ë‹¹ë˜ëŠ” ê²½ìš° í† í° ìˆ˜ê¹Œì§€ ìº¡ì²˜í•©ë‹ˆë‹¤. íŠ¸ë ˆì´ìŠ¤ë¥¼ ìƒì„¸íˆ ì¡°ì‚¬í•˜ì—¬ ê° ë‹¨ê³„ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ í™•ì¸í•´ ë³´ì„¸ìš”.

[![llamaindex_rag.png](/weave/guides/integrations/imgs/llamaindex_rag.png)](https://wandb.ai/wandbot/test-llamaindex-weave/weave/calls?filter=%7B%22traceRootsOnly%22%3Atrue%7D&peekPath=%2Fwandbot%2Ftest-llamaindex-weave%2Fcalls%2F6ac53407-1bb7-4c38-b5a3-c302bd877a11%3Ftracetree%3D1)

## ì›í´ë¦­ ê°€ì‹œì„± (One-click observability) ğŸ”­

LlamaIndex ëŠ” í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì›ì¹™ ìˆëŠ” LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ [ì›í´ë¦­ ê°€ì‹œì„± ğŸ”­](https://docs.llamaindex.ai/en/stable/module_guides/observability/) ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

W&B ì˜ ì¸í…Œê·¸ë ˆì´ì…˜ì€ LlamaIndex ì˜ ì´ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ [`WeaveCallbackHandler()`](https://github.com/wandb/weave/blob/master/weave/integrations/llamaindex/llamaindex.py)ë¥¼ `llama_index.core.global_handler`ì— ìë™ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. ë”°ë¼ì„œ LlamaIndex ì™€ Weave ì‚¬ìš©ìë¡œì„œ í•´ì•¼ í•  ì¼ì€ `weave.init(<name-of-project>)`ë¥¼ í†µí•´ Weave run ì„ ì´ˆê¸°í™”í•˜ëŠ” ê²ƒë¿ì…ë‹ˆë‹¤.

## ë” ì‰¬ìš´ ì‹¤í—˜ì„ ìœ„í•œ `Model` ìƒì„±

ë‹¤ì–‘í•œ ìœ ìŠ¤ ì¼€ì´ìŠ¤ë¥¼ ìœ„í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ í”„ë¡¬í”„íŠ¸, ëª¨ë¸ ì„¤ì •, ì¶”ë¡  íŒŒë¼ë¯¸í„°ì™€ ê°™ì€ ì—¬ëŸ¬ êµ¬ì„± ìš”ì†Œê°€ ì„ì—¬ ìˆëŠ” LLM ì„ ì²´ê³„í™”í•˜ê³  í‰ê°€í•˜ëŠ” ê²ƒì€ ì–´ë ¤ìš´ ì¼ì…ë‹ˆë‹¤. [`weave.Model`](/weave/guides/core-types/models)ì„ ì‚¬ìš©í•˜ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë‚˜ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ê³¼ ê°™ì€ ì‹¤í—˜ì ì¸ ì„¸ë¶€ ì‚¬í•­ì„ ìº¡ì²˜í•˜ê³  ì²´ê³„í™”í•˜ì—¬ ì„œë¡œ ë‹¤ë¥¸ ë°˜ë³µ íšŒì°¨(iteration)ë¥¼ ë” ì‰½ê²Œ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‹¤ìŒ ì˜ˆì‹œëŠ” [weave/data](https://github.com/wandb/weave/tree/master/data) í´ë”ì— ìˆëŠ” ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ `WeaveModel` ë‚´ì—ì„œ LlamaIndex ì¿¼ë¦¬ ì—”ì§„ì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

```python lines {16,52,61}
import weave

from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
from llama_index.core.node_parser import SentenceSplitter
from llama_index.llms.openai import OpenAI
from llama_index.core import PromptTemplate


PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ Paul Grahamì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µë°›ì•˜ìŠµë‹ˆë‹¤. ì œê³µëœ ì •ë³´ì—ë§Œ ê¸°ë°˜í•˜ì—¬ ì‚¬ìš©ì ì¿¼ë¦¬ì— ë‹µí•˜ì„¸ìš”. ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.

ì‚¬ìš©ì ì¿¼ë¦¬: {query_str}
ì»¨í…ìŠ¤íŠ¸: {context_str}
ë‹µë³€:
"""

class SimpleRAGPipeline(weave.Model):
    chat_llm: str = "gpt-4"
    temperature: float = 0.1
    similarity_top_k: int = 2
    chunk_size: int = 256
    chunk_overlap: int = 20
    prompt_template: str = PROMPT_TEMPLATE

    def get_llm(self):
        return OpenAI(temperature=self.temperature, model=self.chat_llm)

    def get_template(self):
        return PromptTemplate(self.prompt_template)

    def load_documents_and_chunk(self, data):
        documents = SimpleDirectoryReader(data).load_data()
        splitter = SentenceSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
        )
        nodes = splitter.get_nodes_from_documents(documents)
        return nodes

    def get_query_engine(self, data):
        nodes = self.load_documents_and_chunk(data)
        index = VectorStoreIndex(nodes)

        llm = self.get_llm()
        prompt_template = self.get_template()

        return index.as_query_engine(
            similarity_top_k=self.similarity_top_k,
            llm=llm,
            text_qa_template=prompt_template,
        )

    @weave.op()
    def predict(self, query: str):
        query_engine = self.get_query_engine(
            # ì´ ë°ì´í„°ëŠ” weave ë ˆí¬ì§€í† ë¦¬ì˜ data/paul_graham ì•„ë˜ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            "data/paul_graham",
        )
        response = query_engine.query(query)
        return {"response": response.response}

weave.init("test-llamaindex-weave")

rag_pipeline = SimpleRAGPipeline()
response = rag_pipeline.predict("What did the author do growing up?")
print(response)
```

`weave.Model`ì„ ìƒì†ë°›ì€ ì´ `SimpleRAGPipeline` í´ë˜ìŠ¤ëŠ” ì´ RAG íŒŒì´í”„ë¼ì¸ì˜ ì¤‘ìš”í•œ íŒŒë¼ë¯¸í„°ë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤. `predict` ë©”ì†Œë“œì— `@weave.op()` ë°ì½”ë ˆì´í„°ë¥¼ ì¶”ê°€í•˜ë©´ íŠ¸ë ˆì´ì‹±ì´ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤.

[![llamaindex_model.png](/weave/guides/integrations/imgs/llamaindex_model.png)](https://wandb.ai/wandbot/test-llamaindex-weave/weave/calls?filter=%7B%22traceRootsOnly%22%3Atrue%7D&peekPath=%2Fwandbot%2Ftest-llamaindex-weave%2Fcalls%2Fa82afbf4-29a5-43cd-8c51-603350abeafd%3Ftracetree%3D1)

## `weave.Evaluation`ìœ¼ë¡œ í‰ê°€ ìˆ˜í–‰í•˜ê¸°

í‰ê°€(Evaluation)ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. [`weave.Evaluation`](/weave/guides/core-types/evaluations) í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì´ íŠ¹ì • íƒœìŠ¤í¬ë‚˜ Datasets ì—ì„œ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰ë˜ëŠ”ì§€ ìº¡ì²˜í•  ìˆ˜ ìˆì–´, ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ê³¼ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë°˜ë³µ íšŒì°¨ë¥¼ ë” ì‰½ê²Œ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì˜ˆì‹œëŠ” ìš°ë¦¬ê°€ ë§Œë“  ëª¨ë¸ì„ í‰ê°€í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

```python lines {25,32,36}
import asyncio
from llama_index.core.evaluation import CorrectnessEvaluator

eval_examples = [
    {
        "id": "0",
        "query": "What programming language did Paul Graham learn to teach himself AI when he was in college?",
        "ground_truth": "Paul Graham learned Lisp to teach himself AI when he was in college.",
    },
    {
        "id": "1",
        "query": "What was the name of the startup Paul Graham co-founded that was eventually acquired by Yahoo?",
        "ground_truth": "The startup Paul Graham co-founded that was eventually acquired by Yahoo was called Viaweb.",
    },
    {
        "id": "2",
        "query": "What is the capital city of France?",
        "ground_truth": "I cannot answer this question because no information was provided in the text.",
    },
]

llm_judge = OpenAI(model="gpt-4", temperature=0.0)
evaluator = CorrectnessEvaluator(llm=llm_judge)

@weave.op()
def correctness_evaluator(query: str, ground_truth: str, output: dict):
    result = evaluator.evaluate(
        query=query, reference=ground_truth, response=output["response"]
    )
    return {"correctness": float(result.score)}

evaluation = weave.Evaluation(dataset=eval_examples, scorers=[correctness_evaluator])

rag_pipeline = SimpleRAGPipeline()

asyncio.run(evaluation.evaluate(rag_pipeline))
```

ì´ í‰ê°€ëŠ” ì´ì „ ì„¹ì…˜ì˜ ì˜ˆì‹œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. `weave.Evaluation`ì„ ì‚¬ìš©í•˜ì—¬ í‰ê°€í•˜ë ¤ë©´ í‰ê°€ìš© ë°ì´í„°ì…‹, ìŠ¤ì½”ì–´ëŸ¬(scorer) í•¨ìˆ˜ ë° `weave.Model`ì´ í•„ìš”í•©ë‹ˆë‹¤. ì„¸ ê°€ì§€ ì£¼ìš” êµ¬ì„± ìš”ì†Œì— ëŒ€í•œ ëª‡ ê°€ì§€ ì°¸ê³  ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

- í‰ê°€ ìƒ˜í”Œ ë”•ì…”ë„ˆë¦¬ì˜ í‚¤ê°€ ìŠ¤ì½”ì–´ëŸ¬ í•¨ìˆ˜ì˜ ì¸ìˆ˜ ë° `weave.Model`ì˜ `predict` ë©”ì†Œë“œ ì¸ìˆ˜ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
- `weave.Model`ì€ `predict`, `infer` ë˜ëŠ” `forward`ë¼ëŠ” ì´ë¦„ì˜ ë©”ì†Œë“œë¥¼ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤. íŠ¸ë ˆì´ì‹±ì„ ìœ„í•´ ì´ ë©”ì†Œë“œì— `@weave.op()`ë¥¼ ë°ì½”ë ˆì´ì…˜í•˜ì„¸ìš”.
- ìŠ¤ì½”ì–´ëŸ¬ í•¨ìˆ˜ëŠ” `@weave.op()`ë¡œ ë°ì½”ë ˆì´ì…˜ë˜ì–´ì•¼ í•˜ë©° `output`ì„ ì´ë¦„ì´ ì§€ì •ëœ ì¸ìˆ˜(named argument)ë¡œ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.

[![llamaindex_evaluation.png](/weave/guides/integrations/imgs/llamaindex_evaluation.png)](https://wandb.ai/wandbot/llamaindex-weave/weave/calls?filter=%7B%22opVersionRefs%22%3A%5B%22weave%3A%2F%2F%2Fwandbot%2Fllamaindex-weave%2Fop%2FEvaluation.predict_and_score%3ANmwfShfFmgAhDGLXrF6Xn02T9MIAsCXBUcifCjyKpOM%22%5D%2C%22parentId%22%3A%2233491e66-b580-47fa-9d43-0cd6f1dc572a%22%7D&peekPath=%2Fwandbot%2Fllamaindex-weave%2Fcalls%2F33491e66-b580-47fa-9d43-0cd6f1dc572a%3Ftracetree%3D1)

Weave ë¥¼ LlamaIndex ì™€ í†µí•©í•¨ìœ¼ë¡œì¨, LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì— ëŒ€í•œ í¬ê´„ì ì¸ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ì„ ë³´ì¥í•˜ê³ , í‰ê°€ë¥¼ í†µí•´ ë” ì‰¬ìš´ ë””ë²„ê¹…ê³¼ ì„±ëŠ¥ ìµœì í™”ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.