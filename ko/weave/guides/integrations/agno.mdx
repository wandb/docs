---
title: Agno
description: "OpenTelemetry를 사용해 Weave에서 Agno 멀티에이전트 시스템을 트레이싱하여 에이전트 상호작용, 툴 호출, 공유 메모리 동작, 멀티모달 워크플로우를 캡처하고 AI 에이전트 시스템을 종합적으로 관측할 수 있습니다."
---

[Agno](https://docs.agno.com/) 에이전트와 툴 호출을 [OpenTelemetry (OTEL)](https://opentelemetry.io/)을 사용해 Weave에서 트레이싱할 수 있습니다. Agno는 공유 메모리, 지식, 추론 기능을 갖춘 멀티에이전트 시스템을 구축하기 위한 Python 프레임워크입니다. 경량이고 모델에 구애받지 않으며 고성능을 목표로 설계되었고, 텍스트, 이미지, 오디오, 비디오 처리를 포함한 멀티모달 기능을 지원합니다.

이 가이드는 OTEL을 사용해 Agno 에이전트와 툴 호출을 트레이싱하고, 해당 트레이스를 Weave에서 시각화하는 방법을 설명합니다. 필요한 의존성을 설치하고, 데이터를 Weave로 전송하는 OTEL 트레이서를 구성하고, Agno 에이전트와 툴을 계측하는 방법을 학습하게 됩니다.

<Tip>
  Weave에서 OTEL 트레이싱에 대한 자세한 내용은 [OTEL 트레이스를 Weave로 보내기](../tracking/otel)를 참조하세요.
</Tip>

<div id="prerequisites">
  ## 사전 준비 사항
</div>

1. 필요한 종속성을 설치합니다.

   ```bash
   pip install agno openinference-instrumentation-agno opentelemetry-sdk opentelemetry-exporter-otlp-proto-http
   ```

2. OpenAI API 키(또는 다른 모델 제공자의 API 키)를 환경 변수로 설정합니다.

   ```bash
   export OPENAI_API_KEY=your_api_key_here
   ```

3. [Weave에서 OTEL 트레이싱을 구성합니다](#configure-otel-tracing-in-weave).

<div id="configure-otel-tracing-in-weave">
  ### Weave에서 OTEL 트레이싱 설정
</div>

Agno에서 Weave로 트레이스를 전송하려면, OTEL에 `TracerProvider`와 `OTLPSpanExporter`를 구성해야 합니다. Exporter를 [인증 및 프로젝트 식별을 위한 적절한 엔드포인트와 HTTP 헤더](#required-configuration)에 맞게 설정하세요.

<note>
  API 키와 프로젝트 정보 같은 민감한 환경 변수는 `.env`와 같은 환경 파일에 저장하고, `os.environ`을 사용해 로드할 것을 권장합니다. 이렇게 하면 자격 증명이 안전하게 보호되고 코드베이스에 포함되지 않도록 할 수 있습니다.
</note>

<div id="required-configuration">
  #### 필요한 설정
</div>

* **Endpoint:** `https://trace.wandb.ai/otel/v1/traces`
* **Headers:**
  * `Authorization`: W&amp;B API 키를 사용하는 Basic 인증
  * `project_id`: W&amp;B Entity/프로젝트 이름(예: `myteam/myproject`)

<div id="send-otel-traces-from-agno-to-weave">
  ## Agno에서 Weave로 OTEL 트레이스 전송하기
</div>

[사전 준비](#prerequisites)를 완료했다면 Agno에서 Weave로 OTEL 트레이스를 전송할 수 있습니다. 다음 코드 스니펫은 OTLP span exporter와 tracer provider를 구성하여 Agno 애플리케이션에서 Weave로 OTEL 트레이스를 전송하는 방법을 보여 줍니다.

<Warning>
  Weave가 Agno를 올바르게 트레이싱하도록 하려면 코드에서 Agno 컴포넌트를 사용하기 *전에* 전역 tracer provider를 설정해야 합니다.
</Warning>

```python lines
# tracing.py

import base64
import os
from openinference.instrumentation.agno import AgnoInstrumentor
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk import trace as trace_sdk
from opentelemetry.sdk.trace.export import SimpleSpanProcessor
from opentelemetry import trace

# 환경 변수에서 민감한 값 로드
WANDB_BASE_URL = "https://trace.wandb.ai"
# W&B entity/프로젝트 이름 예: "myteam/myproject"
PROJECT_ID = os.environ.get("WANDB_PROJECT_ID")  
# https://wandb.ai/settings 에서 W&B API 키 생성
WANDB_API_KEY = os.environ.get("WANDB_API_KEY")  

OTEL_EXPORTER_OTLP_ENDPOINT = f"{WANDB_BASE_URL}/otel/v1/traces"
AUTH = base64.b64encode(f"api:{WANDB_API_KEY}".encode()).decode()

OTEL_EXPORTER_OTLP_HEADERS = {
    "Authorization": f"Basic {AUTH}",
    "project_id": PROJECT_ID,
}

# 엔드포인트와 헤더로 OTLP 스팬 익스포터 생성
exporter = OTLPSpanExporter(
    endpoint=OTEL_EXPORTER_OTLP_ENDPOINT,
    headers=OTEL_EXPORTER_OTLP_HEADERS,
)

# 트레이서 프로바이더 생성 및 익스포터 추가
tracer_provider = trace_sdk.TracerProvider()
tracer_provider.add_span_processor(SimpleSpanProcessor(exporter))

# Agno를 임포트/사용하기 전에 전역 트레이서 프로바이더 설정
trace.set_tracer_provider(tracer_provider)
```

<div id="trace-agno-agents-with-otel">
  ## OTEL로 Agno 에이전트 트레이싱하기
</div>

tracer provider를 설정한 후에는 자동 트레이싱이 적용된 Agno 에이전트를 생성하고 실행할 수 있습니다. 다음 예제에서는 도구를 사용하는 간단한 에이전트를 생성하는 방법을 보여줍니다:

```python lines
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.yfinance import YFinanceTools

from dotenv import load_dotenv
load_dotenv()

# 위에서 생성한 파일에서 AgnoInstrumentor 로드
from tracing import AgnoInstrumentor

# Agno 계측 시작
AgnoInstrumentor().instrument()

# 금융 에이전트 생성
finance_agent = Agent(
    name="Finance Agent",
    model=OpenAIChat(id="gpt-4o-mini"),
    tools=[
        YFinanceTools(
            stock_price=True,
            analyst_recommendations=True,
            company_info=True,
            company_news=True
        )
    ],
    instructions=["Use tables to display data"],
    show_tool_calls=True,
    markdown=True,
)

# 에이전트 사용 - 자동으로 추적됩니다
finance_agent.print_response(
    "What is the current stock price of Apple and what are the latest analyst recommendations?",
    stream=True
)
```

에이전트의 모든 작업은 자동으로 추적되어 Weave로 전송되며, 이를 통해 실행 흐름, 모델 호출, 추론 단계, 도구 호출을 시각화할 수 있습니다.

<Frame>
  ![Agno 에이전트의 트레이스 시각화](/weave/guides/integrations/imgs/agno/agno_agent_trace.png)
</Frame>

<div id="trace-agno-tools-with-otel">
  ## OTEL로 Agno 툴 추적하기
</div>

Agno로 툴을 정의하고 사용할 때, 이러한 툴 호출도 트레이스에 함께 캡처됩니다. OTEL 인테그레이션은 에이전트의 추론 과정과 개별 툴 실행을 모두 자동으로 계측하여, 에이전트의 동작을 포괄적으로 파악할 수 있도록 해 줍니다.

다음은 여러 개의 툴을 사용하는 예시입니다:

```python lines
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.yfinance import YFinanceTools

from dotenv import load_dotenv
load_dotenv()

# 위에서 생성한 파일에서 AgnoInstrumentor 로드
from tracing import AgnoInstrumentor

# Agno 계측 시작
AgnoInstrumentor().instrument()

# 여러 도구를 사용하는 에이전트 생성
research_agent = Agent(
    name="Research Agent",
    model=OpenAIChat(id="gpt-4o-mini"),
    tools=[
        DuckDuckGoTools(),
        YFinanceTools(stock_price=True, company_info=True),
    ],
    instructions=[
        "Search for current information and financial data",
        "Always include sources",
        "Use tables to display financial data"
    ],
    show_tool_calls=True,
    markdown=True,
)

# 에이전트 사용 - 도구 호출이 추적됨
research_agent.print_response(
    "Research Tesla's recent performance and news. Include stock price and any recent developments.",
    stream=True
)
```

<Frame>
  ![Agno 도구 호출 트레이스 시각화](/weave/guides/integrations/imgs/agno/agno_tool_calls.png)
</Frame>

<div id="trace-multi-agent-teams-with-otel">
  ## OTEL로 멀티 에이전트 팀 추적하기
</div>

Agno의 강력한 멀티 에이전트 아키텍처를 사용하면 컨텍스트를 공유하며 협업할 수 있는 에이전트 팀을 구성할 수 있습니다. 이러한 팀 간 상호작용도 전 과정이 모두 추적됩니다:

```python lines
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.yfinance import YFinanceTools

from dotenv import load_dotenv
load_dotenv()

# tracin.py 파일에서 AgnoInstrumentor 로드
from tracing import AgnoInstrumentor

# Agno 계측 시작
AgnoInstrumentor().instrument()

# 전문화된 에이전트 생성
web_agent = Agent(
    name="Web Agent",
    role="Search the web for information",
    model=OpenAIChat(id="gpt-4o-mini"),
    tools=[DuckDuckGoTools()],
    instructions="Always include sources",
    show_tool_calls=True,
    markdown=True,
)

finance_agent = Agent(
    name="Finance Agent", 
    role="Get financial data",
    model=OpenAIChat(id="gpt-4o-mini"),
    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True)],
    instructions="Use tables to display data",
    show_tool_calls=True,
    markdown=True,
)

# 에이전트 팀 생성
agent_team = Agent(
    team=[web_agent, finance_agent],
    model=OpenAIChat(id="gpt-4o"),
    instructions=["Always include sources", "Use tables to display data"],
    show_tool_calls=True,
    markdown=True,
)

# 팀 사용 - 모든 에이전트 상호작용이 추적됨
agent_team.print_response(
    "What's the current market sentiment around NVIDIA? Include both news analysis and financial metrics.",
    stream=True
)
```

이 멀티 에이전트 트레이스는 Weave 내 여러 에이전트 간의 조율 과정을 보여 주어, 작업이 에이전트 팀 전반에 어떻게 분배되고 실행되는지 파악할 수 있게 합니다.

<Frame>
  ![Agno 멀티 에이전트 팀의 트레이스 시각화](/weave/guides/integrations/imgs/agno/agno_team_trace.png)
</Frame>

<div id="work-with-reasoning-agents">
  ## Reasoning Agent 사용하기
</div>

Agno는 에이전트가 문제를 단계별로 사고할 수 있도록 돕는 내장 추론 기능을 제공합니다. 이러한 추론 과정은 trace에도 기록됩니다.

```python lines
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.reasoning import ReasoningTools
from agno.tools.yfinance import YFinanceTools

from dotenv import load_dotenv
load_dotenv()

# tracing.py 파일에서 AgnoInstrumentor 로드
from tracing import AgnoInstrumentor

# Agno 계측 시작
AgnoInstrumentor().instrument()

# 추론 에이전트 생성
reasoning_agent = Agent(
    name="Reasoning Finance Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[
        ReasoningTools(add_instructions=True),
        YFinanceTools(
            stock_price=True,
            analyst_recommendations=True,
            company_info=True,
            company_news=True
        ),
    ],
    instructions="Use tables to display data and show your reasoning process",
    show_tool_calls=True,
    markdown=True,
)

# 추론 에이전트 사용
reasoning_agent.print_response(
    "Should I invest in Apple stock right now? Analyze the current situation and provide a reasoned recommendation.",
    stream=True
)
```

추론 단계는 trace에서 확인할 수 있으며, 에이전트가 복잡한 문제를 어떻게 분해하고 결정을 내리는지 보여줍니다.

<Frame>
  ![Agno 추론 에이전트의 trace 시각화](/weave/guides/integrations/imgs/agno/agno_reasoning_trace.png)
</Frame>

<div id="work-with-memory-and-knowledge">
  ## 메모리와 지식 다루기
</div>

Agno 에이전트는 메모리를 유지하고 지식 베이스에 접근할 수 있습니다. 이러한 작업도 모두 추적됩니다:

```python lines
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.memory import AgentMemory
from agno.storage.sqlite import SqliteStorage

from dotenv import load_dotenv
load_dotenv()

# tracin.py 파일에서 AgnoInstrumentor 로드
from tracing import AgnoInstrumentor

# Agno 계측 시작
AgnoInstrumentor().instrument()


# 메모리가 있는 에이전트 생성
memory_agent = Agent(
    name="Memory Agent",
    model=OpenAIChat(id="gpt-4o-mini"),
    memory=AgentMemory(),
    storage=SqliteStorage(
        table_name="agent_sessions",
        db_file="agent_memory.db"
    ),
    instructions="Remember our conversation history",
    show_tool_calls=True,
    markdown=True,
)

# 첫 번째 상호작용
memory_agent.print_response("My name is John and I'm interested in AI investing strategies.")

# 두 번째 상호작용 - 에이전트가 이전 컨텍스트를 기억함
memory_agent.print_response("What specific AI companies would you recommend for my portfolio?")
```

<Frame>
  ![Agno 메모리 사용량의 트레이스 시각화](/weave/guides/integrations/imgs/agno/agno_memory_use.png)
</Frame>

대화 기록의 저장 및 검색을 포함한 메모리 연산이 트레이스에 표시됩니다.

<div id="learn-more">
  ## 더 알아보기
</div>

* [Weave 문서: OTEL 트레이스를 Weave로 보내기](../tracking/otel)
* [공식 Agno 문서](https://docs.agno.com/)
* [공식 OTEL 문서](https://opentelemetry.io/)
* [Agno GitHub 저장소](https://github.com/agno-agi/agno)
* [OpenInference Agno 계측](https://pypi.org/project/openinference-instrumentation-agno/)