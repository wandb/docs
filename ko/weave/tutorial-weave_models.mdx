---
title: '튜토리얼: App 버전 관리'
description: 애플리케이션과 해당 파라미터를 추적하고 버전 관리를 하기 위해 Weave Model 을 사용하는 방법을 알아보세요
---

시스템의 성능을 이해하기 위해서는 [입력, 출력, 메타데이터](/weave/quickstart)뿐만 아니라 [애플리케이션을 통해 흐르는 데이터](/weave/tutorial-tracing_2)를 추적하는 것이 매우 중요합니다. 하지만 **시간에 따른 애플리케이션의 버전 관리** 또한 코드나 애플리케이션 파라미터의 변경이 출력에 어떤 영향을 미치는지 이해하는 데 필수적입니다. Weave 의 `Model` 클래스를 사용하면 이러한 변경 사항을 Weave 에서 추적할 수 있습니다.

이 튜토리얼에서는 다음 내용을 배웁니다:

- Weave `Model`을 사용하여 애플리케이션과 해당 파라미터를 추적하고 버전 관리하는 방법.
- 이미 로그된 Weave `Model`을 내보내고, 수정하고, 재사용하는 방법.

## `weave.Model` 사용하기

<Warning>

`weave.Model` 클래스는 현재 Python 에서만 지원됩니다.

</Warning>

Weave `Model`을 사용한다는 것은 모델 벤더 ID, 프롬프트, temperature 등과 같은 파라미터가 변경될 때마다 저장되고 버전 관리됨을 의미합니다.

Weave 에서 `Model`을 생성하려면 다음이 필요합니다:

- `weave.Model`을 상속받는 클래스
- 모든 클래스 필드에 대한 타입 정의
- `@weave.op()` 데코레이터가 적용된 타입이 지정된 `invoke` 함수

클래스 필드나 모델을 정의하는 코드를 변경하면, **이러한 변경 사항이 로그되고 버전이 업데이트됩니다**. 이를 통해 애플리케이션의 서로 다른 버전 간에 생성 결과를 비교할 수 있습니다.

아래 예시에서는 **모델 이름, temperature 및 시스템 프롬프트가 추적되고 버전 관리됩니다**:

<Tabs>
  <Tab title="Python">
    ```python lines {26,33-34}
    import json
    from openai import OpenAI

    import weave

    @weave.op()
    def extract_dinos(wmodel: weave.Model, sentence: str) -> dict:
        # response를 생성할 때 wmodel의 파라미터를 사용합니다.
        response = wmodel.client.chat.completions.create(
            model=wmodel.model_name,
            temperature=wmodel.temperature,
            messages=[
                {
                    "role": "system",
                    "content": wmodel.system_prompt
                },
                {
                    "role": "user",
                    "content": sentence
                }
                ],
                response_format={ "type": "json_object" }
            )
        return response.choices[0].message.content

    # weave.Model을 상속받는 서브클래스 정의
    class ExtractDinos(weave.Model):
        client: OpenAI = None
        model_name: str
        temperature: float
        system_prompt: str

        # 함수 이름을 `invoke` 또는 `predict`로 설정하세요.
        @weave.op()
        def invoke(self, sentence: str) -> dict:
            dino_data  = extract_dinos(self, sentence)
            return json.loads(dino_data)
    ```

  </Tab>
  <Tab title="TypeScript">
    ```plaintext
    이 기능은 아직 TypeScript에서 지원되지 않습니다. 조금만 기다려 주세요!
    ```
  </Tab>
</Tabs>

이제 모델을 인스턴스화하고 `invoke`로 호출할 수 있습니다:

<Tabs>
  <Tab title="Python">
    ```python lines {7,18}
    weave.init('jurassic-park')
    client = OpenAI()

    system_prompt = """Extract any dinosaur `name`, their `common_name`, \
    names and whether its `diet` is a herbivore or carnivore, in JSON format."""

    dinos = ExtractDinos(
        client=client,
        model_name='gpt-4o',
        temperature=0.4,
        system_prompt=system_prompt
    )

    sentence = """I watched as a Tyrannosaurus rex (T. rex) chased after a Triceratops (Trike), \
    both carnivore and herbivore locked in an ancient dance. Meanwhile, a gentle giant \
    Brachiosaurus (Brachi) calmly munched on treetops, blissfully unaware of the chaos below."""

    result = dinos.invoke(sentence)
    print(result)
    ```

  </Tab>
  <Tab title="TypeScript">
    ```plaintext
    이 기능은 아직 TypeScript에서 지원되지 않습니다. 조금만 기다려 주세요!
    ```
  </Tab>
</Tabs>

`.invoke`를 호출한 후 Weave 의 trace 를 확인하면, **이제 모델 파라미터와 함께** `weave.op()`로 데코레이션된 모델 함수의 **코드도 추적되는 것**을 볼 수 있습니다. 모델이 버전 관리(이 경우 "v21")되는 것을 확인할 수 있으며, 모델을 클릭하면 해당 버전의 모델을 사용한 **모든 호출 내역을 볼 수 있습니다**.

![weave 모델 재사용하기](/images/tutorial-model_invoke3.png)

**`weave.Model` 사용 시 참고 사항:**

- 선호에 따라 Weave `Model` 내의 함수 이름을 `invoke` 대신 `predict`로 사용할 수 있습니다.
- 다른 클래스 메소드도 Weave 에서 추적되기를 원한다면 `weave.op()`로 감싸야 합니다.
- 밑줄(`_`)로 시작하는 파라미터는 Weave 에서 무시하며 로그되지 않습니다.

## 로그된 `weave.Model` 내보내기 및 재사용하기

Weave 는 호출된 모델을 저장하고 버전을 관리하므로, 이 모델들을 내보내어 재사용하는 것이 가능합니다.

**모델 참조(ref) 가져오기**
Weave UI 에서 특정 버전에 대한 모델 참조(ref)를 가져올 수 있습니다.

**모델 사용하기**
모델 오브젝트의 URI를 확보하면, 이를 내보내어 재사용할 수 있습니다. 내보낸 모델은 이미 초기화되어 바로 사용할 수 있는 상태입니다:

<Tabs>
  <Tab title="Python">
    ```python lines {2}
    # 내보낸 weave 모델은 이미 초기화되어 호출할 준비가 되어 있습니다.
    new_dinos = weave.ref("weave://morgan/jurassic-park/object/ExtractDinos:ey4udBU2MU23heQFJenkVxLBX4bmDsFk7vsGcOWPjY4").get()

    # client를 다시 openai client로 설정합니다.
    new_dinos.client = client

    new_sentence = """I also saw an Ankylosaurus grazing on giant ferns"""
    new_result = new_dinos.invoke(new_sentence)
    print(new_result)
    ```

  </Tab>
  <Tab title="TypeScript">
    ```plaintext
    이 기능은 아직 TypeScript에서 지원되지 않습니다. 조금만 기다려 주세요!
    ```
  </Tab>
</Tabs>

여기서 새로운 입력에 대해 동일한 모델 버전(v21)이 사용된 것을 확인할 수 있습니다:

![weave 모델 재사용하기](/images/tutorial-model_re-use.png)

## 다음 단계는?

- [Evaluation 파이프라인 구축 튜토리얼](/weave/tutorial-eval)을 따라 애플리케이션을 반복적으로 개선해 보세요.