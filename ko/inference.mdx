---
title: "W&B Inference"
description: W&B Weave와 OpenAI 호환 API를 통해 오픈 소스 파운데이션 모델에 액세스하세요
mode: wide
---

W&amp;B Inference를 사용하면 W&amp;B Weave와 OpenAI 호환 API를 통해 선도적인 오픈 소스 파운데이션 모델에 액세스할 수 있습니다. 다음과 같은 작업을 수행할 수 있습니다:

* 호스팅 제공업체에 가입하거나 모델을 직접 호스팅하지 않고도 AI 애플리케이션과 에이전트를 구축할 수 있습니다
* [지원되는 모델](/ko/inference/models)을 [W&amp;B Weave Playground](/ko/weave/guides/tools/playground)에서 사용해 볼 수 있습니다

Weave를 사용하면 W&amp;B Inference로 구동되는 애플리케이션을 추적, 평가, 모니터링하고 개선할 수 있습니다.

<div id="quickstart">
  ## 빠른 시작
</div>

다음은 Python을 사용한 간단한 예제입니다:

```python
import openai

client = openai.OpenAI(
    # 커스텀 base URL은 W&B Inference를 가리킵니다
    base_url='https://api.inference.wandb.ai/v1',

    # https://wandb.ai/settings 에서 API 키를 생성하세요
    api_key="<your-api-key>",

    # 선택 사항: 사용량 추적을 위한 팀 및 프로젝트
    project="<your-team>/<your-project>",
)

response = client.chat.completions.create(
    model="meta-llama/Llama-3.1-8B-Instruct",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Tell me a joke."}
    ],
)

print(response.choices[0].message.content)
```

<div id="next-steps">
  ## 다음 단계
</div>

1. [사용 가능한 모델](/ko/inference/models)과 [사용량 정보 및 제한](/ko/inference/usage-limits/)을 검토합니다.
2. [사전 준비 사항](/ko/inference/prerequisites/)을 따라 계정을 설정합니다.
3. [API](/ko/inference/api-reference/) 또는 [UI](/ko/inference/ui-guide/)를 통해 서비스를 이용합니다.
4. [사용 예제](/ko/inference/examples/)를 시도해 봅니다.

<div id="usage-details">
  ## 사용량 상세 정보
</div>

<Info>
  요금, 사용 한도 및 크레딧에 대한 자세한 내용은 [사용 정보 및 한도](/ko/inference/usage-limits/)를 참고하세요.
</Info>