---
title: TensorFlow
---
import { ColabLink } from '/snippets/en/_includes/colab-link.mdx';

<ColabLink url="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/tensorflow/Simple_TensorFlow_Integration.ipynb" />

## 이 노트북에서 다루는 내용

* 실험 트래킹을 위해 W&B를 TensorFlow 파이프라인에 간편하게 통합하는 방법.
* `keras.metrics`를 사용하여 메트릭 계산하기.
* 커스텀 트레이닝 루프에서 `wandb.log`를 사용하여 해당 메트릭 로그 기록하기.

<Frame>
    <img src="/images/tutorials/tensorflow/dashboard.png" alt="dashboard"  />
</Frame>

**참고**: _Step_으로 시작하는 섹션들만 확인하면 기존 코드에 W&B를 통합하는 데 충분합니다. 나머지 부분은 표준적인 MNIST 예제입니다.

```python
import os

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.datasets import cifar10
```

## 설치, 임포트, 로그인

### W&B 설치


```jupyter
%%capture
!pip install wandb
```

### W&B 임포트 및 로그인


```python
import wandb
from wandb.integration.keras import WandbMetricsLogger

wandb.login()
```

> 참고: W&B를 처음 사용하거나 로그인하지 않은 경우, `wandb.login()` 실행 후 나타나는 링크를 통해 가입/로그인 페이지로 이동할 수 있습니다. 클릭 한 번으로 간편하게 가입할 수 있습니다.

### 데이터셋 준비

```python
# 트레이닝 데이터셋 준비
BATCH_SIZE = 64
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
x_train = np.reshape(x_train, (-1, 784))
x_test = np.reshape(x_test, (-1, 784))

# tf.data를 사용하여 입력 파이프라인 구축
train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)

val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))
val_dataset = val_dataset.batch(BATCH_SIZE)
```

## 모델 및 트레이닝 루프 정의

```python
def make_model():
    inputs = keras.Input(shape=(784,), name="digits")
    x1 = keras.layers.Dense(64, activation="relu")(inputs)
    x2 = keras.layers.Dense(64, activation="relu")(x1)
    outputs = keras.layers.Dense(10, name="predictions")(x2)

    return keras.Model(inputs=inputs, outputs=outputs)
```


```python
def train_step(x, y, model, optimizer, loss_fn, train_acc_metric):
    with tf.GradientTape() as tape:
        logits = model(x, training=True)
        loss_value = loss_fn(y, logits)

    grads = tape.gradient(loss_value, model.trainable_weights)
    optimizer.apply_gradients(zip(grads, model.trainable_weights))

    train_acc_metric.update_state(y, logits)

    return loss_value
```


```python
def test_step(x, y, model, loss_fn, val_acc_metric):
    val_logits = model(x, training=False)
    loss_value = loss_fn(y, val_logits)
    val_acc_metric.update_state(y, val_logits)

    return loss_value
```

## 트레이닝 루프에 `wandb.log` 추가하기


```python
def train(
    train_dataset,
    val_dataset,
    model,
    optimizer,
    train_acc_metric,
    val_acc_metric,
    epochs=10,
    log_step=200,
    val_log_step=50,
):
    # wandb.init으로 run을 시작하고 프로젝트 및 설정 정보를 전달합니다.
    run = wandb.init(
        project="my-tf-integration",
        config={
            "epochs": epochs,
            "log_step": log_step,
            "val_log_step": val_log_step,
            "architecture": "MLP",
            "dataset": "MNIST",
        },
    )
    for epoch in range(epochs):
        print("\nStart of epoch %d" % (epoch,))

        train_loss = []
        val_loss = []

        # 데이터셋의 배치에 대해 반복합니다.
        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):
            loss_value = train_step(
                x_batch_train,
                y_batch_train,
                model,
                optimizer,
                loss_fn,
                train_acc_metric,
            )
            train_loss.append(float(loss_value))

        # 각 에포크가 끝날 때 검증 루프를 실행합니다.
        for step, (x_batch_val, y_batch_val) in enumerate(val_dataset):
            val_loss_value = test_step(
                x_batch_val, y_batch_val, model, loss_fn, val_acc_metric
            )
            val_loss.append(float(val_loss_value))

        # 에포크 종료 시 메트릭을 표시합니다.
        train_acc = train_acc_metric.result()
        print("Training acc over epoch: %.4f" % (float(train_acc),))

        val_acc = val_acc_metric.result()
        print("Validation acc: %.4f" % (float(val_acc),))

        # 에포크 종료 시 메트릭 상태를 리셋합니다.
        train_acc_metric.reset_state()
        val_acc_metric.reset_state()

        # run.log()를 사용하여 메트릭 로그를 기록합니다.
        run.log(
            {
                "epochs": epoch,
                "loss": np.mean(train_loss),
                "acc": float(train_acc),
                "val_loss": np.mean(val_loss),
                "val_acc": float(val_acc),
            }
        )
    run.finish()
```

## 트레이닝 실행

### `wandb.init()`을 호출하여 Run 시작하기

이 과정을 통해 실험을 시작함을 알릴 수 있으며, 고유 ID와 대시보드가 생성됩니다.

[공식 문서 확인하기](/models/ref/python/functions/init)

```python
# 프로젝트 이름과 선택적으로 설정을 포함하여 wandb를 초기화합니다.
# 설정 값을 변경해보며 wandb 대시보드에서 결과를 확인해보세요.
config = {
    "learning_rate": 0.001,
    "epochs": 10,
    "batch_size": 64,
    "log_step": 200,
    "val_log_step": 50,
    "architecture": "CNN",
    "dataset": "CIFAR-10",
}

run = wandb.init(project='my-tf-integration', config=config)
config = run.config

# 모델 초기화.
model = make_model()

# 모델 트레이닝을 위한 옵티마이저 인스턴스 생성.
optimizer = keras.optimizers.SGD(learning_rate=config.learning_rate)
# 손실 함수 인스턴스 생성.
loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)

# 메트릭 준비.
train_acc_metric = keras.metrics.SparseCategoricalAccuracy()
val_acc_metric = keras.metrics.SparseCategoricalAccuracy()

train(
    train_dataset,
    val_dataset, 
    model,
    optimizer,
    train_acc_metric,
    val_acc_metric,
    epochs=config.epochs, 
    log_step=config.log_step, 
    val_log_step=config.val_log_step,
)

run.finish()  # Jupyter/Colab 환경에서 프로세스 종료를 알립니다.
```

### 결과 시각화

위의 [run page](/models/runs/#view-logged-runs) 링크를 클릭하여 실시간 결과를 확인하세요.

## Sweep 101

W&B Sweeps 를 사용하여 하이퍼파라미터 최적화를 자동화하고 가능한 모델 공간을 탐색하세요.

[W&B Sweeps를 사용한 하이퍼파라미터 최적화 데모 Colab 노트북](https://wandb.me/tf-sweeps-colab)을 확인해 보세요.

### W&B Sweeps 사용의 장점

* **빠른 설정**: 단 몇 줄의 코드만으로 W&B Sweeps 를 실행할 수 있습니다.
* **투명성**: 사용 중인 모든 알고리즘을 명시하며, [코드는 오픈 소스](https://github.com/wandb/sweeps)로 공개되어 있습니다.
* **강력한 기능**: Sweeps 는 완전히 커스터마이징 및 설정이 가능합니다. 수십 대의 장비에서 스윕을 실행하는 것도 노트북에서 시작하는 것만큼 쉽습니다.

<Frame>
    <img src="/images/tutorials/tensorflow/sweeps.png" alt="Sweep result"  />
</Frame>

## 예제 갤러리

W&B로 트래킹하고 시각화한 프로젝트 예제들을 [Fully Connected →](https://wandb.me/fc) 갤러리에서 살펴보세요.

## 모범 사례
1. **Projects**: 여러 run 을 하나의 프로젝트에 기록하여 비교하세요. `wandb.init(project="project-name")`
2. **Groups**: 멀티 프로세스나 교차검증 폴드의 경우, 각 프로세스를 run 으로 기록하고 그룹화하세요. `wandb.init(group="experiment-1")`
3. **Tags**: 태그를 추가하여 현재 베이스라인 이나 프로덕션 모델을 추적하세요.
4. **Notes**: 테이블에 노트를 작성하여 각 run 사이의 변경 사항을 기록하세요.
5. **Reports**: 진행 상황에 대해 간단한 노트를 작성하여 동료와 공유하고, ML 프로젝트의 대시보드와 스냅샷 을 만드세요.

### 고급 설정
1. [환경 변수](/platform/hosting/env-vars/): 관리형 클러스터 에서 트레이닝을 실행할 수 있도록 환경 변수에 API 키 를 설정하세요.
2. [오프라인 모드](/models/support/run_wandb_offline/)
3. [온프레미스](/platform/hosting/hosting-options/self-managed): 자체 인프라의 프라이빗 클라우드 나 에어갭(air-gapped) 서버에 W&B를 설치하세요. 학계부터 엔터프라이즈 팀까지 모두를 위한 로컬 설치를 지원합니다.
4. [Artifacts](/models/artifacts/): 모델을 트레이닝할 때 파이프라인 단계를 자동으로 캡처하여 모델과 데이터셋 을 효율적인 방식으로 추적하고 버전 관리하세요.