---
title: 파라미터 중요도
description: 모델의 하이퍼파라미터와 출력 메트릭 사이의 관계를 시각화하세요
---

어떤 하이퍼파라미터가 메트릭의 바람직한 값을 가장 잘 예측하고 높은 상관관계를 가졌는지 확인해 보세요.


<Frame>
    <img src="/images/general/parameter-importance-1.png" alt="Parameter importance panel"  />
</Frame>

**Correlation** (상관관계)은 하이퍼파라미터와 선택한 메트릭(이 경우 val_loss) 사이의 선형 상관관계입니다. 높은 상관관계는 하이퍼파라미터 값이 높을 때 메트릭 값도 높아짐을 의미하며, 그 반대도 마찬가지입니다. 상관관계는 살펴보기에 좋은 메트릭이지만, 입력값 사이의 2차 상호작용을 포착할 수 없으며 범위가 크게 다른 입력값들을 비교할 때 복잡해질 수 있습니다.

따라서 W&B는 **importance** (중요도) 메트릭도 함께 계산합니다. W&B는 하이퍼파라미터를 입력으로, 메트릭을 타겟 출력으로 하여 랜덤 포레스트를 트레이닝하고 해당 랜덤 포레스트의 피처 중요도 값을 리포트합니다.

이 기법에 대한 아이디어는 [Fast.ai](https://fast.ai)에서 하이퍼파라미터 공간 탐색을 위해 랜덤 포레스트 피처 중요도 사용을 개척한 [Jeremy Howard](https://twitter.com/jeremyphoward)와의 대화에서 영감을 얻었습니다. W&B는 이 분석 뒤에 숨겨진 동기에 대해 더 자세히 알아보기 위해 이 [강의](https://course18.fast.ai/lessonsml1/lesson4.html) (및 [노트](https://forums.fast.ai/t/wiki-lesson-thread-lesson-4/7540))를 확인해 보실 것을 강력히 권장합니다.

하이퍼파라미터 파라미터 중요도 패널은 상관관계가 높은 하이퍼파라미터 간의 복잡한 상호작용을 풀어냅니다. 이를 통해 모델 성능 예측에 있어 어떤 하이퍼파라미터가 가장 중요한지 보여줌으로써 하이퍼파라미터 탐색을 세밀하게 튜닝할 수 있도록 도와줍니다.

## 하이퍼파라미터 파라미터 중요도 패널 생성하기

1. W&B 프로젝트로 이동합니다.
2. **Add panels** 버튼을 선택합니다.
3. **CHARTS** 드롭다운을 확장하고 드롭다운에서 **Parallel coordinates**를 선택합니다.


<Note>
빈 패널이 나타나면 Runs 가 그룹화 해제되어 있는지 확인하세요.
</Note>


<Frame>
    <img src="/images/app_ui/hyperparameter_importance_panel.gif" alt="Automatic parameter visualization"  />
</Frame>

파라미터 매니저를 사용하여 표시하거나 숨길 파라미터를 수동으로 설정할 수 있습니다.

<Frame>
    <img src="/images/app_ui/hyperparameter_importance_panel_manual.gif" alt="Manually setting the visible and hidden fields"  />
</Frame>

## 하이퍼파라미터 파라미터 중요도 패널 해석하기

<Frame>
    <img src="/images/general/parameter-importance-4.png" alt="Feature importance analysis"  />
</Frame>

이 패널은 트레이닝 스크립트의 [wandb.Run.config](/models/track/config/) 오브젝트로 전달된 모든 파라미터를 보여줍니다. 그다음, 선택한 모델 메트릭(이 경우 `val_loss`)에 대한 이러한 config 파라미터의 피처 중요도와 상관관계를 보여줍니다.

### Importance (중요도)

중요도 컬럼은 각 하이퍼파라미터가 선택한 메트릭을 예측하는 데 얼마나 유용했는지를 보여줍니다. 수많은 하이퍼파라미터를 튜닝하기 시작할 때 이 플롯을 사용하여 어떤 파라미터가 추가 탐색 가치가 있는지 좁혀가는 시나리오를 상상해 보세요. 이후의 Sweeps 는 가장 중요한 하이퍼파라미터로 제한하여 더 빠르고 저렴하게 더 나은 모델을 찾을 수 있습니다.

<Note>
W&B는 선형 모델보다 범주형 데이터와 정규화되지 않은 데이터에 더 관대한 트리 기반 모델을 사용하여 중요도를 계산합니다.
</Note>

위의 이미지에서 `epochs, learning_rate, batch_size` 및 `weight_decay`가 상당히 중요했음을 알 수 있습니다.

### Correlations (상관관계)

상관관계는 개별 하이퍼파라미터와 메트릭 값 사이의 선형 관계를 포착합니다. 이는 SGD 옵티마이저와 같은 하이퍼파라미터 사용과 `val_loss` 사이에 유의미한 관계가 있는지에 대한 질문에 답을 줍니다(이 경우 답은 '예'입니다). 상관관계 값의 범위는 -1에서 1 사이이며, 양수 값은 양의 선형 상관관계, 음수 값은 음의 선형 상관관계, 0은 상관관계 없음을 나타냅니다. 일반적으로 어느 방향으로든 0.7보다 큰 값은 강한 상관관계를 나타냅니다.

이 그래프를 사용하여 메트릭과 더 높은 상관관계를 가진 값을 더 탐색하거나(이 경우 rmsprop이나 nadam보다 stochastic gradient descent 또는 adam을 선택할 수 있음), 더 많은 에포크 동안 트레이닝할 수 있습니다.


<Note>
* 상관관계는 연관성의 증거를 보여주는 것이며, 반드시 인과관계를 의미하지는 않습니다.
* 상관관계는 아웃라이어에 민감하여, 특히 시도된 하이퍼파라미터의 샘플 크기가 작은 경우 강한 관계를 중간 정도로 바꿀 수 있습니다.
* 마지막으로, 상관관계는 하이퍼파라미터와 메트릭 사이의 선형 관계만 포착합니다. 강한 다항식 관계가 있더라도 상관관계로는 포착되지 않습니다.
</Note>

중요도와 상관관계 사이의 차이는 중요도가 하이퍼파라미터 간의 상호작용을 고려하는 반면, 상관관계는 개별 하이퍼파라미터가 메트릭 값에 미치는 영향만을 측정한다는 사실에서 발생합니다. 둘째, 상관관계는 선형 관계만 포착하는 반면, 중요도는 더 복잡한 관계를 포착할 수 있습니다.

보시는 것처럼 중요도와 상관관계 모두 하이퍼파라미터가 모델 성능에 어떤 영향을 미치는지 이해하는 데 강력한 툴입니다.