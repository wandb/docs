---
description: 모델의 하이퍼파라미터와 출력 지표 간의 관계를 시각화합니다
title: 파라미터 중요도
---

어떤 하이퍼파라미터가 모델 지표의 바람직한 값을 가장 잘 예측하고, 그와 높은 상관관계를 보였는지 확인합니다.

<Frame>
  <img src="/images/general/parameter-importance-1.png" alt="Parameter importance panel" />
</Frame>

**Correlation**은 하이퍼파라미터와 선택한 지표(이 경우 `val_loss`) 사이의 선형 상관관계를 의미합니다. 상관관계가 높다는 것은 하이퍼파라미터 값이 커질수록 지표 값도 커지고, 그 반대도 마찬가지라는 뜻입니다. Correlation은 유용한 지표이지만, 입력값들 간의 2차 상호작용을 포착하지 못하고, 범위가 크게 다른 입력값들을 비교할 때는 해석이 복잡해질 수 있습니다.

그래서 W&amp;B는 **importance** 지표도 계산합니다. W&amp;B는 하이퍼파라미터를 입력으로, 지표를 타깃 출력으로 사용해 랜덤 포레스트를 학습시키고, 해당 랜덤 포레스트의 특성 중요도(feature importance) 값을 보고합니다.

이 기법은 랜덤 포레스트 특성 중요도를 사용해 하이퍼파라미터 공간을 탐색하는 방법을 개척한 [Fast.ai](https://fast.ai)의 [Jeremy Howard](https://twitter.com/jeremyphoward)와의 대화에서 영감을 받았습니다. 이 분석의 동기에 대해 더 알아보고 싶다면 이 [강의](https://course18.fast.ai/lessonsml1/lesson4.html)와 [노트](https://forums.fast.ai/t/wiki-lesson-thread-lesson-4/7540)를 꼭 확인해 보시기를 W&amp;B는 강력히 권장합니다.

하이퍼파라미터 중요도 패널은 강하게 상관관계가 있는 하이퍼파라미터들 사이의 복잡한 상호작용을 풀어내는 데 도움을 줍니다. 이를 통해 모델 성능을 예측하는 데 가장 중요한 하이퍼파라미터가 무엇인지 보여 줌으로써 하이퍼파라미터 탐색을 더 정교하게 튜닝할 수 있도록 도와줍니다.

<div id="creating-a-hyperparameter-importance-panel">
  ## 하이퍼파라미터 중요도 패널 생성하기
</div>

1. W&amp;B 프로젝트로 이동합니다.
2. **Add panels** 버튼을 클릭합니다.
3. **CHARTS** 드롭다운을 펼친 다음, **Parallel coordinates**를 선택합니다.

<Note>
  비어 있는 패널이 나타나면 실행이 그룹 해제되어 있는지 확인하세요.
</Note>

<Frame>
  <img src="/images/app_ui/hyperparameter_importance_panel.gif" alt="자동 파라미터 시각화" />
</Frame>

파라미터 매니저를 사용하면 표시할 파라미터와 숨길 파라미터를 수동으로 설정할 수 있습니다.

<Frame>
  <img src="/images/app_ui/hyperparameter_importance_panel_manual.gif" alt="표시 및 숨김 필드를 수동으로 설정하기" />
</Frame>

<div id="interpreting-a-hyperparameter-importance-panel">
  ## 하이퍼파라미터 중요도 패널 해석하기
</div>

<Frame>
  <img src="/images/general/parameter-importance-4.png" alt="특성 중요도 분석" />
</Frame>

이 패널은 학습 스크립트에서 [wandb.Run.config](/ko/models/track/config/) 객체에 전달된 모든 구성 파라미터를 보여줍니다. 또한 선택한 모델 지표(여기서는 `val_loss`)에 대해 이러한 config 파라미터의 특성 중요도와 상관관계를 표시합니다.

<div id="importance">
  ### 중요도
</div>

`importance` 열은 각 하이퍼파라미터가 선택한 메트릭을 예측하는 데 얼마나 유용했는지를 보여 줍니다. 아주 많은 하이퍼파라미터를 튜닝하면서, 이 플롯을 사용해 어떤 것들을 더 깊이 탐색할 가치가 있는지 좁혀 나가는 상황을 떠올려 보세요. 이후 스윕에서는 가장 중요한 하이퍼파라미터만 대상으로 제한하여, 더 빠르고 저렴하게 더 나은 모델을 찾을 수 있습니다.

<Note>
  W&amp;B는 선형 모델이 아니라 트리 기반 모델을 사용해 중요도를 계산합니다. 전자가 범주형 데이터와 정규화되지 않은 데이터 모두에 더 잘 대응할 수 있기 때문입니다.
</Note>

앞선 이미지에서 `epochs, learning_rate, batch_size`, `weight_decay`가 상당히 중요한 역할을 했음을 알 수 있습니다.

<div id="correlations">
  ### 상관관계
</div>

상관관계는 개별 하이퍼파라미터와 메트릭 값 사이의 선형 관계를 포착합니다. 예를 들어 SGD optimizer 사용 여부와 `val_loss` 사이에 유의미한 관계가 있는지(이 경우에는 있음)를 알려 줍니다. 상관계수 값은 -1에서 1 사이이며, 양수는 양의 선형 상관관계를, 음수는 음의 선형 상관관계를, 0은 상관관계가 없음을 의미합니다. 일반적으로 절댓값이 0.7을 넘으면 어느 방향이든 강한 상관관계로 간주합니다.

이 그래프를 사용해 메트릭과 더 높은 상관관계를 갖는 값들을 추가로 분석할 수 있습니다. 예를 들어 이 경우에는 rmsprop이나 nadam보다 stochastic gradient descent나 adam을 선택하거나, 학습 epoch 수를 늘리는 선택을 할 수 있습니다.

<Note>
  * 상관관계는 인과관계가 아니라 연관성이 있다는 증거만 보여 줍니다.
  * 상관관계는 이상치에 민감해서, 특히 시도한 하이퍼파라미터의 표본 수가 적을 때 강한 관계를 중간 정도의 관계로 보이게 만들 수 있습니다.
  * 마지막으로, 상관관계는 하이퍼파라미터와 메트릭 사이의 선형 관계만 포착합니다. 강한 다항식 관계가 있는 경우, 상관관계만으로는 포착되지 않습니다.
</Note>

중요도와 상관관계의 차이는, 중요도는 하이퍼파라미터들 사이의 상호작용을 고려하는 반면 상관관계는 개별 하이퍼파라미터가 메트릭 값에 미치는 영향만 측정한다는 점에서 비롯됩니다. 또한 상관관계는 오직 선형 관계만 포착하는 반면, 중요도는 더 복잡한 관계도 포착할 수 있습니다.

보시다시피 중요도와 상관관계는 모두 하이퍼파라미터가 모델 성능에 어떤 영향을 미치는지 이해하는 데 강력하고 유용한 도구입니다.