---
description: 모델의 하이퍼파라미터와 출력 메트릭 사이의 관계를 시각화합니다
title: 파라미터 중요도
---

하이퍼파라미터 중 어떤 것들이 메트릭의 바람직한 값과 가장 강한 상관관계와 예측력을 보였는지 확인할 수 있습니다.

<Frame>
  <img src="/images/general/parameter-importance-1.png" alt="파라미터 중요도 패널" />
</Frame>

**Correlation(상관관계)** 는 하이퍼파라미터와 선택한 메트릭(이 예에서는 val&#95;loss) 간의 선형 상관관계를 의미합니다. 상관관계가 높다는 것은 하이퍼파라미터 값이 커질 때 메트릭 값도 함께 커지고, 그 반대의 경우에도 마찬가지라는 뜻입니다. 상관관계는 살펴보기 좋은 메트릭이지만, 입력값들 간의 2차 상호작용을 포착하지 못하고, 범위가 크게 다른 입력들을 비교할 때는 해석이 복잡해질 수 있습니다.

그래서 W&amp;B는 **importance(중요도)** 메트릭도 계산합니다. W&amp;B는 하이퍼파라미터를 입력으로, 메트릭을 목표 출력으로 사용해 랜덤 포레스트를 학습시키고, 해당 랜덤 포레스트의 feature importance 값을 리포트합니다.

이 기법은 [Jeremy Howard](https://twitter.com/jeremyphoward)와의 대화에서 영감을 얻었습니다. 그는 [Fast.ai](https://fast.ai)에서 하이퍼파라미터 공간을 탐색하기 위해 랜덤 포레스트 feature importance를 활용하는 방법을 개척했습니다. W&amp;B는 이 분석의 동기에 대해 더 알고 싶다면 이 [강의](https://course18.fast.ai/lessonsml1/lesson4.html)와 이 [노트](https://forums.fast.ai/t/wiki-lesson-thread-lesson-4/7540)를 꼭 확인해 보시기를 강력히 추천합니다.

하이퍼파라미터 중요도 패널은 서로 높은 상관관계를 가진 하이퍼파라미터들 사이의 복잡한 상호작용을 풀어 줍니다. 이를 통해 어떤 하이퍼파라미터가 모델 성능을 예측하는 데 가장 중요한지를 보여 줌으로써, 하이퍼파라미터 탐색을 더 정교하게 조정하는 데 도움을 줍니다.

<div id="creating-a-hyperparameter-importance-panel">
  ## 하이퍼파라미터 중요도 패널 만들기
</div>

1. W&amp;B 프로젝트로 이동합니다.
2. **Add panels** 버튼을 클릭합니다.
3. **CHARTS** 드롭다운을 펼친 다음, 목록에서 **Parallel coordinates**를 선택합니다.

<Note>
  빈 패널이 나타나면 run이 그룹화되어 있지 않은지 확인하세요.
</Note>

<Frame>
  <img src="/images/app_ui/hyperparameter_importance_panel.gif" alt="하이퍼파라미터를 자동으로 시각화한 예시" />
</Frame>

파라미터 관리자를 사용하면 표시할/숨길 파라미터를 수동으로 설정할 수 있습니다.

<Frame>
  <img src="/images/app_ui/hyperparameter_importance_panel_manual.gif" alt="표시 및 숨김 필드를 수동으로 설정하는 예시" />
</Frame>

<div id="interpreting-a-hyperparameter-importance-panel">
  ## 하이퍼파라미터 중요도 패널 해석하기
</div>

<Frame>
  <img src="/images/general/parameter-importance-4.png" alt="Feature importance analysis" />
</Frame>

이 패널은 트레이닝 스크립트에서 [wandb.Run.config](/ko/models/track/config/) 객체에 전달된 모든 파라미터를 보여줍니다. 또한 선택한 모델 메트릭(이 경우 `val_loss`)에 대해 이러한 config 파라미터들의 피처 중요도와 상관관계를 보여줍니다.

<div id="importance">
  ### 중요도
</div>

중요도 열은 각 하이퍼파라미터가 선택한 메트릭을 예측하는 데 얼마나 유용했는지를 보여줍니다. 수많은 하이퍼파라미터를 튜닝하기 시작한 뒤, 이 플롯을 사용해 어떤 하이퍼파라미터를 더 심층적으로 탐색할 가치가 있는지 추려 간다고 상상해 보십시오. 이후의 스윕은 가장 중요한 하이퍼파라미터로 범위를 제한할 수 있고, 이를 통해 더 나은 모델을 더 빠르고 저렴하게 찾을 수 있습니다.

<Note>
  W&amp;B는 중요도를 계산할 때 선형 모델이 아니라 트리 기반 모델을 사용하는데, 트리 기반 모델이 범주형 데이터와 정규화되지 않은 데이터 모두에 더 잘 대응하기 때문입니다.
</Note>

앞의 이미지에서 `epochs, learning_rate, batch_size` 및 `weight_decay`가 상당히 중요한 하이퍼파라미터로 나타났음을 확인할 수 있습니다.

<div id="correlations">
  ### 상관관계
</div>

상관관계는 개별 하이퍼파라미터와 메트릭 값 사이의 선형 관계를 포착합니다. 예를 들어 SGD 옵티마이저 같은 하이퍼파라미터를 사용할 때와 `val_loss` 사이에 유의미한 관계가 있는지에 대한 질문에 답해 줍니다(이 예시에서는 관계가 있습니다). 상관계수 값은 -1에서 1까지의 범위를 가지며, 양수는 양의 선형 상관관계를, 음수는 음의 선형 상관관계를, 0은 상관관계가 없음을 나타냅니다. 일반적으로 절댓값이 0.7보다 크면 강한 상관관계가 있다고 봅니다.

이 그래프를 사용해 메트릭과 상관관계가 더 높은 값들을 추가로 탐색할 수 있습니다(이 경우 rmsprop이나 nadam 대신 stochastic gradient descent나 adam을 선택하거나), 혹은 더 많은 에포크 동안 학습을 진행할 수 있습니다.

<Note>
  * 상관관계는 인과관계가 아니라 연관성에 대한 근거만을 보여 줍니다.
  * 상관관계는 이상치에 민감해서, 특히 시도한 하이퍼파라미터의 표본 크기가 작은 경우 강한 관계를 중간 정도의 관계로 보이게 만들 수 있습니다.
  * 마지막으로, 상관관계는 하이퍼파라미터와 메트릭 사이의 선형 관계만을 포착합니다. 강한 다항식 관계가 있는 경우에는 상관관계로는 포착되지 않습니다.
</Note>

중요도와 상관관계 사이의 차이는, 중요도는 하이퍼파라미터 간 상호작용을 고려하지만 상관관계는 개별 하이퍼파라미터가 메트릭 값에 미치는 영향만을 측정한다는 사실에서 기인합니다. 또, 상관관계는 선형 관계만을 포착하는 반면 중요도는 더 복잡한 관계까지 포착할 수 있습니다.

보시는 것처럼, 중요도와 상관관계는 모두 하이퍼파라미터가 모델 성능에 어떤 영향을 미치는지 이해하는 데 매우 강력한 도구입니다.