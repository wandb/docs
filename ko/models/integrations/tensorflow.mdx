---
title: TensorFlow
---
import { ColabLink } from '/snippets/en/_includes/colab-link.mdx';

<ColabLink url="https://colab.research.google.com/drive/1JCpAbjkCFhYMT7LCQ399y35TS3jlMpvM" />

## 시작하기

이미 TensorBoard를 사용하고 계시다면, wandb와 쉽게 연동할 수 있습니다.

```python
import tensorflow as tf
import wandb
```

## 커스텀 메트릭 로그

TensorBoard에 기록되지 않는 추가적인 커스텀 메트릭을 로그해야 하는 경우, 코드에서 `run.log()`를 호출할 수 있습니다. `run.log({"custom": 0.8})`

Tensorboard를 동기화할 때 `run.log()`의 step 인수는 비활성화됩니다. 만약 다른 step 카운트를 설정하고 싶다면, 다음과 같이 step 메트릭과 함께 메트릭을 로그할 수 있습니다:

``` python
with wandb.init(config=tf.flags.FLAGS, sync_tensorboard=True) as run:
    run.log({"custom": 0.8, "global_step":global_step}, step=global_step)
```

## TensorFlow estimators 훅

로그되는 내용을 더 세밀하게 제어하고 싶은 경우, wandb는 TensorFlow estimators를 위한 훅 (hook)을 제공합니다. 이 훅은 그래프의 모든 `tf.summary` 값을 로그합니다.

```python
import tensorflow as tf
import wandb

run = wandb.init(config=tf.FLAGS)

# 1000 스텝마다 로그를 남기도록 설정
estimator.train(hooks=[wandb.tensorflow.WandbHook(steps_per_log=1000)])
run.finish()
```

## 수동으로 로그하기

TensorFlow에서 메트릭을 로그하는 가장 간단한 방법은 TensorFlow 로거를 사용하여 `tf.summary`를 로그하는 것입니다:

```python
import wandb
run = wandb.init(config=tf.flags.FLAGS, sync_tensorboard=True)
with tf.Session() as sess:
    # ...
    wandb.tensorflow.log(tf.summary.merge_all())
```

TensorFlow 2에서 커스텀 루프로 모델을 트레이닝하는 권장 방식은 `tf.GradientTape`를 사용하는 것입니다. 자세한 내용은 [TensorFlow 커스텀 트레이닝 가이드](https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough)에서 확인할 수 있습니다. 커스텀 TensorFlow 트레이닝 루프에 `wandb`를 통합하여 메트릭을 로그하려면 다음 스니펫을 참고하세요:

```python
    with tf.GradientTape() as tape:
        # 예측값 가져오기
        predictions = model(features)
        # 손실(loss) 계산
        loss = loss_func(labels, predictions)

    # 메트릭 로그
    run.log("loss": loss.numpy())
    # 그레이디언트 계산
    gradients = tape.gradient(loss, model.trainable_variables)
    # 가중치 업데이트
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
```

[TensorFlow 2에서 트레이닝 루프를 커스터마이징하는 전체 예제](https://www.wandb.com/articles/wandb-customizing-training-loops-in-tensorflow-2)도 확인할 수 있습니다.

## W&B는 TensorBoard와 어떻게 다른가요?

W&B의 공동 창립자들은 OpenAI에서 TensorBoard를 사용하며 불편함을 느꼈던 사용자들을 위해 이 툴을 개발하기 시작했습니다. 저희가 개선에 집중한 몇 가지 사항은 다음과 같습니다:

1. **모델 재현성**: W&B는 실험, 탐색 및 나중에 모델을 재현하는 데 탁월합니다. 메트릭뿐만 아니라 하이퍼파라미터와 코드의 버전도 캡처하며, 버전 관리 상태와 모델 체크포인트를 저장하여 프로젝트의 재현성을 보장합니다.
2. **자동 정리**: 협업자의 프로젝트를 이어받든, 휴가에서 복귀하든, 오래된 프로젝트를 다시 꺼내 보든, W&B를 사용하면 시도했던 모든 모델을 쉽게 확인할 수 있습니다. 따라서 누구도 실험을 재실행하며 시간, GPU 자원, 탄소를 낭비하지 않게 됩니다.
3. **빠르고 유연한 인테그레이션**: 5분 만에 프로젝트에 W&B를 추가하세요. 무료 오픈 소스 Python 패키지를 설치하고 코드에 몇 줄만 추가하면, 모델을 실행할 때마다 깔끔하게 정리된 메트릭 로그와 기록을 가질 수 있습니다.
4. **영구적이고 중앙 집중화된 대시보드**: 로컬 머신, 공용 랩 클러스터, 클라우드의 스팟 인스턴스 등 어디에서 모델을 트레이닝하든 결과는 동일한 중앙 집중식 대시보드에 공유됩니다. 여러 머신에서 TensorBoard 파일을 복사하고 정리하는 데 시간을 쓸 필요가 없습니다.
5. **강력한 테이블**: 다양한 모델의 결과를 검색, 필터링, 정렬 및 그룹화할 수 있습니다. 수천 개의 모델 버전을 훑어보고 각 태스크에 가장 적합한 모델을 쉽게 찾을 수 있습니다. TensorBoard는 대규모 프로젝트를 처리하도록 설계되지 않았습니다.
6. **협업을 위한 툴**: 복잡한 기계학습 프로젝트를 구성하는 데 W&B를 활용하세요. W&B 링크를 쉽게 공유할 수 있으며, 비공개 Teams를 만들어 모든 구성원이 공유 프로젝트로 결과를 보낼 수 있습니다. 또한 Reports를 통한 협업도 지원합니다. 대화형 시각화 자료를 추가하고 markdown으로 작업 내용을 설명할 수 있습니다. 이는 작업 로그를 유지하거나, 발견한 내용 (findings)을 관리자에게 공유하거나, 랩 또는 팀에 발표할 때 매우 유용한 방법입니다.

[무료 계정](https://wandb.ai)으로 시작해 보세요.

## 예제

인테그레이션이 어떻게 작동하는지 확인할 수 있는 몇 가지 예제를 준비했습니다:

* [Github 예제](https://github.com/wandb/examples/blob/master/examples/tensorflow/tf-estimator-mnist/mnist.py): TensorFlow Estimators를 사용한 MNIST 예제
* [Github 예제](https://github.com/wandb/examples/blob/master/examples/tensorflow/tf-cnn-fashion/train.py): 순수 TensorFlow를 사용한 Fashion MNIST 예제
* [Wandb Dashboard](https://app.wandb.ai/l2k2/examples-tf-estimator-mnist/runs/p0ifowcb): W&B에서 결과 보기
* TensorFlow 2에서 트레이닝 루프 커스터마이징하기 - [아티클](https://www.wandb.com/articles/wandb-customizing-training-loops-in-tensorflow-2) | [대시보드](https://app.wandb.ai/sayakpaul/custom_training_loops_tf)