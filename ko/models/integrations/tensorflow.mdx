---
title: TensorFlow
---

import { ColabLink } from '/snippets/ko/_includes/colab-link.mdx';

<ColabLink url="https://colab.research.google.com/drive/1JCpAbjkCFhYMT7LCQ399y35TS3jlMpvM" />


<div id="get-started">
  ## 시작하기
</div>

이미 TensorBoard를 사용 중이라면 wandb와 쉽게 통합할 수 있습니다.

```python
import tensorflow as tf
import wandb
```


<div id="log-custom-metrics">
  ## 사용자 정의 메트릭 로깅
</div>

TensorBoard로 기록되지 않는 추가 사용자 정의 메트릭이 필요한 경우 코드에서 `run.log()`를 호출하면 됩니다. 예: `run.log({"custom": 0.8})`

TensorBoard를 동기화할 때는 `run.log()`의 step 인수가 무시됩니다. 다른 step 값을 설정하려면 다음과 같이 step 메트릭과 함께 메트릭을 로깅할 수 있습니다:

```python
with wandb.init(config=tf.flags.FLAGS, sync_tensorboard=True) as run:
    run.log({"custom": 0.8, "global_step":global_step}, step=global_step)
```


<div id="tensorflow-estimators-hook">
  ## TensorFlow estimators hook
</div>

무엇을 기록할지 더 세밀하게 제어하려면, wandb는 TensorFlow estimator용 훅(hook)도 제공합니다. 이 훅은 그래프의 모든 `tf.summary` 값을 기록합니다.

```python
import tensorflow as tf
import wandb

run = wandb.init(config=tf.FLAGS)

estimator.train(hooks=[wandb.tensorflow.WandbHook(steps_per_log=1000)])
run.finish()
```


<div id="log-manually">
  ## 수동으로 로그 기록하기
</div>

TensorFlow에서 메트릭을 기록하는 가장 간단한 방법은 TensorFlow 로거를 사용하여 `tf.summary`를 로깅하는 것입니다:

```python
import wandb
run = wandb.init(config=tf.flags.FLAGS, sync_tensorboard=True)
with tf.Session() as sess:
    # ...
    wandb.tensorflow.log(tf.summary.merge_all())
```

TensorFlow 2에서는 사용자 정의 루프로 모델을 학습하는 권장 방법은 `tf.GradientTape`를 사용하는 것입니다. 자세한 내용은 [TensorFlow custom training walkthrough](https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough)를 참고하세요. 사용자 정의 TensorFlow 학습 루프에서 메트릭을 `wandb`로 로깅하려면 다음 코드 스니펫을 참고하세요:

```python
    with tf.GradientTape() as tape:
        # 확률 가져오기
        predictions = model(features)
        # 손실 계산
        loss = loss_func(labels, predictions)

    # 메트릭 기록
    run.log("loss": loss.numpy())
    # 그래디언트 가져오기
    gradients = tape.gradient(loss, model.trainable_variables)
    # 가중치 업데이트
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
```

[TensorFlow 2에서 학습 루프를 사용자 정의하는 전체 예제](https://www.wandb.com/articles/wandb-customizing-training-loops-in-tensorflow-2)를 확인할 수 있습니다.


<div id="how-is-wb-different-from-tensorboard">
  ## W&B는 TensorBoard와 어떻게 다른가요?
</div>

공동 창업자들이 W&B를 만들기 시작했을 때, OpenAI에서 TensorBoard에 답답함을 느끼던 사용자들을 위한 도구를 만들고자 하는 데서 출발했습니다. 그동안 특히 다음과 같은 부분을 개선하는 데 집중해 왔습니다:

1. **모델 재현**: W&B는 실험과 탐색, 그리고 나중에 모델을 다시 재현하는 데 적합합니다. 단순히 메트릭뿐 아니라 하이퍼파라미터와 코드 버전까지 함께 기록하고, 버전 관리 상태와 모델 체크포인트도 저장해 두어 프로젝트를 재현 가능하게 만듭니다.
2. **자동 정리**: 협업자의 프로젝트를 이어받을 때든, 휴가에서 돌아왔을 때든, 오래된 프로젝트를 다시 꺼낼 때든, W&B를 사용하면 지금까지 시도된 모든 모델을 한눈에 파악할 수 있어, 누구도 실험을 다시 돌리느라 시간, GPU 자원, 탄소를 낭비하지 않게 됩니다.
3. **빠르고 유연한 통합**: 5분 만에 W&B를 프로젝트에 추가하세요. 무료 오픈소스 Python 패키지를 설치하고 코드에 몇 줄만 추가하면, 모델을 실행할 때마다 메트릭과 기록이 깔끔하게 로깅됩니다.
4. **지속적이고 중앙화된 대시보드**: 로컬 머신, 공용 연구실 클러스터, 클라우드의 스팟 인스턴스 등 어디에서 모델을 학습하든 결과는 모두 동일한 중앙 대시보드로 공유됩니다. 여러 머신에서 생성된 TensorBoard 파일을 복사하고 정리하는 데 시간을 쓸 필요가 없습니다.
5. **강력한 테이블**: 서로 다른 모델의 결과를 검색, 필터링, 정렬, 그룹화할 수 있습니다. 수천 개의 모델 버전을 한눈에 살펴보고, 다양한 작업에 대해 성능이 가장 좋은 모델을 쉽게 찾을 수 있습니다. TensorBoard는 대규모 프로젝트에서 잘 동작하도록 설계되지 않았습니다.
6. **협업을 위한 도구**: W&B를 사용해 복잡한 머신러닝 프로젝트를 체계적으로 정리하세요. W&B 링크를 쉽게 공유할 수 있고, 비공개 팀을 사용해 모두가 결과를 공유 프로젝트로 전송하도록 할 수 있습니다. 또한 리포트를 통해 협업을 지원합니다. 인터랙티브한 시각화를 추가하고, Markdown으로 작업 내용을 설명할 수 있습니다. 이는 작업 로그를 남기고, 지도교수와 결과를 공유하거나, 연구실 혹은 팀에 결과를 발표하는 훌륭한 방법입니다.

[무료 계정](https://wandb.ai)으로 시작하세요

<div id="examples">
  ## 예제
</div>

연동이 어떻게 작동하는지 확인할 수 있도록 몇 가지 예제를 준비했습니다.

* [GitHub 예제](https://github.com/wandb/examples/blob/master/examples/tensorflow/tf-estimator-mnist/mnist.py): TensorFlow Estimator를 사용한 MNIST 예제
* [GitHub 예제](https://github.com/wandb/examples/blob/master/examples/tensorflow/tf-cnn-fashion/train.py): 순수 TensorFlow를 사용한 Fashion MNIST 예제
* [W&B 대시보드](https://app.wandb.ai/l2k2/examples-tf-estimator-mnist/runs/p0ifowcb): W&B에서 결과 보기
* TensorFlow 2에서 훈련 루프 커스터마이징 - [기사](https://www.wandb.com/articles/wandb-customizing-training-loops-in-tensorflow-2) | [대시보드](https://app.wandb.ai/sayakpaul/custom_training_loops_tf)