---
title: "Python 라이브러리에 W&B 추가하기"
decription: "실험 추적, 시스템 모니터링 및 모델 관리를 위해 Python 라이브러리에 W&B를 통합하기 위한 모범 사례."
---

import ApiKeyCreateStreamlined from "/snippets/ko/_includes/api-key-create-streamlined.mdx";

이 가이드는 Python 라이브러리에 Weights &amp; Biases(W&amp;B)를 통합하는 방법을 설명합니다.

학습 프레임워크, SDK, 재사용 가능한 라이브러리와 같이 복잡한 코드베이스에 W&amp;B를 통합하려는 경우 이 가이드의 권장 사항을 따르세요.

<Tip>
  W&amp;B가 처음이라면, 계속 읽기 전에 [Experiment Tracking](/ko/models/track/)과 같은 핵심 가이드를 먼저 살펴보기를 권장합니다.
</Tip>

아래에서는 여러분이 작업 중인 코드베이스가 단일 Python 학습 스크립트나 Jupyter 노트북보다 더 복잡할 때 유용한 주요 팁과 모범 사례를 다룹니다.

<div id="decide-how-users-install-wb">
  ## 사용자가 W&amp;B를 어떻게 설치하도록 할지 결정하기
</div>

시작하기 전에, 라이브러리에서 W&amp;B를 필수 의존성으로 포함할지, 선택적 기능으로 제공할지 결정하세요.

<div id="require-wb-as-a-dependency">
  ### W&amp;B를 필수 의존성으로 지정하기
</div>

라이브러리의 핵심 기능이 W&amp;B에 의존한다면, W&amp;B Python SDK(`wandb`)를 의존성에 추가하세요.

```txt
torch==1.8.0 
...
wandb==0.13.*
```

<div id="make-wb-optional-on-installation">
  ### 설치 시 W&amp;B를 선택 사항으로 만들기
</div>

W&amp;B가 선택적 기능이라면, W&amp;B가 설치되지 않은 상태에서도 라이브러리가 실행될 수 있도록 해야 합니다.

Python에서 `wandb`를 조건부로 import 하거나, `pyproject.toml`에서 선택적 의존성으로 선언할 수 있습니다.

<Tabs>
  <Tab title="Python">
    `wandb` 사용 가능 여부를 감지하고, 사용자가 W&amp;B 기능을 활성화했지만 설치하지 않은 경우 명확한 오류를 발생시킵니다:

    ```python
    try:
        import wandb
        _WANDB_AVAILABLE = True
    except ImportError:
        _WANDB_AVAILABLE = False
    ```
  </Tab>

  <Tab title="pyproject.toml">
    `pyproject.toml` 파일에서 `wandb`를 선택적 의존성으로 선언합니다:

    ```toml
    [project]
    name = "my_awesome_lib"
    version = "0.1.0"
    dependencies = [
        "torch",
        "sklearn"
    ]

    [project.optional-dependencies]
    dev = [
        "wandb"
    ]
    ```
  </Tab>
</Tabs>

<div id="authenticate-users">
  ## 사용자 인증
</div>

W&amp;B는 사용자와 머신을 인증하는 데 API 키를 사용합니다.

<div id="create-an-api-key">
  ### API 키 생성
</div>

API 키는 클라이언트나 머신을 W&amp;B에 인증하는 데 사용됩니다. 사용자 프로필에서 API 키를 생성할 수 있습니다.

<ApiKeyCreateStreamlined />

1. 화면 오른쪽 상단에서 사용자 프로필 아이콘을 클릭합니다.
2. **User Settings**를 선택한 다음, 아래로 스크롤하여 **API Keys** 섹션까지 이동합니다.

<div id="install-and-log-in-to-wb">
  ### W&amp;B 설치 및 로그인
</div>

로컬에서 `wandb` 라이브러리를 설치하고 로그인하려면:

<Tabs>
  <Tab title="커맨드 라인">
    1. `WANDB_API_KEY` [환경 변수](/ko/models/track/environment-variables/)를 자신의 API 키로 설정합니다:

       ```bash
       export WANDB_API_KEY=<your_api_key>
       ```

    2. `wandb` 라이브러리를 설치하고 로그인합니다:

       ```bash
       pip install wandb

       wandb login
       ```
  </Tab>

  <Tab title="Python">
    1. 터미널을 열고 Python SDK를 설치합니다.
       ```bash
       pip install wandb
       ```

    2. Python 스크립트나 노트북에서 W&amp;B에 로그인합니다. API 키를 입력하라는 프롬프트가 표시됩니다.
       ```python
       import wandb
       wandb.login()
       ```
  </Tab>

  <Tab title="Python 노트북">
    다음 코드 스니펫을 Jupyter 노트북의 셀에 복사해 붙여넣고 실행합니다. 그러면 API 키를 입력하라는 프롬프트가 표시됩니다.

    ```notebook
    !pip install wandb

    import wandb
    wandb.login()
    ```
  </Tab>
</Tabs>

<div id="start-a-run">
  ## 실행 시작하기
</div>

*실행*은 학습 실험과 같은 단일 계산 단위를 나타냅니다. 대부분의 라이브러리는 학습 작업(job)마다 하나의 실행을 생성합니다. 실행에 대한 자세한 내용은 [W&amp;B Runs](/ko/models/runs/)를 참조하세요.

[`wandb.init()`](/ko/models/ref/python/functions/init)으로 실행을 초기화하고 프로젝트 이름과 팀 엔터티(팀 이름)를 지정합니다. 프로젝트를 지정하지 않으면 W&amp;B는 실행을 기본 프로젝트인 &quot;uncategorized&quot;에 저장합니다.:

```python
with wandb.init(project="<project_name>", entity="<entity>") as run:
    ...
```

W&amp;B는 오류가 발생하더라도 실행이 정상적으로 종료되도록 컨텍스트 매니저를 사용할 것을 권장합니다. 컨텍스트 매니저를 사용하지 않는 경우, 실행을 종료하고 모든 데이터를 W&amp;B에 로깅하기 위해 `run.finish()`를 호출해야 합니다.

<Tip>
  **`wandb.init`을(를) 언제 호출해야 하나요**

  가능한 한 빨리 `wandb.init()`을 호출하세요. W&amp;B는 stdout, stderr, 그리고 오류 메시지를 캡처하므로 디버깅이 더 쉬워집니다.

  모든 관련 정보가 실행에 캡처되도록 전체 학습 루프를 `wandb.init` 컨텍스트 매니저로 감싸세요. 여기에는 디버깅에 매우 중요할 수 있는 오류 메시지도 포함됩니다.
</Tip>

<div id="set-wandb-as-an-optional-dependency">
  ### `wandb`를 선택적 의존성으로 설정하기
</div>

사용자가 라이브러리를 사용할 때 `wandb`를 선택적으로 사용할 수 있게 하려면, 다음 중 하나를 사용할 수 있습니다:

* 다음과 같이 `wandb` 플래그를 정의하거나:

<Tabs>
  <Tab title="Python">
    ```python
    trainer = my_trainer(..., use_wandb=True)
    ```
  </Tab>

  <Tab title="Bash">
    ```bash
    python train.py ... --use-wandb
    ```
  </Tab>
</Tabs>

* 또는 `wandb.init`에서 `wandb`를 `disabled`로 설정하거나:

<Tabs>
  <Tab title="Python">
    ```python
    wandb.init(mode="disabled")
    ```
  </Tab>

  <Tab title="Bash">
    ```bash
    export WANDB_MODE=disabled
    ```

    or

    ```bash
    wandb disabled
    ```
  </Tab>
</Tabs>

* 또는 `wandb`를 오프라인 모드로 설정할 수 있습니다. 이 경우에도 `wandb`는 실행되지만, 인터넷을 통해 W&amp;B와 통신을 시도하지 않습니다:

<Tabs>
  <Tab title="Environment Variable">
    ```bash
    export WANDB_MODE=offline
    ```

    or

    ```python
    os.environ['WANDB_MODE'] = 'offline'
    ```
  </Tab>

  <Tab title="Bash">
    ```bash
    wandb offline
    ```
  </Tab>
</Tabs>

<div id="define-a-run-config">
  ## 실행 config 정의하기
</div>

실행을 초기화할 때 config 딕셔너리를 제공하여 하이퍼파라미터와 기타 메타데이터를 W&amp;B에 로깅합니다.

W&amp;B App에서 실행의 config 파라미터를 기준으로 실행을 비교하고 Runs 테이블에서 필터링할 수 있습니다. 또한 이러한 파라미터를 사용하여 W&amp;B App에서 실행들을 그룹화할 수 있습니다.

예를 들어, 아래 이미지에서 배치 크기(bathch&#95;size)가 config 파라미터로 정의되어 있으며 Runs 테이블의 첫 번째 열에서 확인할 수 있습니다. 이렇게 하면 사용자가 배치 크기를 기준으로 실행을 필터링하고 비교할 수 있습니다:

<Frame>
  <img src="/images/integrations/integrations_add_any_lib_runs_page.png" alt="W&B Runs 테이블" />
</Frame>

일반적인 config 파라미터 값은 다음과 같습니다:

* 모델 이름, 버전, 아키텍처 파라미터, 하이퍼파라미터
* 데이터셋 이름, 버전, 학습 또는 검증 예제 개수
* 학습률, 배치 크기, 옵티마이저와 같은 학습 파라미터

다음 코드 스니펫은 config를 로깅하는 방법을 보여줍니다:

```python
config = {"batch_size": 32, ...}
with wandb.init(..., config=config) as run:
    ...
```

<div id="update-the-run-config">
  ### 실행 config 업데이트
</div>

초기화할 때 값을 알 수 없다면, 나중에 `wandb.Run.config.update`로 config를 업데이트하세요. 예를 들어, 모델을 인스턴스화한 후에 모델의 파라미터를 추가하고 싶을 수 있습니다.

```python
with wandb.init(...) as run:
    model = MyModel(...)
    run.config.update({"model_parameters": 3500})
```

자세한 내용은 [실험 구성](/ko/models/track/config/)을 참고하세요.

<div id="log-metrics-and-data">
  ## 메트릭 및 데이터 기록
</div>

<div id="log-metrics">
  ### 메트릭 기록
</div>

키가 메트릭 이름이 되도록 딕셔너리를 생성합니다. 이 딕셔너리 객체를 [`wandb.Run.log()`](/ko/models/ref/python/experiments/run#method-run-log)에 전달하여 W&amp;B에 기록합니다:

```python
NUM_EPOCHS = 10

for epoch in range(NUM_EPOCHS):
    for input, ground_truth in data: 
        prediction = model(input) 
        loss = loss_fn(prediction, ground_truth) 
        metrics = { "loss": loss } 
        run.log(metrics)
```

W&amp;B App에서 관련 메트릭을 그룹화하려면 메트릭 이름에 접두사를 사용하세요. 일반적인 접두사로는 학습 및 검증 메트릭에 사용하는 `train/`, `val/` 등이 있지만, 사용 사례에 맞는 어떤 접두사든 사용할 수 있습니다.

이렇게 하면 학습 및 검증 메트릭(또는 별도로 구분하고 싶은 다른 메트릭 유형)에 대해 프로젝트 Workspace 내에 각각 별도의 섹션이 생성됩니다:

```python
with wandb.init(...) as run:
    metrics = {
        "train/loss": 0.4,
        "train/learning_rate": 0.4,
        "val/loss": 0.5, 
        "val/accuracy": 0.7
    }
    run.log(metrics)
```

<Frame>
  <img src="/images/integrations/integrations_add_any_lib_log.png" alt="W&B Workspace" />
</Frame>

자세한 내용은 [`wandb.Run.log()`](/ko/models/ref/python/experiments/run#method-run-log)를 참조하세요.

<div id="control-the-x-axis">
  ### x축 제어
</div>

동일한 학습 스텝에 대해 `wandb.Run.log()`를 여러 번 호출하면 wandb SDK는 `wandb.Run.log()` 호출마다 내부 스텝 카운터를 증가시킵니다. 이 카운터는 학습 루프의 학습 스텝과 일치하지 않을 수 있습니다.

이러한 상황을 피하려면 `wandb.init`을 호출한 직후에 한 번만 `run.define_metric`으로 x축 스텝을 명시적으로 정의하세요:

```python
with wandb.init(...) as run:
    run.define_metric("*", step_metric="global_step")
```

글롭 패턴 `*`는 모든 메트릭이 차트에서 `global_step`을 x축으로 사용한다는 의미입니다. 특정 메트릭만 `global_step` 기준으로 로깅하고 싶다면, 해당 메트릭들만 다음과 같이 명시적으로 지정할 수 있습니다:

```python
run.define_metric("train/loss", step_metric="global_step")
```

이제 `wandb.Run.log()`를 호출할 때마다 각종 지표와 `step` 지표, `global_step`을 기록하세요:

```python
for step, (input, ground_truth) in enumerate(data):
    ...
    run.log({"global_step": step, "train/loss": 0.1})
    run.log({"global_step": step, "eval/loss": 0.2})
```

독립적인 step 변수에 접근할 수 없다면, 예를 들어 검증 루프 동안 &quot;global&#95;step&quot;에 접근할 수 없는 경우 wandb는 이전에 로깅된 &quot;global&#95;step&quot; 값을 자동으로 사용합니다. 이때 필요한 시점에 해당 메트릭이 이미 정의되어 있도록 초깃값을 먼저 로깅해 두었는지 확인하세요.

<div id="log-media-and-structured-data">
  ### 미디어와 구조화된 데이터 로깅하기
</div>

스칼라뿐만 아니라 이미지, 테이블, 텍스트, 오디오, 비디오 등도 로그로 남길 수 있습니다.

데이터를 로깅할 때는 다음 사항을 고려하세요.

* 메트릭을 얼마나 자주 기록할지, 선택적으로 기록할지를 결정합니다.
* 어떤 유형의 데이터가 시각화에 유용할지 고려합니다.
  * 이미지의 경우, 시간에 따른 변화를 확인할 수 있도록 샘플 예측 결과, 세그멘테이션 마스크 등을 기록할 수 있습니다.
  * 텍스트의 경우, 나중에 탐색할 수 있도록 샘플 예측을 테이블 형태로 기록할 수 있습니다.

예제는 [객체 및 미디어 로깅](/ko/models/track/log) 문서를 참고하세요.

<div id="support-distributed-training">
  ## 분산 학습 지원
</div>

분산 환경을 지원하는 프레임워크의 경우, 다음 워크플로 중 하나를 사용할 수 있습니다:

* main 프로세스에서만 로그를 기록합니다 (권장).
* 모든 프로세스에서 로그를 기록하고, 공유된 `group` 이름을 사용하여 실행을 그룹화합니다.

자세한 내용은 [Log Distributed Training Experiments](/ko/models/track/log/distributed-training/)를 참조하세요.

<div id="track-models-and-datasets-with-artifacts">
  ## 아티팩트로 모델과 데이터셋 추적하기
</div>

[W&amp;B Artifacts](/ko/models/artifacts/)를 사용해 모델과 데이터셋을 추적하고 버전 관리를 하십시오. Artifacts는 머신 러닝 자산에 대한 저장소와 버전 관리를 제공하며, 데이터와 모델 간의 연관 관계(lineage)를 자동으로 추적합니다.

<Frame>
  <img src="/images/integrations/integrations_add_any_lib_dag.png" alt="W&B에 저장된 데이터셋과 모델 체크포인트" />
</Frame>

라이브러리에 아티팩트를 통합할 때는 다음 사항을 고려하십시오:

* 모델 체크포인트나 데이터셋을 아티팩트로 로깅할지 여부(선택 사항으로 둘지 여부).
* 아티팩트 입력 참조(예: `entity/project/artifact`).
* 모델 체크포인트나 데이터셋을 로깅하는 주기(예: 매 에포크마다, 500 스텝마다 등).

<div id="log-model-checkpoints">
  ### 모델 체크포인트 로깅하기
</div>

모델 체크포인트를 W&amp;B에 로깅하세요. 일반적인 방법은 W&amp;B에서 생성한 고유 실행 ID를 아티팩트 이름에 포함해 체크포인트를 아티팩트로 로깅하는 것입니다.

```python
metadata = {"eval/accuracy": 0.8, "train/steps": 800} 

artifact = wandb.Artifact(
                name=f"model-{run.id}", 
                metadata=metadata, 
                type="model"
                ) 
artifact.add_dir("output_model") # 모델 가중치가 저장된 로컬 디렉터리

aliases = ["best", "epoch_10"] 
run.log_artifact(artifact, aliases=aliases)
```

앞의 코드 스니펫은 모델 체크포인트를 아티팩트로 로깅하고, 평가 정확도와 학습 단계와 같은 메타데이터를 추가하는 방법을 보여줍니다. 이 아티팩트에는 고유한 실행 ID가 포함된 이름이 지정되고, 쉽게 참조할 수 있도록 [사용자 지정 별칭](/ko/models/artifacts/create-a-custom-alias/) 태그가 추가됩니다.

<div id="log-input-artifacts">
  ### 입력 아티팩트 로깅
</div>

입력으로 사용한 데이터셋이나 사전 학습된 모델을 로깅합니다:

```python
dataset = wandb.Artifact(name="flowers", type="dataset")
dataset.add_file("flowers.npy")
run.use_artifact(dataset)
```

앞의 코드 스니펫은 &quot;flowers&quot;라는 데이터셋에 대한 아티팩트를 생성하고, 그 안에 파일을 추가합니다. 그런 다음 `run.use_artifact()`을 사용해 이 아티팩트를 현재 실행에 연결하면, W&amp;B가 해당 실행에서 사용된 데이터셋의 계보를 추적할 수 있습니다.

<div id="download-artifacts">
  ### 아티팩트 다운로드
</div>

학습 또는 추론 코드에서 사용하기 위해 W&amp;B에 이전에 로깅한 아티팩트를 다운로드합니다.

실행 컨텍스트가 있다면, [`wandb.Run.use_artifact()`](/ko/models/ref/python/experiments/run)를 사용해 W&amp;B의 아티팩트를 참조한 다음 [`wandb.Artifact.download()`](/ko/models/ref/python/experiments/artifact)를 호출해 로컬 디렉터리로 다운로드합니다.

```python
with wandb.init(...) as run:
    artifact = run.use_artifact("user/project/artifact:latest")
    local_path = artifact.download()
```

[W&amp;B Public API](/ko/models/ref/python/public-api/)를 사용하면 실행을 초기화하지 않고도 Artifact를 참조하거나 다운로드할 수 있습니다. 이는 분산 환경이나 추론을 수행할 때처럼 새 실행을 만들고 싶지 않은 상황에서 유용합니다.

```python
import wandb
artifact = wandb.Api().artifact("user/project/artifact:latest")
local_path = artifact.download()
```

자세한 내용은 [아티팩트 다운로드 및 사용](/ko/models/artifacts/download-and-use-an-artifact/) 문서를 참조하세요.

<div id="tune-hyper-parameters">
  ## 하이퍼파라미터 튜닝
</div>

라이브러리가 하이퍼파라미터 튜닝을 지원한다면, 실험을 관리하고 시각화하기 위해 [W&amp;B Sweeps](/ko/models/sweeps/)를 통합하여 사용할 수 있습니다.