---
title: Scikit-Learn
---

import ApiKeyCreateStreamlined from "/snippets/ko/_includes/api-key-create-streamlined.mdx";

wandb를 사용하면 간단한 코드 몇 줄만으로 scikit-learn 모델의 성능을 시각화하고 비교할 수 있습니다. [예제 살펴보기 →](https://wandb.me/scikit-colab)

<div id="get-started">
  ## 시작하기
</div>

<div id="sign-up-and-create-an-api-key">
  ### 가입 및 API 키 생성
</div>

API 키는 사용 중인 머신을 W&amp;B에 인증하는 데 사용됩니다. API 키는 사용자 프로필에서 생성할 수 있습니다.

<ApiKeyCreateStreamlined />

1. 오른쪽 상단에 있는 사용자 프로필 아이콘을 클릭합니다.
2. **User Settings**를 선택한 다음, 아래로 스크롤하여 **API Keys** 섹션으로 이동합니다.

<div id="install-the-wandb-library-and-log-in">
  ### `wandb` 라이브러리를 설치하고 로그인하기
</div>

로컬 환경에 `wandb` 라이브러리를 설치하고 로그인하려면:

<Tabs>
  <Tab title="명령줄">
    1. `WANDB_API_KEY` [환경 변수](/ko/models/track/environment-variables/)를 API 키 값으로 설정합니다.

       ```bash
       export WANDB_API_KEY=<your_api_key>
       ```

    2. `wandb` 라이브러리를 설치한 다음 로그인합니다.

       ```shell
       pip install wandb

       wandb login
       ```
  </Tab>

  <Tab title="Python">
    ```bash
    pip install wandb
    ```

    ```python
    import wandb
    wandb.login()
    ```
  </Tab>

  <Tab title="Python 노트북">
    ```notebook
    !pip install wandb

    import wandb
    wandb.login()
    ```
  </Tab>
</Tabs>

<div id="log-metrics">
  ### 메트릭 기록
</div>

```python
import wandb

wandb.init(project="visualize-sklearn") as run:

  y_pred = clf.predict(X_test)
  accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)

  # 시간 경과에 따라 메트릭을 로깅하는 경우 run.log를 사용하세요
  run.log({"accuracy": accuracy})

  # 또는 트레이닝 종료 시 최종 메트릭을 로깅하려면 run.summary를 사용할 수도 있습니다
  run.summary["accuracy"] = accuracy
```

<div id="make-plots">
  ### 플롯 생성하기
</div>

<div id="step-1-import-wandb-and-initialize-a-new-run">
  #### 1단계: wandb를 임포트하고 새 run을 초기화합니다
</div>

```python
import wandb

run = wandb.init(project="visualize-sklearn")
```

<div id="step-2-visualize-plots">
  #### 2단계: 플롯을 시각화하기
</div>

<div id="individual-plots">
  #### 개별 플롯
</div>

모델을 트레이닝하고 예측을 수행한 후에는 wandb에서 플롯을 생성해 예측 결과를 분석할 수 있습니다. 지원되는 차트의 전체 목록은 아래 **지원되는 플롯** 섹션을 참고하세요.

```python
# 단일 플롯 시각화
wandb.sklearn.plot_confusion_matrix(y_true, y_pred, labels)
```

<div id="all-plots">
  #### 모든 플롯
</div>

W&amp;B에는 `plot_classifier`와 같이 여러 관련 플롯을 한 번에 그려 주는 함수들이 있습니다:

```python
# 모든 분류기 플롯 시각화
wandb.sklearn.plot_classifier(
    clf,
    X_train,
    X_test,
    y_train,
    y_test,
    y_pred,
    y_probas,
    labels,
    model_name="SVC",
    feature_names=None,
)

# 모든 회귀 플롯
wandb.sklearn.plot_regressor(reg, X_train, X_test, y_train, y_test, model_name="Ridge")

# 모든 클러스터링 플롯
wandb.sklearn.plot_clusterer(
    kmeans, X_train, cluster_labels, labels=None, model_name="KMeans"
)

run.finish()
```

<div id="existing-matplotlib-plots">
  #### 기존 Matplotlib 플롯
</div>

Matplotlib에서 생성한 플롯도 W&amp;B 대시보드에 로깅할 수 있습니다. 이를 위해 먼저 `plotly`를 설치해야 합니다.

```bash
pip install plotly
```

마지막으로 플롯을 다음과 같이 W&amp;B 대시보드에 로깅할 수 있습니다.

```python
import matplotlib.pyplot as plt
import wandb

with wandb.init(project="visualize-sklearn") as run:

  # plt.plot(), plt.scatter() 등을 여기서 모두 수행합니다.
  # ...

  # plt.show() 대신 다음을 실행합니다:
  run.log({"plot": plt})
```

<div id="supported-plots">
  ## 지원되는 그래프
</div>

<div id="learning-curve">
  ### 러닝 커브
</div>

<Frame>
  <img src="/images/integrations/scikit_learning_curve.png" alt="Scikit-learn 러닝 커브" />
</Frame>

크기가 서로 다른 데이터셋으로 모델을 트레이닝하고, 트레이닝 및 테스트 세트 각각에 대해 교차 검증 점수와 데이터셋 크기의 관계를 나타내는 플롯을 생성합니다.

`wandb.sklearn.plot_learning_curve(model, X, y)`

* model (clf or reg): 학습된 회귀기 또는 분류기를 전달합니다.
* X (arr): 데이터셋 특징.
* y (arr): 데이터셋 레이블.

<div id="roc">
  ### ROC
</div>

<Frame>
  <img src="/images/integrations/scikit_roc.png" alt="Scikit-learn ROC 곡선" />
</Frame>

ROC 곡선은 참양성률(TPR, y축)을 거짓양성률(FPR, x축)에 대해 나타낸 것입니다. 이상적인 점수는 TPR = 1, FPR = 0으로, 왼쪽 상단의 점에 해당합니다. 일반적으로 ROC 곡선 아래 면적(AUC-ROC)을 계산하며, AUC-ROC 값이 클수록 더 좋습니다.

`wandb.sklearn.plot_roc(y_true, y_probas, labels)`

* y&#95;true (arr): 테스트 세트의 레이블.
* y&#95;probas (arr): 테스트 세트의 예측 확률.
* labels (list): 타깃 변수(y)의 이름이 지정된 레이블.

<div id="class-proportions">
  ### 클래스 비율
</div>

<Frame>
  <img src="/images/integrations/scikic_class_props.png" alt="Scikit-learn classification properties" />
</Frame>

트레이닝 및 테스트 세트에서 타깃 클래스의 분포를 시각화합니다. 불균형 클래스를 탐지하고 하나의 클래스가 모델에 과도한 영향을 미치지 않는지 확인하는 데 유용합니다.

`wandb.sklearn.plot_class_proportions(y_train, y_test, ['dog', 'cat', 'owl'])`

* y&#95;train (arr): 트레이닝 세트 레이블.
* y&#95;test (arr): 테스트 세트 레이블.
* labels (list): 타깃 변수(y)에 대한 이름이 지정된 레이블.

<div id="precision-recall-curve">
  ### 정밀도-재현율 곡선
</div>

<Frame>
  <img src="/images/integrations/scikit_precision_recall.png" alt="Scikit-learn 정밀도-재현율 곡선" />
</Frame>

서로 다른 임곗값에 대해 정밀도와 재현율 사이의 트레이드오프를 계산합니다. 곡선 아래 면적이 클수록 재현율과 정밀도가 모두 높다는 의미입니다. 여기서 높은 정밀도는 낮은 거짓 양성률과, 높은 재현율은 낮은 거짓 음성률과 관련됩니다.

두 값이 모두 높으면 분류기가 정확한 결과(높은 정밀도)를 반환하면서, 전체 양성 사례의 대부분을 찾아내고 있음을 의미합니다(높은 재현율). PR 곡선은 클래스 불균형이 심할 때 특히 유용합니다.

`wandb.sklearn.plot_precision_recall(y_true, y_probas, labels)`

* y&#95;true (arr): 테스트 세트의 레이블.
* y&#95;probas (arr): 테스트 세트의 예측 확률.
* labels (list): 타깃 변수(y)에 대한 레이블 이름 목록.

<div id="feature-importances">
  ### 특성 중요도
</div>

<Frame>
  <img src="/images/integrations/scikit_feature_importances.png" alt="Scikit-learn 특성 중요도 차트" />
</Frame>

분류 작업에서 각 특성의 중요도를 평가하고 시각화합니다. 트리처럼 `feature_importances_` 속성을 가진 분류기에서만 사용할 수 있습니다.

`wandb.sklearn.plot_feature_importances(model, ['width', 'height, 'length'])`

* model (clf): 적합(fit)이 완료된 분류기를 입력합니다.
* feature&#95;names (list): 특성 이름입니다. 특성 인덱스를 해당 이름으로 대체하여 플롯을 더 읽기 쉽게 만듭니다.

<div id="calibration-curve">
  ### 캘리브레이션 곡선 (Calibration curve)
</div>

<Frame>
  <img src="/images/integrations/scikit_calibration_curve.png" alt="Scikit-learn calibration curve" />
</Frame>

분류기의 예측 확률이 얼마나 잘 보정(calibration)되어 있는지, 그리고 보정되지 않은 분류기를 어떻게 보정할 수 있는지를 보여 줍니다. 기준 로지스틱 회귀 모델, 인자로 전달한 모델, 그리고 해당 모델에 대한 isotonic 보정과 sigmoid 보정을 통해 추정된 예측 확률을 비교합니다.

캘리브레이션 곡선이 대각선에 가까울수록 더 좋습니다. 좌우가 뒤집힌 시그모이드 모양의 곡선은 과적합된 분류기를, 시그모이드 모양의 곡선은 과소적합된 분류기를 나타냅니다. 모델에 대해 isotonic 및 sigmoid 보정을 학습하고 그 곡선을 비교하면, 모델이 과적합 또는 과소적합인지, 그리고 그렇다면 어떤 보정 방식(sigmoid 또는 isotonic)이 이를 개선하는 데 도움이 될지 파악할 수 있습니다.

자세한 내용은 [sklearn 문서](https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html)를 참고하세요.

`wandb.sklearn.plot_calibration_curve(clf, X, y, 'RandomForestClassifier')`

* model (clf): 학습이 완료된 분류기를 입력으로 받습니다.
* X (arr): 트레이닝 세트의 특성.
* y (arr): 트레이닝 세트의 레이블.
* model&#95;name (str): 모델 이름. 기본값은 &#39;Classifier&#39;입니다.

<div id="confusion-matrix">
  ### Confusion matrix
</div>

<Frame>
  <img src="/images/integrations/scikit_confusion_matrix.png" alt="Scikit-learn confusion matrix" />
</Frame>

분류 모델의 정확도를 평가하기 위해 혼동 행렬(confusion matrix)을 계산합니다. 이는 모델 예측의 품질을 평가하고, 모델이 틀린 예측에서 패턴을 찾는 데 유용합니다. 대각선은 실제 레이블과 예측 레이블이 같은, 모델이 올바르게 예측한 경우를 나타냅니다.

`wandb.sklearn.plot_confusion_matrix(y_true, y_pred, labels)`

* y&#95;true (arr): 테스트 세트 레이블.
* y&#95;pred (arr): 테스트 세트 예측 레이블.
* labels (list): 타깃 변수(y)에 대한 이름이 지정된 레이블.

<div id="summary-metrics">
  ### 요약 메트릭
</div>

<Frame>
  <img src="/images/integrations/scikit_summary_metrics.png" alt="Scikit-learn 요약 메트릭" />
</Frame>

* `mse`, `mae`, `r2` 점수와 같은 회귀용 요약 메트릭을 계산합니다.
* `f1`, accuracy, precision, recall과 같은 분류용 요약 메트릭을 계산합니다.

`wandb.sklearn.plot_summary_metrics(model, X_train, y_train, X_test, y_test)`

* model (clf 또는 reg): 학습이 완료된 회귀기 또는 분류기를 입력합니다.
* X (arr): 트레이닝 세트 피처.
* y (arr): 트레이닝 세트 레이블.
  * X&#95;test (arr): 테스트 세트 피처.
* y&#95;test (arr): 테스트 세트 레이블.

<div id="elbow-plot">
  ### 엘보 플롯
</div>

<Frame>
  <img src="/images/integrations/scikit_elbow_plot.png" alt="Scikit-learn 엘보 플롯" />
</Frame>

클러스터 개수에 따른 설명 분산 비율을 트레이닝 시간과 함께 측정하고 시각화합니다. 최적의 클러스터 개수를 선택할 때 유용합니다.

`wandb.sklearn.plot_elbow_curve(model, X_train)`

* model (clusterer): 피팅된 클러스터러를 받습니다.
* X (arr): 트레이닝 세트 특성입니다.

<div id="silhouette-plot">
  ### 실루엣 플롯
</div>

<Frame>
  <img src="/images/integrations/scikit_silhouette_plot.png" alt="Scikit-learn 실루엣 플롯" />
</Frame>

각 클러스터 안의 각 점이 이웃 클러스터의 점들과 얼마나 가까운지를 측정하고 시각화합니다. 클러스터의 두께는 클러스터 크기에 비례합니다. 세로선은 모든 점의 평균 실루엣 점수를 나타냅니다.

실루엣 계수가 +1에 가까울수록 해당 샘플이 이웃 클러스터로부터 멀리 떨어져 있음을 의미합니다. 값이 0이면 샘플이 두 이웃 클러스터 사이의 결정 경계 위나 그 근처에 있음을 의미하고, 음수 값은 해당 샘플이 잘못된 클러스터에 할당되었을 가능성을 나타냅니다.

일반적으로 모든 실루엣 클러스터 점수가 평균 이상(빨간 선을 지난 값)이고, 1에 최대한 가깝기를 기대합니다. 또한 데이터의 근본적인 패턴을 잘 반영하는 클러스터 크기를 선호합니다.

`wandb.sklearn.plot_silhouette(model, X_train, ['spam', 'not spam'])`

* model (clusterer): 학습이 완료된 클러스터링 모델을 입력으로 받습니다.
* X (arr): 트레이닝 세트 특성입니다.
  * cluster&#95;labels (list): 클러스터 레이블의 이름입니다. 클러스터 인덱스를 해당 이름으로 바꿔 플롯을 더 읽기 쉽게 만듭니다.

<div id="outlier-candidates-plot">
  ### 이상치 후보 플롯
</div>

<Frame>
  <img src="/images/integrations/scikit_outlier_plot.png" alt="Scikit-learn 이상치 플롯" />
</Frame>

Cook&#39;s distance를 사용해 회귀 모델에서 각 데이터 포인트의 영향력을 측정합니다. 영향력이 심하게 치우친 인스턴스는 잠재적으로 이상치일 수 있습니다. 이상치 탐지에 유용합니다.

`wandb.sklearn.plot_outlier_candidates(model, X, y)`

* model (regressor): 학습이 완료된 회귀 모델을 입력합니다.
* X (arr): 트레이닝 세트 특성입니다.
* y (arr): 트레이닝 세트 레이블입니다.

<div id="residuals-plot">
  ### 잔차 플롯
</div>

<Frame>
  <img src="/images/integrations/scikit_residuals_plot.png" alt="Scikit-learn 잔차 플롯" />
</Frame>

예측된 타깃 값( y축 )과 실제 타깃 값과 예측된 타깃 값의 차이( x축 )를 측정하고 플롯하며, 잔차 오차의 분포도 함께 시각화합니다.

일반적으로 잘 적합된 모델의 잔차는 무작위로 분포하는 경향이 있습니다. 좋은 모델은 데이터셋에서 무작위 오차를 제외한 대부분의 현상을 설명하기 때문입니다.

`wandb.sklearn.plot_residuals(model, X, y)`

* model (regressor): 학습이 완료된 분류기를 입력으로 받습니다.
* X (arr): 트레이닝 세트 특성입니다.
* y (arr): 트레이닝 세트 레이블입니다.

  궁금한 점이 있으면 언제든지 [Slack 커뮤니티](https://wandb.me/slack)에서 질문해 주세요.

<div id="example">
  ## 예시
</div>

* [Run in colab](https://wandb.me/scikit-colab): 빠르게 시작할 수 있는 간단한 노트북입니다.