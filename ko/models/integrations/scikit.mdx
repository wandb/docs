---
title: Scikit-Learn
---

import ApiKeyCreateStreamlined from "/snippets/ko/_includes/api-key-create-streamlined.mdx";

코드 몇 줄만으로 wandb를 사용하여 scikit-learn 모델의 성능을 시각화하고 비교할 수 있습니다. [예제 살펴보기 →](https://wandb.me/scikit-colab)

<div id="get-started">
  ## 시작하기
</div>

<div id="sign-up-and-create-an-api-key">
  ### 가입 및 API 키 생성
</div>

API 키는 사용 중인 머신을 W&amp;B에 인증하는 데 사용됩니다. API 키는 사용자 프로필에서 생성할 수 있습니다.

<ApiKeyCreateStreamlined />

1. 오른쪽 상단에서 사용자 프로필 아이콘을 클릭합니다.
2. **User Settings**를 선택한 다음, 아래로 스크롤하여 **API Keys** 섹션으로 이동합니다.

<div id="install-the-wandb-library-and-log-in">
  ### `wandb` 라이브러리 설치 및 로그인
</div>

로컬 환경에 `wandb` 라이브러리를 설치하고 로그인하려면 다음을 수행합니다.

<Tabs>
  <Tab title="Command Line">
    1. `WANDB_API_KEY` [환경 변수](/ko/models/track/environment-variables/)에 API 키를 설정합니다.

       ```bash
       export WANDB_API_KEY=<your_api_key>
       ```

    2. `wandb` 라이브러리를 설치한 다음 로그인합니다.

       ```shell
       pip install wandb

       wandb login
       ```
  </Tab>

  <Tab title="Python">
    ```bash
    pip install wandb
    ```

    ```python
    import wandb
    wandb.login()
    ```
  </Tab>

  <Tab title="Python notebook">
    ```notebook
    !pip install wandb

    import wandb
    wandb.login()
    ```
  </Tab>
</Tabs>

<div id="log-metrics">
  ### 메트릭 로깅
</div>

```python
import wandb

wandb.init(project="visualize-sklearn") as run:

  y_pred = clf.predict(X_test)
  accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)

  # 시간 경과에 따라 메트릭을 로깅하려면 run.log를 사용하세요
  run.log({"accuracy": accuracy})

  # 또는 학습 종료 시 최종 메트릭을 로깅하려면 run.summary를 사용할 수도 있습니다
  run.summary["accuracy"] = accuracy
```

<div id="make-plots">
  ### 플롯 생성하기
</div>

<div id="step-1-import-wandb-and-initialize-a-new-run">
  #### 1단계: wandb를 import하고 새 실행을 초기화하기
</div>

```python
import wandb

run = wandb.init(project="visualize-sklearn")
```

<div id="step-2-visualize-plots">
  #### 2단계: 플롯 시각화하기
</div>

<div id="individual-plots">
  #### 개별 플롯
</div>

모델을 학습하고 예측을 수행한 후, 예측 결과를 분석하기 위해 wandb에서 플롯을 생성할 수 있습니다. 지원되는 차트의 전체 목록은 아래 **Supported Plots** 섹션을 참조하세요.

```python
# 단일 플롯 시각화
wandb.sklearn.plot_confusion_matrix(y_true, y_pred, labels)
```

<div id="all-plots">
  #### 모든 플롯
</div>

W&amp;B에는 `plot_classifier`와 같이 여러 관련 플롯을 한 번에 그려 주는 함수들이 있습니다.

```python
# 모든 분류기 플롯 시각화
wandb.sklearn.plot_classifier(
    clf,
    X_train,
    X_test,
    y_train,
    y_test,
    y_pred,
    y_probas,
    labels,
    model_name="SVC",
    feature_names=None,
)

# 모든 회귀 플롯
wandb.sklearn.plot_regressor(reg, X_train, X_test, y_train, y_test, model_name="Ridge")

# 모든 클러스터링 플롯
wandb.sklearn.plot_clusterer(
    kmeans, X_train, cluster_labels, labels=None, model_name="KMeans"
)

run.finish()
```

<div id="existing-matplotlib-plots">
  #### 기존 Matplotlib 플롯
</div>

Matplotlib에서 생성한 플롯도 W&amp;B 대시보드에 로깅할 수 있습니다. 이를 위해 먼저 `plotly`를 설치해야 합니다.

```bash
pip install plotly
```

마지막으로, 다음과 같이 플롯을 W&amp;B 대시보드에 로그할 수 있습니다:

```python
import matplotlib.pyplot as plt
import wandb

with wandb.init(project="visualize-sklearn") as run:

  # plt.plot(), plt.scatter() 등을 여기서 모두 실행합니다.
  # ...

  # plt.show() 대신 다음을 실행합니다:
  run.log({"plot": plt})
```

<div id="supported-plots">
  ## 지원되는 플롯 유형
</div>

<div id="learning-curve">
  ### 학습 곡선
</div>

<Frame>
  <img src="/images/integrations/scikit_learning_curve.png" alt="Scikit-learn 학습 곡선" />
</Frame>

서로 다른 크기의 데이터셋으로 모델을 학습하고, 학습 및 테스트 세트에 대해 데이터셋 크기 대비 교차 검증 점수의 관계를 나타내는 플롯을 생성합니다.

`wandb.sklearn.plot_learning_curve(model, X, y)`

* model (clf 또는 reg): 학습이 완료된 회귀기(regressor) 또는 분류기(classifier)를 전달합니다.
* X (arr): 데이터셋 특성(feature)입니다.
* y (arr): 데이터셋 레이블(label)입니다.

<div id="roc">
  ### ROC
</div>

<Frame>
  <img src="/images/integrations/scikit_roc.png" alt="Scikit-learn ROC curve" />
</Frame>

ROC 곡선은 y축에 실제 양성 비율(true positive rate, TPR), x축에 거짓 양성 비율(false positive rate, FPR)을 나타낸 곡선입니다. 이상적인 점수는 TPR = 1, FPR = 0인 경우이며, 이는 왼쪽 상단 지점에 해당합니다. 일반적으로 ROC 곡선 아래 면적(AUC-ROC)을 계산하며, AUC-ROC 값이 클수록 더 좋습니다.

`wandb.sklearn.plot_roc(y_true, y_probas, labels)`

* y&#95;true (arr): 테스트 세트의 레이블.
* y&#95;probas (arr): 테스트 세트의 예측 확률.
* labels (list): 타깃 변수(y)의 이름이 지정된 레이블.

<div id="class-proportions">
  ### 클래스 비율
</div>

<Frame>
  <img src="/images/integrations/scikic_class_props.png" alt="Scikit-learn 분류 속성" />
</Frame>

학습 및 테스트 세트에서 타깃 클래스의 분포를 그립니다. 클래스 불균형을 탐지하고, 하나의 클래스가 모델에 과도한 영향을 미치지 않도록 하는 데 유용합니다.

`wandb.sklearn.plot_class_proportions(y_train, y_test, ['dog', 'cat', 'owl'])`

* y&#95;train (arr): 학습 세트 레이블.
* y&#95;test (arr): 테스트 세트 레이블.
* labels (list): 타깃 변수(y)의 각 클래스에 대한 이름 레이블.

<div id="precision-recall-curve">
  ### 정밀도-재현율 곡선
</div>

<Frame>
  <img src="/images/integrations/scikit_precision_recall.png" alt="Scikit-learn 정밀도-재현율 곡선" />
</Frame>

서로 다른 임계값에 대해 정밀도와 재현율 간의 트레이드오프를 계산합니다. 곡선 아래 면적(AUC)이 높다는 것은 재현율과 정밀도가 모두 높다는 의미이며, 높은 정밀도는 낮은 거짓 양성 비율과 관련되고, 높은 재현율은 낮은 거짓 음성 비율과 관련됩니다.

두 점수 모두 높다면 분류기가 정확한 결과를 반환할 뿐만 아니라(높은 정밀도), 전체 양성 결과의 대부분을 반환하고 있다는 것(높은 재현율)을 나타냅니다. PR 곡선은 클래스 불균형이 심할 때 특히 유용합니다.

`wandb.sklearn.plot_precision_recall(y_true, y_probas, labels)`

* y&#95;true (arr): 테스트 세트의 레이블.
* y&#95;probas (arr): 테스트 세트의 예측 확률.
* labels (list): 타깃 변수(y)에 대한 레이블 이름 목록.

<div id="feature-importances">
  ### 특성 중요도
</div>

<Frame>
  <img src="/images/integrations/scikit_feature_importances.png" alt="Scikit-learn 특성 중요도 차트" />
</Frame>

분류 작업에서 각 특성의 중요도를 평가하고 이를 플롯으로 시각화합니다. 트리 모델처럼 `feature_importances_` 속성을 가진 분류기에서만 사용할 수 있습니다.

`wandb.sklearn.plot_feature_importances(model, ['width', 'height, 'length'])`

* model (clf): 학습이 완료된 분류기를 입력으로 받습니다.
* feature&#95;names (list): 특성 이름 목록입니다. 특성 인덱스를 해당 이름으로 대체하여 플롯을 더 쉽게 읽을 수 있게 해 줍니다.

<div id="calibration-curve">
  ### 캘리브레이션 커브
</div>

<Frame>
  <img src="/images/integrations/scikit_calibration_curve.png" alt="Scikit-learn calibration curve" />
</Frame>

분류기의 예측 확률이 얼마나 잘 캘리브레이션(calibrated)되어 있는지와, 캘리브레이션되지 않은 분류기를 어떻게 캘리브레이션할 수 있는지를 시각화합니다. 베이스라인 로지스틱 회귀 모델, 인자로 전달된 모델, 그리고 해당 모델에 대한 isotonic 캘리브레이션과 sigmoid 캘리브레이션이 추정한 예측 확률을 비교합니다.

캘리브레이션 커브가 대각선에 가까울수록 더 좋습니다. 전치된(transposed) 시그모이드 형태의 곡선은 과적합된 분류기를 나타내고, 시그모이드 형태의 곡선은 과소적합된 분류기를 나타냅니다. 모델에 대해 isotonic 및 sigmoid 캘리브레이션을 학습시키고 그 곡선을 비교하면, 모델이 과적합인지 과소적합인지, 그리고 그렇다면 어떤 캘리브레이션(sigmoid 또는 isotonic)이 이를 개선하는 데 도움이 될지 파악할 수 있습니다.

자세한 내용은 [sklearn 문서](https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html)를 참고하세요.

`wandb.sklearn.plot_calibration_curve(clf, X, y, 'RandomForestClassifier')`

* model (clf): 학습이 완료된 분류기를 입력합니다.
* X (arr): 학습 데이터셋의 특성(feature)입니다.
* y (arr): 학습 데이터셋의 레이블(label)입니다.
* model&#95;name (str): 모델 이름입니다. 기본값은 &#39;Classifier&#39;입니다.

<div id="confusion-matrix">
  ### 혼동 행렬
</div>

<Frame>
  <img src="/images/integrations/scikit_confusion_matrix.png" alt="Scikit-learn 혼동 행렬" />
</Frame>

분류의 정확도를 평가하기 위해 혼동 행렬을 계산합니다. 모델 예측의 품질을 평가하고, 모델이 오답을 내는 예측에서 패턴을 찾는 데 유용합니다. 대각선은 실제 레이블과 예측 레이블이 같은, 모델이 정확하게 예측한 경우를 나타냅니다.

`wandb.sklearn.plot_confusion_matrix(y_true, y_pred, labels)`

* y&#95;true (arr): 테스트 세트 레이블.
* y&#95;pred (arr): 테스트 세트 예측 레이블.
* labels (list): 타깃 변수(y)의 레이블 이름 목록.

<div id="summary-metrics">
  ### 요약 지표
</div>

<Frame>
  <img src="/images/integrations/scikit_summary_metrics.png" alt="Scikit-learn 요약 지표" />
</Frame>

* 분류에 대한 요약 지표(예: `mse`, `mae`, `r2` 점수)를 계산합니다.
* 회귀에 대한 요약 지표(예: `f1`, 정확도, 정밀도, 재현율)를 계산합니다.

`wandb.sklearn.plot_summary_metrics(model, X_train, y_train, X_test, y_test)`

* model (clf 또는 reg): 학습된 회귀 모델 또는 분류 모델을 입력받습니다.
* X (arr): 학습 세트 피처.
* y (arr): 학습 세트 레이블.
  * X&#95;test (arr): 테스트 세트 피처.
* y&#95;test (arr): 테스트 세트 레이블.

<div id="elbow-plot">
  ### 엘보 플롯
</div>

<Frame>
  <img src="/images/integrations/scikit_elbow_plot.png" alt="Scikit-learn 엘보 플롯" />
</Frame>

클러스터 수에 따른 설명된 분산의 비율과 학습 시간을 함께 측정하고 그래프로 표시합니다. 최적의 클러스터 개수를 선택할 때 유용합니다.

`wandb.sklearn.plot_elbow_curve(model, X_train)`

* model (clusterer): 학습이 완료된 클러스터링 모델입니다.
* X (arr): 학습 데이터셋의 특성(feature)입니다.

<div id="silhouette-plot">
  ### 실루엣 플롯
</div>

<Frame>
  <img src="/images/integrations/scikit_silhouette_plot.png" alt="Scikit-learn 실루엣 플롯" />
</Frame>

각 클러스터의 포인트가 인접 클러스터의 포인트와 얼마나 가까운지를 측정하고 시각화합니다. 클러스터의 두께는 클러스터 크기를 나타냅니다. 수직선은 모든 포인트의 평균 실루엣 점수를 나타냅니다.

실루엣 계수가 +1에 가까울수록 해당 샘플은 인접 클러스터로부터 멀리 떨어져 있음을 의미합니다. 값이 0이면 샘플이 두 인접 클러스터 사이의 결정 경계 위에 있거나 그 근처에 있음을 의미하며, 음수 값은 해당 샘플이 잘못된 클러스터에 할당되었을 수 있음을 나타냅니다.

일반적으로 모든 실루엣 클러스터 점수가 평균 이상(빨간 선을 지난 상태)이면서 1에 최대한 가깝기를 원합니다. 또한 데이터에 내재된 패턴을 잘 반영하는 클러스터 크기를 선호합니다.

`wandb.sklearn.plot_silhouette(model, X_train, ['spam', 'not spam'])`

* model (clusterer): 학습이 완료된 클러스터러를 입력으로 받습니다.
* X (arr): 학습 데이터의 특성입니다.
  * cluster&#95;labels (list): 클러스터 레이블의 이름입니다. 클러스터 인덱스를 해당 이름으로 대체하여 플롯을 더 읽기 쉽게 만듭니다.

<div id="outlier-candidates-plot">
  ### 이상치 후보 플롯
</div>

<Frame>
  <img src="/images/integrations/scikit_outlier_plot.png" alt="Scikit-learn 이상치 플롯" />
</Frame>

Cook 거리(Cook&#39;s distance)를 사용해 회귀 모델에서 각 데이터 포인트가 미치는 영향력을 측정합니다. 영향력이 크게 치우친 인스턴스는 잠재적으로 이상치일 수 있습니다. 이상치 탐지에 유용합니다.

`wandb.sklearn.plot_outlier_candidates(model, X, y)`

* model (regressor): 학습이 완료된 회귀 모델을 입력으로 받습니다.
* X (arr): 학습 세트 특징.
* y (arr): 학습 세트 레이블.

<div id="residuals-plot">
  ### 잔차 플롯
</div>

<Frame>
  <img src="/images/integrations/scikit_residuals_plot.png" alt="Scikit-learn 잔차 플롯" />
</Frame>

예측된 타깃 값(y축)과 실제 값과 예측 값의 차이(잔차, x축)를 계산해 플롯하고, 잔차 오차의 분포도 함께 시각화합니다.

일반적으로 잘 적합된 모델의 잔차는 무작위로 분포해야 합니다. 좋은 모델은 데이터셋의 대부분의 패턴을 설명하고, 무작위 오차만 남기기 때문입니다.

`wandb.sklearn.plot_residuals(model, X, y)`

* model (regressor): 학습이 완료된 회귀기(regressor)를 입력으로 받습니다.
* X (arr): 학습 세트 특성.
* y (arr): 학습 세트 레이블.

  궁금한 점이 있다면, [Slack 커뮤니티](https://wandb.me/slack)에서 언제든지 질문해 주세요.

<div id="example">
  ## 예시
</div>

* [Colab에서 실행](https://wandb.me/scikit-colab): 시작하는 데 도움이 되는 간단한 노트북입니다.