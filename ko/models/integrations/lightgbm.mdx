---
description: W&B로 트리 모델을 추적하세요.
title: LightGBM
---

import { ColabLink } from '/snippets/ko/_includes/colab-link.mdx';

<ColabLink url="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/boosting/Simple_LightGBM_Integration.ipynb" />

`wandb` 라이브러리에는 [LightGBM](https://lightgbm.readthedocs.io/en/latest/)을 위한 전용 콜백이 포함되어 있습니다. 또한 W&amp;B의 일반적인 로깅 기능을 사용해 하이퍼파라미터 스윕과 같은 대규모 실험을 쉽게 추적할 수 있습니다.

```python
from wandb.integration.lightgbm import wandb_callback, log_summary
import lightgbm as lgb

# W&B에 메트릭 기록
gbm = lgb.train(..., callbacks=[wandb_callback()])

# 피처 중요도 플롯을 기록하고 모델 체크포인트를 W&B에 업로드
log_summary(gbm, save_model_checkpoint=True)
```

<Note>
  예제 코드가 필요하신가요? [GitHub의 예제 저장소](https://github.com/wandb/examples/tree/master/examples/boosting-algorithms)를 확인해 보세요.
</Note>

<div id="tuning-your-hyperparameters-with-sweeps">
  ## Sweeps로 하이퍼파라미터 튜닝하기
</div>

모델의 성능을 극대화하려면 트리 깊이(tree depth), 학습률(learning rate) 같은 하이퍼파라미터를 튜닝해야 합니다. W&amp;B [Sweeps](/ko/models/sweeps/)는 대규모 하이퍼파라미터 실험을 구성하고 오케스트레이션하며 분석할 수 있는 강력한 툴킷입니다.

이 도구에 대해 더 알아보고 XGBoost와 함께 Sweeps를 사용하는 예제를 보려면 아래 대화형 Colab 노트북을 확인하세요.

<ColabLink url="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/boosting/Using_W%26B_Sweeps_with_XGBoost.ipynb" />

<Frame>
  <img src="/images/integrations/lightgbm_sweeps.png" alt="LightGBM 성능 비교" />
</Frame>