---
title: Hugging Face
---

import { ColabLink } from '/snippets/ko/_includes/colab-link.mdx';

<ColabLink url="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/huggingface/Huggingface_wandb.ipynb" />

[Hugging Face](https://github.com/huggingface/transformers) 모델의 성능을 [W&amp;B](https://wandb.ai/site)와 매끄럽게 연동해 빠르게 시각화하세요.

여러 모델 간에 하이퍼파라미터, 결과 지표, GPU 사용률과 같은 시스템 통계를 비교할 수 있습니다.

<div id="why-should-i-use-wb">
  ## 왜 W&amp;B를 사용해야 하나요?
</div>

<Frame>
  <img src="/images/tutorials/huggingface-why.png" alt="W&B 사용의 이점" />
</Frame>

* **통합 대시보드**: 모든 모델 지표와 예측을 한곳에 모으는 중앙 저장소
* **가벼운 통합**: Hugging Face와 연동할 때 코드 변경이 필요 없음
* **높은 접근성**: 개인 및 학술 팀에 무료 제공
* **보안성**: 모든 프로젝트가 기본적으로 비공개
* **신뢰성**: OpenAI, Toyota, Lyft 등 다양한 머신 러닝 팀에서 사용

W&amp;B를 머신 러닝 모델을 위한 GitHub이라고 생각해 보세요. 머신 러닝 실험을 개인용 호스팅 대시보드에 저장할 수 있습니다. 스크립트를 어디에서 실행하든, 모든 모델 버전이 안전하게 저장된다는 확신을 가지고 빠르게 실험할 수 있습니다.

W&amp;B의 가벼운 통합 기능은 어떤 Python 스크립트와도 함께 사용할 수 있으며, 실행을 추적하고 모델을 시각화하려면 무료 W&amp;B 계정에 가입하기만 하면 됩니다.

Hugging Face Transformers 저장소에서는 `Trainer`를 계측해, 각 로깅 단계마다 학습 및 평가 지표를 자동으로 W&amp;B에 기록하도록 구성해 두었습니다.

통합이 어떻게 동작하는지 자세한 내용은 다음 리포트를 참조하세요: [Hugging Face + W&amp;B Report](https://app.wandb.ai/jxmorris12/huggingface-demo/reports/Train-a-model-with-Hugging-Face-and-Weights-%26-Biases--VmlldzoxMDE2MTU).

<div id="install-import-and-log-in">
  ## 설치, 임포트, 로그인
</div>

이 튜토리얼에서 사용할 Hugging Face와 W&amp;B 라이브러리, GLUE 데이터셋, 학습 스크립트를 설치합니다.

* [Hugging Face Transformers](https://github.com/huggingface/transformers): 자연어 모델과 데이터셋
* [W&amp;B](/ko/): 실험 추적과 시각화
* [GLUE 데이터셋](https://gluebenchmark.com/): 언어 이해 벤치마크 데이터셋
* [GLUE 스크립트](https://raw.githubusercontent.com/huggingface/transformers/refs/heads/main/examples/pytorch/text-classification/run_glue.py): 시퀀스 분류용 모델 학습 스크립트

```notebook
!pip install datasets wandb evaluate accelerate -qU
!wget https://raw.githubusercontent.com/huggingface/transformers/refs/heads/main/examples/pytorch/text-classification/run_glue.py
```

```notebook
# run_glue.py 스크립트는 transformers 개발 버전이 필요합니다
!pip install -q git+https://github.com/huggingface/transformers
```

계속하기 전에 [무료 계정을 생성하세요](https://app.wandb.ai/login?signup=true).

<div id="put-in-your-api-key">
  ## API 키 입력하기
</div>

가입을 완료했으면, 다음 셀을 실행한 뒤 링크를 클릭해 API 키를 확인하고 이 노트북을 인증하세요.

```python
import wandb
wandb.login()
```

선택적으로 환경 변수를 설정해 W&amp;B 로깅을 사용자 정의할 수 있습니다. 자세한 내용은 [Hugging Face 통합 가이드](/ko/models/integrations/huggingface/)를 참고하세요.

```python
# 선택 사항: 그래디언트와 파라미터 모두 기록
%env WANDB_WATCH=all
```

<div id="train-the-model">
  ## 모델 학습
</div>

다음으로, 다운로드한 학습 스크립트 [run&#95;glue.py](https://huggingface.co/transformers/examples.html#glue)를 실행하면 학습이 자동으로 W&amp;B 대시보드에 추적되는 것을 볼 수 있습니다. 이 스크립트는 Microsoft Research Paraphrase Corpus — 두 문장이 의미적으로 동등한지에 대한 사람 주석이 포함된 문장 쌍으로 구성된 데이터셋 — 에서 BERT를 파인튜닝합니다.

```python
%env WANDB_PROJECT=huggingface-demo
%env TASK_NAME=MRPC

!python run_glue.py \
  --model_name_or_path bert-base-uncased \
  --task_name $TASK_NAME \
  --do_train \
  --do_eval \
  --max_seq_length 256 \
  --per_device_train_batch_size 32 \
  --learning_rate 2e-4 \
  --num_train_epochs 3 \
  --output_dir /tmp/$TASK_NAME/ \
  --overwrite_output_dir \
  --logging_steps 50
```

<div id="visualize-results-in-dashboard">
  ## 대시보드에서 결과 시각화하기
</div>

위에 출력된 링크를 클릭하거나 [wandb.ai](https://app.wandb.ai)로 이동해 실시간으로 스트리밍되는 결과를 확인하세요. 브라우저에서 실행을 볼 수 있는 링크는 모든 의존성이 로드된 뒤에 표시됩니다. 다음과 같은 출력 내용을 찾으세요: &quot;**wandb**: View run at [URL to your unique run]&quot;

**모델 성능 시각화**
수십 개의 실험을 한눈에 비교하고, 흥미로운 결과를 확대해서 살펴보며, 고차원 데이터를 손쉽게 시각화할 수 있습니다.

<Frame>
  <img src="/images/tutorials/huggingface-visualize.gif" alt="모델 지표 대시보드" />
</Frame>

**아키텍처 비교**
다음은 [BERT vs DistilBERT](https://app.wandb.ai/jack-morris/david-vs-goliath/reports/Does-model-size-matter%3F-Comparing-BERT-and-DistilBERT-using-Sweeps--VmlldzoxMDUxNzU)를 비교한 예시입니다. 자동 선 그래프 시각화를 통해 서로 다른 아키텍처에 따라 학습 과정 전반의 평가 정확도가 어떻게 달라지는지 쉽게 확인할 수 있습니다.

<Frame>
  <img src="/images/tutorials/huggingface-comparearchitectures.gif" alt="BERT와 DistilBERT 비교" />
</Frame>

<div id="track-key-information-effortlessly-by-default">
  ## 기본값으로 핵심 정보를 손쉽게 추적하기
</div>

W&amp;B는 각 실험마다 새로운 실행을 생성해 저장합니다. 기본적으로 다음 정보가 저장됩니다:

* **하이퍼파라미터**: 모델 설정이 Config에 저장됩니다
* **모델 지표**: 스트리밍되는 지표의 시계열 데이터가 Log에 저장됩니다
* **터미널 로그**: 커맨드 라인 출력 내용이 저장되어 별도 탭에서 확인할 수 있습니다
* **시스템 지표**: GPU 및 CPU 사용률, 메모리, 온도 등이 기록됩니다

<div id="learn-more">
  ## 자세히 알아보기
</div>

* [Hugging Face 통합 가이드](/ko/models/integrations/huggingface)
* [YouTube 동영상 튜토리얼](http://wandb.me/youtube)