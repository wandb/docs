---
description: Python 스크립트 또는 Jupyter Notebook에 W&B를 추가합니다.
title: 코드에 W&B(wandb) 추가하기
---

이 가이드는 하이퍼파라미터 탐색을 최적화하기 위해 Python 학습 스크립트나 노트북에 W&amp;B를 통합하는 방법에 대한 권장 방법을 설명합니다.

<div id="original-training-script">
  ## 원본 학습 스크립트
</div>

아래와 같이 모델을 학습하는 Python 스크립트가 있다고 가정해 보겠습니다. 목표는 검증 정확도(`val_acc`)를 최대화하는 하이퍼파라미터를 찾는 것입니다.

Python 스크립트에서 `train_one_epoch`와 `evaluate_one_epoch` 두 개의 함수를 정의합니다. `train_one_epoch` 함수는 한 에폭 동안의 학습을 시뮬레이션하고, 학습 정확도와 손실을 반환합니다. `evaluate_one_epoch` 함수는 검증 데이터셋에 대해 모델을 평가하는 과정을 시뮬레이션하고, 검증 정확도와 손실을 반환합니다.

`config`라는 설정 딕셔너리를 정의하고, 여기에 학습률(`lr`), 배치 크기(`batch_size`), 에폭 수(`epochs`)와 같은 하이퍼파라미터 값을 넣습니다. 설정 딕셔너리의 값들이 학습 과정을 제어합니다.

다음으로 일반적인 학습 루프를 모사한 `main` 함수를 정의합니다. 각 에폭마다 학습 및 검증 데이터셋에 대해 정확도와 손실을 계산합니다.

<Note>
  이 코드는 예제용 모의 학습 스크립트입니다. 실제로 모델을 학습하지 않고, 무작위로 정확도와 손실 값을 생성하여 학습 과정을 시뮬레이션합니다. 이 코드의 목적은 W&amp;B를 학습 스크립트에 통합하는 방법을 보여 주는 것입니다.
</Note>

```python
import random
import numpy as np

def train_one_epoch(epoch, lr, batch_size):
    acc = 0.25 + ((epoch / 30) + (random.random() / 10))
    loss = 0.2 + (1 - ((epoch - 1) / 10 + random.random() / 5))
    return acc, loss

def evaluate_one_epoch(epoch):
    acc = 0.1 + ((epoch / 20) + (random.random() / 10))
    loss = 0.25 + (1 - ((epoch - 1) / 10 + random.random() / 6))
    return acc, loss

# 하이퍼파라미터 값을 담은 config 변수
config = {"lr": 0.0001, "batch_size": 16, "epochs": 5}

def main():
    lr = config["lr"]
    batch_size = config["batch_size"]
    epochs = config["epochs"]

    for epoch in np.arange(1, epochs):
        train_acc, train_loss = train_one_epoch(epoch, lr, batch_size)
        val_acc, val_loss = evaluate_one_epoch(epoch)

        print("epoch: ", epoch)
        print("training accuracy:", train_acc, "training loss:", train_loss)
        print("validation accuracy:", val_acc, "validation loss:", val_loss)

if __name__ == "__main__":
    main()
```

다음 섹션에서는 학습 중 하이퍼파라미터와 메트릭을 추적하기 위해 Python 스크립트에 W&amp;B를 추가합니다. 검증 정확도(`val_acc`)를 최대화하는 최적의 하이퍼파라미터를 찾기 위해 W&amp;B를 사용합니다.

<div id="add-wb-to-your-training-script">
  ## 학습 스크립트에 W&amp;B 추가하기
</div>

학습 스크립트에 W&amp;B를 포함하도록 수정하세요. Python 스크립트나 노트북에 W&amp;B를 통합하는 방식은 스윕을 어떻게 관리하느냐에 따라 달라집니다.

W&amp;B Python SDK를 사용해 스윕을 시작, 중지 및 관리하려면 **Python script or notebook** 탭의 안내를 따르세요. 대신 W&amp;B CLI를 사용하려면 **CLI** 탭의 안내를 따르세요.

<Tabs>
  <Tab title="CLI">
    스윕 구성이 포함된 YAML 설정 파일을 만듭니다. 이 설정 파일에는 스윕에서 탐색할 하이퍼파라미터를 정의합니다. 다음 예제에서는 배치 크기(`batch_size`), 에포크 수(`epochs`), 학습률(`lr`) 하이퍼파라미터가 스윕 실행마다 달라지도록 설정합니다.

    ```yaml
    # config.yaml
    program: train.py
    method: random
    name: sweep
    metric:
      goal: maximize
      name: val_acc
    parameters:
      batch_size:
        values: [16, 32, 64]
      lr:
        min: 0.0001
        max: 0.1
      epochs:
        values: [5, 10, 15]
    ```

    W&amp;B Sweep 구성 생성 방법에 대한 자세한 내용은 [Define sweep configuration](/ko/models/sweeps/define-sweep-configuration/)을 참고하세요.

    YAML 파일에서 `program` 키에 Python 스크립트의 이름을 지정해야 합니다.

    이제 코드 예시에 다음을 추가하세요.

    1. W&amp;B Python SDK(`wandb`)와 PyYAML(`yaml`)을 import합니다. PyYAML은 YAML 구성 파일을 읽는 데 사용됩니다.
    2. 구성 파일을 읽어들입니다.
    3. [`wandb.init()`](/ko/models/ref/python/functions/init)을(를) 사용해 백그라운드 프로세스를 시작하여 데이터를 [W&amp;B 실행](/ko/models/ref/python/experiments/run)으로 동기화하고 로그합니다. `config` 객체를 `config` 매개변수에 전달합니다.
    4. 하드 코딩된 값을 사용하는 대신 `wandb.Run.config`에서 하이퍼파라미터 값을 정의합니다.
    5. [`wandb.Run.log()`](/ko/models/ref/python/experiments/run.md/#method-runlog)을(를) 사용해 최적화하려는 메트릭을 로그합니다. 구성에서 정의한 메트릭을 반드시 로그해야 합니다. 구성 딕셔너리(이 예시에서는 `sweep_configuration`) 안에서 `val_acc` 값을 최대화하도록 Sweep을 정의합니다.

    ```python
    import wandb
    import yaml
    import random
    import numpy as np


    def train_one_epoch(epoch, lr, batch_size):
        acc = 0.25 + ((epoch / 30) + (random.random() / 10))
        loss = 0.2 + (1 - ((epoch - 1) / 10 + random.random() / 5))
        return acc, loss


    def evaluate_one_epoch(epoch):
        acc = 0.1 + ((epoch / 20) + (random.random() / 10))
        loss = 0.25 + (1 - ((epoch - 1) / 10 + random.random() / 6))
        return acc, loss


    def main():
        # 기본 하이퍼파라미터를 설정합니다
        with open("./config.yaml") as file:
            config = yaml.load(file, Loader=yaml.FullLoader)

        with wandb.init(config=config) as run:
            for epoch in np.arange(1, run.config['epochs']):
                train_acc, train_loss = train_one_epoch(epoch, run.config['lr'], run.config['batch_size'])
                val_acc, val_loss = evaluate_one_epoch(epoch)
                run.log(
                    {
                        "epoch": epoch,
                        "train_acc": train_acc,
                        "train_loss": train_loss,
                        "val_acc": val_acc,
                        "val_loss": val_loss,
                    }
                )

    # main 함수를 호출합니다.
    main()
    ```

    CLI에서 sweep 에이전트가 시도할 실행의 최대 개수를 설정합니다.
    이는 선택 사항입니다. 이 예제에서는 최대 개수를 5로 설정했습니다.

    ```bash
    NUM=5
    ```

    다음으로 [`wandb sweep`](/ko/models/ref/cli/wandb-sweep) 명령으로 스윕을 초기화합니다. YAML 파일의 이름을 지정하고, 필요하다면 프로젝트 플래그(`--project`)에 사용할 프로젝트 이름도 지정합니다:

    ```bash
    wandb sweep --project sweep-demo-cli config.yaml
    ```

    이렇게 하면 스윕 ID가 반환됩니다. 스윕을 초기화하는 방법에 대한 자세한 내용은
    [스윕 초기화](./initialize-sweeps)를 참고하세요.

    스윕 ID를 복사한 다음 아래 코드 스니펫에서 `sweepID`를 해당 값으로 바꿔서
    [`wandb agent`](/ko/models/ref/cli/wandb-agent) 명령으로 스윕 작업을 시작하세요:

    ```bash
    wandb agent --count $NUM your-entity/sweep-demo-cli/sweepID
    ```

    자세한 내용은 [스윕 작업 시작하기](./start-sweep-agents)를 참조하세요.
  </Tab>

  <Tab title="Python 스크립트나 노트북">
    다음 단계에 따라 Python 스크립트에 W&amp;B를 추가하세요:

    1. 키-값 쌍으로 [sweep configuration](/ko/models/sweeps/define-sweep-configuration/)을 정의하는 딕셔너리 객체를 만드세요. Sweep configuration은 W&amp;B가 대신 탐색할 하이퍼파라미터와 최적화하려는 지표(metric)를 정의합니다. 앞의 예제를 이어서, 배치 크기(`batch_size`), 에포크 수(`epochs`), 그리고 학습률(`lr`)이 각 스윕에서 바꿔 가며 탐색할 하이퍼파라미터입니다. 검증 정확도를 최대화하고 싶으므로 `"goal": "maximize"`로 설정하고, 이때 최적화할 변수의 이름으로 `val_acc`를 지정합니다(`"name": "val_acc"`).
    2. 스윕 설정 딕셔너리를 [`wandb.sweep()`](/ko/models/ref/python/functions/sweep)에 전달하세요. 이 함수는 스윕을 초기화하고 스윕 ID(`sweep_id`)를 반환합니다. 자세한 내용은 [스윕 초기화](./initialize-sweeps)를 참조하세요.
    3. 스크립트 맨 위에 W&amp;B Python SDK (`wandb`)를 임포트합니다.
    4. `main` 함수 안에서 [`wandb.init()`](/ko/models/ref/python/functions/init)를 사용하여 백그라운드 프로세스를 생성하고 데이터를 [W&amp;B 실행](/ko/models/ref/python/experiments/run)으로 동기화하고 로깅하세요. `wandb.init()` 메서드에 프로젝트 이름을 매개변수로 전달하세요. 프로젝트 이름을 전달하지 않으면 W&amp;B는 기본 프로젝트 이름을 사용합니다.
    5. `wandb.Run.config` 객체에서 하이퍼파라미터 값을 가져오세요. 그러면 하드코딩된 값 대신 스윕 설정 딕셔너리에 정의된 하이퍼파라미터 값을 사용할 수 있습니다.
    6. [`wandb.Run.log()`](/ko/models/ref/python/experiments/run.md/#method-runlog)을 사용하여 최적화하려는 metric을 W&amp;B에 기록합니다. 구성에서 정의한 metric을 반드시 기록해야 합니다. 예를 들어, 최적화할 metric을 `val_acc`로 정의했다면 `val_acc`를 반드시 기록해야 합니다. metric을 기록하지 않으면 W&amp;B는 무엇을 최적화해야 하는지 알 수 없습니다. 구성 딕셔너리(이 예시에서는 `sweep_configuration`)에서 `val_acc` 값을 최대화하도록 sweep을 정의합니다.
    7. [`wandb.agent()`](/ko/models/ref/python/functions/agent)로 스윕을 시작합니다. 스윕 ID와 스윕이 실행할 함수 이름(`function=main`)을 전달하고, 시도할 실행 횟수의 최대값을 4로 지정합니다(`count=4`).

    이 모든 내용을 종합하면, 스크립트는 다음과 같은 형태가 됩니다:

    ```python
    import wandb # W&B Python SDK 가져오기
    import numpy as np
    import random
    import argparse

    def train_one_epoch(epoch, lr, batch_size):
        acc = 0.25 + ((epoch / 30) + (random.random() / 10))
        loss = 0.2 + (1 - ((epoch - 1) / 10 + random.random() / 5))
        return acc, loss

    def evaluate_one_epoch(epoch):
        acc = 0.1 + ((epoch / 20) + (random.random() / 10))
        loss = 0.25 + (1 - ((epoch - 1) / 10 + random.random() / 6))
        return acc, loss

    def main(args=None):
        # sweep 에이전트에 의해 호출될 때 args는 None이므로,
        # sweep 설정의 프로젝트를 사용합니다
        project = args.project if args else None
        
        with wandb.init(project=project) as run:
            # `wandb.Run.config` 객체에서 하이퍼파라미터 값을 가져옵니다
            lr = run.config["lr"]
            batch_size = run.config["batch_size"]
            epochs = run.config["epochs"]

            # 학습 루프를 실행하고 성능 값을 W&B에 기록합니다
            for epoch in np.arange(1, epochs):
                train_acc, train_loss = train_one_epoch(epoch, lr, batch_size)
                val_acc, val_loss = evaluate_one_epoch(epoch)
                run.log(
                    {
                        "epoch": epoch,
                        "train_acc": train_acc,
                        "train_loss": train_loss,
                        "val_acc": val_acc, # 최적화된 메트릭
                        "val_loss": val_loss,
                    }
                )

    if __name__ == "__main__":
        parser = argparse.ArgumentParser()
        parser.add_argument("--project", type=str, default="sweep-example", help="W&B 프로젝트 이름")
        args = parser.parse_args()

        # sweep 설정 딕셔너리 정의
        sweep_configuration = {
            "method": "random",
            "name": "sweep",
            # 최적화할 메트릭
            # 예를 들어, 검증 정확도를 최대화하려면
            # "goal": "maximize"로 설정하고 최적화할 변수의
            # 이름을 지정합니다. 이 경우 "val_acc"
            "metric": {
                "goal": "maximize",
                "name": "val_acc"
                },
            "parameters": {
                "batch_size": {"values": [16, 32, 64]},
                "epochs": {"values": [5, 10, 15]},
                "lr": {"max": 0.1, "min": 0.0001},
            },
        }

        # 설정 딕셔너리를 전달하여 sweep 초기화
        sweep_id = wandb.sweep(sweep=sweep_configuration, project=args.project)

        # sweep 작업 시작
        wandb.agent(sweep_id, function=main, count=4)
    ```
  </Tab>
</Tabs>

<Note>
  **스윕에서 W&amp;B로 메트릭 로깅하기**

  스윕 구성에서 정의하고 최적화할 메트릭은 스윕 구성과 `wandb.Run.log()` 모두에 로깅해야 합니다. 예를 들어, 스윕 구성에서 최적화할 메트릭을 `val_acc`로 정의했다면, `val_acc`를 W&amp;B에도 로깅해야 합니다. 메트릭을 로깅하지 않으면 W&amp;B는 무엇을 기준으로 최적화해야 할지 알 수 없습니다.

  ```python
  with wandb.init() as run:
      val_loss, val_acc = train()
      run.log(
          {
              "val_loss": val_loss,
              "val_acc": val_acc
              }
          )
  ```

  다음 예시는 W&amp;B로 메트릭을 잘못 로깅한 경우입니다. 스윕 구성에서 최적화 대상으로 설정된 메트릭은 `val_acc`이지만, 코드에서는 `validation` 키 아래의 중첩 딕셔너리 안에 `val_acc`를 로깅하고 있습니다. 메트릭은 중첩 딕셔너리 안이 아니라, 최상위 키로 직접 로깅해야 합니다.

  ```python
  with wandb.init() as run:
      val_loss, val_acc = train()
      run.log(
          {
              "validation": {
                  "val_loss": val_loss, 
                  "val_acc": val_acc
                  }
              }
          )
  ```
</Note>