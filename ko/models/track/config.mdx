---
description: 딕셔너리처럼 동작하는 객체를 사용해 실험 구성을 저장합니다
title: 실험 구성하기
---

import { ColabLink } from '/snippets/ko/_includes/colab-link.mdx';

<ColabLink url="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Configs_in_W%26B.ipynb" />

실행의 `config` 속성을 사용해 학습 설정을 저장하세요:

* 하이퍼파라미터
* 데이터셋 이름이나 모델 타입과 같은 입력 설정
* 그 외 실험에 사용되는 독립 변수들

`wandb.Run.config` 속성을 사용하면 실험을 분석하고, 나중에 작업을 재현하기가 쉬워집니다. W&amp;B 앱에서 설정 값으로 그룹화하고, 서로 다른 W&amp;B 실행의 설정을 비교하며, 각 학습 설정이 출력에 어떤 영향을 미치는지 평가할 수 있습니다. `config` 속성은 여러 개의 딕셔너리와 유사한 객체를 합쳐서 구성할 수 있는 딕셔너리 유사 객체입니다.

<Note>
  loss, accuracy와 같은 출력 메트릭이나 종속 변수를 저장하려면 `wandb.Run.config` 대신 `wandb.Run.log()`를 사용하세요.
</Note>

<div id="set-up-an-experiment-configuration">
  ## 실험 구성 설정하기
</div>

구성은 일반적으로 학습 스크립트의 시작 부분에서 정의합니다. 다만 머신러닝 워크플로는 다양하기 때문에, 학습 스크립트의 시작 부분에서 구성을 반드시 정의해야 하는 것은 아닙니다.

config 변수 이름에서는 마침표(`.`) 대신 대시(`-`) 또는 밑줄(`_`)을 사용하십시오.

스크립트에서 루트 수준 이하의 `wandb.Run.config` 키에 접근하는 경우, 속성 접근 구문 `config.key.value` 대신 딕셔너리 접근 구문 `["key"]["value"]`를 사용하십시오.

다음 섹션에서는 실험 구성을 정의하는 여러 가지 일반적인 시나리오를 설명합니다.

<div id="set-the-configuration-at-initialization">
  ### 초기화 시 설정 구성하기
</div>

스크립트 시작 부분에서 `wandb.init()` API를 호출할 때 딕셔너리를 전달하여 백그라운드 프로세스를 생성하고, 데이터를 W&amp;B 실행으로 동기화하고 로그를 남기도록 합니다.

다음 코드 스니펫은 구성 값이 포함된 Python 딕셔너리를 정의하는 방법과, W&amp;B 실행을 초기화할 때 해당 딕셔너리를 인자로 전달하는 방법을 보여 줍니다.

```python
import wandb

# config 딕셔너리 객체 정의
config = {
    "hidden_layer_sizes": [32, 64],
    "kernel_sizes": [3],
    "activation": "ReLU",
    "pool_sizes": [2],
    "dropout": 0.5,
    "num_classes": 10,
}

# W&B 초기화 시 config 딕셔너리 전달
with wandb.init(project="config_example", config=config) as run:
    ...
```

중첩된 딕셔너리를 `config`로 전달하면, W&amp;B는 점(.) 구분자를 사용해 키 이름을 평탄화합니다.

딕셔너리의 값에는 Python에서 다른 딕셔너리에 접근할 때와 같은 방식으로 접근할 수 있습니다:

```python
# 키를 인덱스 값으로 사용하여 값에 접근
hidden_layer_sizes = run.config["hidden_layer_sizes"]
kernel_sizes = run.config["kernel_sizes"]
activation = run.config["activation"]

# Python 딕셔너리 get() 메서드
hidden_layer_sizes = run.config.get("hidden_layer_sizes")
kernel_sizes = run.config.get("kernel_sizes")
activation = run.config.get("activation")
```

<Note>
  Developer Guide와 예제 전반에서 구성 값을 별도의 변수로 복사합니다. 이 단계는 선택 사항이며, 가독성을 위해 수행합니다.
</Note>

<div id="set-the-configuration-with-argparse">
  ### argparse로 설정 구성하기
</div>

`argparse` 객체로 설정을 구성할 수 있습니다. [argparse](https://docs.python.org/3/library/argparse.html)는 argument parser의 약자로, Python 3.2 이상에서 사용할 수 있는 표준 라이브러리 모듈이며, 커맨드 라인 인자의 유연함과 강력함을 손쉽게 활용하는 스크립트를 작성할 수 있도록 해 줍니다.

이는 커맨드 라인에서 실행되는 스크립트의 결과를 추적할 때 유용합니다.

아래 Python 스크립트는 parser 객체를 정의해서 실험 설정(config)을 정의하고 지정하는 방법을 보여 줍니다. `train_one_epoch`와 `evaluate_one_epoch` 함수는 이 데모를 위해 학습 루프를 시뮬레이션하는 용도로 제공됩니다:

```python
# config_experiment.py
import argparse
import random

import numpy as np
import wandb


# 훈련 및 평가 데모 코드
def train_one_epoch(epoch, lr, bs):
    acc = 0.25 + ((epoch / 30) + (random.random() / 10))
    loss = 0.2 + (1 - ((epoch - 1) / 10 + random.random() / 5))
    return acc, loss


def evaluate_one_epoch(epoch):
    acc = 0.1 + ((epoch / 20) + (random.random() / 10))
    loss = 0.25 + (1 - ((epoch - 1) / 10 + random.random() / 6))
    return acc, loss


def main(args):
    # W&B 실행 시작
    with wandb.init(project="config_example", config=args) as run:
        # config 딕셔너리에서 값을 가져와 가독성을 위해
        # 변수에 저장
        lr = run.config["learning_rate"]
        bs = run.config["batch_size"]
        epochs = run.config["epochs"]

        # 훈련 시뮬레이션 및 W&B에 값 로깅
        for epoch in np.arange(1, epochs):
            train_acc, train_loss = train_one_epoch(epoch, lr, bs)
            val_acc, val_loss = evaluate_one_epoch(epoch)

            run.log(
                {
                    "epoch": epoch,
                    "train_acc": train_acc,
                    "train_loss": train_loss,
                    "val_acc": val_acc,
                    "val_loss": val_loss,
                }
            )


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    parser.add_argument("-b", "--batch_size", type=int, default=32, help="배치 크기")
    parser.add_argument(
        "-e", "--epochs", type=int, default=50, help="훈련 에포크 수"
    )
    parser.add_argument(
        "-lr", "--learning_rate", type=int, default=0.001, help="학습률"
    )

    args = parser.parse_args()
    main(args)
```

<div id="set-the-configuration-throughout-your-script">
  ### 스크립트 전체에서 구성 설정하기
</div>

스크립트 전반에서 `config` 객체에 파라미터를 계속 추가할 수 있습니다. 다음 코드 스니펫은 `config` 객체에 새로운 키-값 쌍을 추가하는 방법을 보여줍니다.

```python
import wandb

# config 딕셔너리 객체 정의
config = {
    "hidden_layer_sizes": [32, 64],
    "kernel_sizes": [3],
    "activation": "ReLU",
    "pool_sizes": [2],
    "dropout": 0.5,
    "num_classes": 10,
}

# W&B를 초기화할 때 config 딕셔너리 전달
with wandb.init(project="config_example", config=config) as run:
    # W&B 초기화 후 config 업데이트
    run.config["dropout"] = 0.2
    run.config.epochs = 4
    run.config["batch_size"] = 32
```

여러 값을 한꺼번에 업데이트할 수 있습니다:

```python
run.config.update({"lr": 0.1, "channels": 16})
```

<div id="set-the-configuration-after-your-run-has-finished">
  ### 실행이 완료된 후 구성 설정하기
</div>

[W&amp;B Public API](/ko/models/ref/python/public-api/)를 사용하여 완료된 실행의 구성(config)을 업데이트합니다.

API에 엔터티, 프로젝트 이름, 그리고 실행 ID를 제공해야 합니다. 이 정보는 Run 객체 또는 [W&amp;B App](/ko/models/track/workspaces/)에서 확인할 수 있습니다:

```python
with wandb.init() as run:
    ...

# 현재 스크립트 또는 노트북에서 실행이 시작된 경우 Run 객체에서 다음 값을 찾거나,
# W&B App UI에서 복사할 수 있습니다.
username = run.entity
project = run.project
run_id = run.id

# api.run()은 wandb.init()과 다른 타입의 객체를 반환한다는 점에 유의하세요.
api = wandb.Api()
api_run = api.run(f"{username}/{project}/{run_id}")
api_run.config["bar"] = 32
api_run.update()
```

<div id="abslflags">
  ## `absl.FLAGS`
</div>

[`absl` 플래그](https://abseil.io/docs/python/guides/flags)를 함께 전달할 수도 있습니다.

```python
flags.DEFINE_string("model", None, "model to run")  # 이름, 기본값, 도움말

run.config.update(flags.FLAGS)  # absl 플래그를 config에 추가
```

<div id="file-based-configs">
  ## 파일 기반 구성
</div>

`config-defaults.yaml`라는 파일을 실행 스크립트와 동일한 디렉터리에 두면, 해당 실행에서 파일에 정의된 키-값 쌍을 자동으로 읽어 `wandb.Run.config`에 전달합니다.

다음 코드 스니펫은 예시 `config-defaults.yaml` YAML 파일을 보여 줍니다:

```yaml
batch_size:
  desc: 각 미니 배치의 크기
  value: 32
```

`config-defaults.yaml`에서 자동으로 로드되는 기본값은 `wandb.init`의 `config` 인수에 변경된 값을 설정해서 덮어쓸 수 있습니다. 예를 들어:

```python
import wandb

# 사용자 정의 값을 전달하여 config-defaults.yaml 재정의
with wandb.init(config={"epochs": 200, "batch_size": 64}) as run:
    ...
```

`config-defaults.yaml`이 아닌 다른 구성 파일을 로드하려면 명령줄 인수 `--configs`를 사용하고 파일의 경로를 지정하세요:

```bash
python train.py --configs other-config.yaml
```

<div id="example-use-case-for-file-based-configs">
  ### 파일 기반 설정의 사용 예
</div>

실행에 대한 메타데이터가 담긴 YAML 파일이 있고, Python 스크립트 안에 하이퍼파라미터 딕셔너리가 있다고 가정해 보겠습니다. 둘 모두를 중첩된 `config` 객체에 저장할 수 있습니다.

```python
hyperparameter_defaults = dict(
    dropout=0.5,
    batch_size=100,
    learning_rate=0.001,
)

config_dictionary = dict(
    yaml=my_yaml_file,
    params=hyperparameter_defaults,
)

with wandb.init(config=config_dictionary) as run:
    ...
```

<div id="tensorflow-v1-flags">
  ## TensorFlow v1 플래그
</div>

TensorFlow 플래그를 `wandb.Run.config` 객체에 직접 넘길 수 있습니다.

```python
with wandb.init() as run:
    run.config.epochs = 4

    flags = tf.app.flags
    flags.DEFINE_string("data_dir", "/tmp/data")
    flags.DEFINE_integer("batch_size", 128, "Batch size.")
    run.config.update(flags.FLAGS)  # tensorflow 플래그를 config에 추가
```
