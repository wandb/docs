---
description: W&B 빠르게 시작하기
title: W&B 빠르게 시작하기
---

import ApiKeyCreate from "/snippets/ko/_includes/api-key-create.mdx";

W&amp;B를 설치하여 모든 규모의 머신러닝 실험을 추적하고, 시각화하고, 관리하세요.

<Note>
  W&amp;B Weave에 대한 정보를 찾고 계신가요? [Weave Python SDK 빠른 시작](/ko/weave/quickstart) 또는 [Weave TypeScript SDK 빠른 시작](/ko/weave/reference/generated_typescript_docs/intro-notebook)을 참조하세요.
</Note>

<div id="sign-up-and-create-an-api-key">
  ## 가입 및 API 키 생성
</div>

로컬 머신을 W&amp;B에 인증하려면 API 키가 필요합니다.

<ApiKeyCreate />

<div id="install-the-wandb-library-and-log-in">
  ## `wandb` 라이브러리를 설치하고 로그인하기
</div>

<Tabs>
  <Tab title="명령줄">
    1. `WANDB_API_KEY` [환경 변수](/ko/models/track/environment-variables/)를 설정합니다.

       ```bash
       export WANDB_API_KEY=<your_api_key>
       ```

    2. `wandb` 라이브러리를 설치하고 로그인합니다.

       ```shell
       pip install wandb
       wandb login
       ```
  </Tab>

  <Tab title="Python">
    ```bash
    pip install wandb
    ```

    ```python
    import wandb

    wandb.login()
    ```
  </Tab>

  <Tab title="Python 노트북">
    ```notebook
    !pip install wandb
    import wandb
    wandb.login()
    ```
  </Tab>
</Tabs>

<div id="initialize-a-run-and-track-hyperparameters">
  ## 실행 초기화 및 하이퍼파라미터 추적
</div>

Python 스크립트나 노트북에서 [`wandb.init()`](/ko/models/ref/python/experiments/run/)을 사용해 W&amp;B 실행 객체를 초기화합니다. `config` 매개변수에는 딕셔너리를 사용하여 하이퍼파라미터 이름과 값을 지정합니다. `with` 문 블록 안에서 지표와 기타 정보를 W&amp;B에 로깅할 수 있습니다.

```python
import wandb

wandb.login()

# 실행이 기록될 프로젝트
project = "my-awesome-project"

# 하이퍼파라미터 딕셔너리
config = {
    'epochs' : 10,
    'lr' : 0.01
}

with wandb.init(project=project, config=config) as run:
    # 학습 코드 작성
    # run.log()로 W&B에 값 기록
    run.log({"accuracy": 0.9, "loss": 0.1})
```

다음 섹션에서는 학습 실행을 시뮬레이션하고 정확도와 손실 지표를 W&amp;B에 로깅하는 전체 예제를 살펴볼 수 있습니다.

<Info>
  [실행](/ko/models/runs/)은 W&amp;B의 핵심 구성 요소입니다. 실행을 사용하여 [지표를 추적](/ko/models/track/), [로그를 남기고](/ko/models/track/log/), 아티팩트를 추적하는 등 다양한 작업을 수행할 수 있습니다.
</Info>

<div id="create-a-machine-learning-training-experiment">
  ## 머신러닝 학습 실험 생성
</div>

이 예제 학습 스크립트는 시뮬레이션한 정확도와 손실 지표를 W&amp;B에 기록합니다. 다음 코드를 Python 스크립트 또는 노트북 셀에 복사해 붙여넣고 실행하세요:

```python
import wandb
import random

wandb.login()

# 실행이 기록될 프로젝트
project = "my-awesome-project"

# 하이퍼파라미터 딕셔너리
config = {
    'epochs' : 10,
    'lr' : 0.01
}

with wandb.init(project=project, config=config) as run:
    offset = random.random() / 5
    print(f"lr: {config['lr']}")
    
    # 학습 실행 시뮬레이션
    for epoch in range(2, config['epochs']):
        acc = 1 - 2**-config['epochs'] - random.random() / config['epochs'] - offset
        loss = 2**-config['epochs'] + random.random() / config['epochs'] + offset
        print(f"epoch={config['epochs']}, accuracy={acc}, loss={loss}")
        run.log({"accuracy": acc, "loss": loss})
```

[wandb.ai/home](https://wandb.ai/home)에서 정확도와 손실 같은 기록된 지표와 각 학습 단계에서 어떻게 변했는지 확인할 수 있습니다. 아래 이미지는 각 실행에서 추적된 손실과 정확도를 보여줍니다. 각 실행 객체는 생성된 이름과 함께 **Runs** 열에 표시됩니다.

<Frame>
  <img src="/images/quickstart/quickstart_image.png" alt="각 실행에서 추적된 손실과 정확도를 보여줍니다." />
</Frame>

<div id="next-steps">
  ## 다음 단계
</div>

W&amp;B 에코시스템의 더 많은 기능을 살펴보세요:

1. PyTorch 같은 프레임워크, Hugging Face 같은 라이브러리, SageMaker 같은 서비스와 W&amp;B를 함께 사용하는 [W&amp;B 통합 튜토리얼](/ko/models/integrations)을 읽어보세요.
2. [W&amp;B Reports](/ko/models/reports)를 사용해 실행을 정리하고 시각화를 자동화하며 결과를 요약하고 협업자와 업데이트를 공유하세요.
3. 머신 러닝 파이프라인 전반에 걸쳐 데이터셋, 모델, 의존성, 결과를 추적하기 위해 [W&amp;B Artifacts](/ko/models/artifacts)를 생성하세요.
4. [W&amp;B Sweeps](/ko/models/sweeps)를 사용해 하이퍼파라미터 탐색을 자동화하고 모델을 최적화하세요.
5. [중앙 대시보드](/ko/models/tables)에서 실행을 분석하고, 모델 예측을 시각화하고, 인사이트를 공유하세요.
6. [W&amp;B AI Academy](https://wandb.ai/site/courses/)를 방문해 실습형 코스를 통해 LLM, MLOps, W&amp;B Models에 대해 학습하세요.
7. [weave-docs.wandb.ai](/ko/weave)를 방문해 Weave를 사용하여 LLM 기반 애플리케이션을 추적하고, 실험하고, 평가하고, 배포하고, 개선하는 방법을 알아보세요.