---
title: CSV ファイルを Experiments で追跡する
description: W&B へのデータのインポートと ログ の記録
---

W&B Pythonライブラリを使用してCSVファイルをログに記録し、 [W&B Dashboard](/models/track/workspaces/) で可視化します。 W&B Dashboard は、機械学習モデルの結果を整理して可視化するための中心的な場所です。これは、W&Bにログが記録されていない [過去の機械学習実験の情報を含むCSVファイル](#import-and-log-your-csv-of-experiments) がある場合や、 [データセットを含むCSVファイル](#import-and-log-your-dataset-csv-file) がある場合に特に便利です。

## データセットのCSVファイルをインポートしてログに記録する

{/* {% embed url="https://drive.google.com/file/d/1jBG3M4VnaMgeclRzowYZEYvFxvwb9SXF/view?usp=sharing" %} */}

CSVファイルの内容をより簡単に再利用できるようにするために、 W&B Artifacts を活用することをお勧めします。

1. まず、CSVファイルをインポートします。以下のコードスニペットで、 `iris.csv` をお手元のCSVファイル名に置き換えてください。

```python
import wandb
import pandas as pd

# CSVを新しいDataFrameに読み込む
new_iris_dataframe = pd.read_csv("iris.csv")
```

2. CSVファイルを W&B Table に変換して、 [W&B Dashboards](/models/track/workspaces/) を利用できるようにします。

```python
# DataFrameをW&B Tableに変換する
iris_table = wandb.Table(dataframe=new_iris_dataframe)
```

3. 次に、 W&B Artifact を作成し、その Artifact にテーブルを追加します。

```python
# テーブルをArtifactに追加して、行制限を200,000に増やし、
# 再利用しやすくする
iris_table_artifact = wandb.Artifact("iris_artifact", type="dataset")
iris_table_artifact.add(iris_table, "iris_table")

# データを保存するために、生のcsvファイルをアーティファクト内にログ記録する
iris_table_artifact.add_file("iris.csv")
```
W&B Artifacts の詳細については、 [Artifactsのチャプター](/models/artifacts/) を参照してください。

4. 最後に、 `wandb.init` を使用して新しい W&B Run を開始し、W&Bへのトラッキングとログ記録を行います。

```python
# データをログに記録するためのW&B runを開始する
with wandb.init(project="tables-walkthrough") as run:

    # runで可視化するためにテーブルをログに記録する...
    run.log({"iris": iris_table})

    # さらにArtifactとしてログに記録し、利用可能な行制限を増やす！
    run.log_artifact(iris_table_artifact)
```

`wandb.init()` APIは、 Run にデータをログ記録するための新しいバックグラウンドプロセスを生成し、（デフォルトで）データを wandb.ai に同期します。 W&B Workspace Dashboard でライブの可視化を確認できます。以下の画像は、コードスニペットのデモンストレーションの出力を示しています。

<Frame>
    <img src="/images/track/import_csv_tutorial.png" alt="W&B DashboardにインポートされたCSVファイル"  />
</Frame>


上記のコードスニペットをまとめた完全なスクリプトは以下の通りです。

```python
import wandb
import pandas as pd

# CSVを新しいDataFrameに読み込む
new_iris_dataframe = pd.read_csv("iris.csv")

# DataFrameをW&B Tableに変換する
iris_table = wandb.Table(dataframe=new_iris_dataframe)

# テーブルをArtifactに追加して、行制限を200,000に増やし、
# 再利用しやすくする
iris_table_artifact = wandb.Artifact("iris_artifact", type="dataset")
iris_table_artifact.add(iris_table, "iris_table")

# データを保存するために、生のcsvファイルをアーティファクト内にログ記録する
iris_table_artifact.add_file("iris.csv")

# データをログに記録するためのW&B runを開始する
with wandb.init(project="tables-walkthrough") as run:

    # runで可視化するためにテーブルをログに記録する...
    run.log({"iris": iris_table})

    # さらにArtifactとしてログに記録し、利用可能な行制限を増やす！
    run.log_artifact(iris_table_artifact)
```

## 実験のCSVをインポートしてログに記録する

{/* {% embed url="https://drive.google.com/file/d/1PL4RSdopHEptDR5Gi0DEzECXuoW_5B0f/view?usp=sharing" %}
以下のテーブルは変換後にこのW&B Dashboardになります
{% endembed %} */}

場合によっては、実験の詳細がCSVファイルに保存されていることがあります。このようなCSVファイルで見られる一般的な詳細には以下のものがあります。

* 実験 Run の名前
* 初期 [notes](/models/runs/#add-a-note-to-a-run) （ノート）
* 実験を区別するための [Tags](/models/runs/tags/) （タグ）
* 実験に必要な設定（これには [Sweeps Hyperparameter Tuning](/models/sweeps/) を利用できるという利点もあります）

| Experiment   | Model Name       | Notes                                            | Tags          | Num Layers | Final Train Acc | Final Val Acc | Training Losses                       |
| ------------ | ---------------- | ------------------------------------------------ | ------------- | ---------- | --------------- | ------------- | ------------------------------------- |
| Experiment 1 | mnist-300-layers | Overfit way too much on training data            | \[latest]     | 300        | 0.99            | 0.90          | \[0.55, 0.45, 0.44, 0.42, 0.40, 0.39] |
| Experiment 2 | mnist-250-layers | Current best model                               | \[prod, best] | 250        | 0.95            | 0.96          | \[0.55, 0.45, 0.44, 0.42, 0.40, 0.39] |
| Experiment 3 | mnist-200-layers | Did worse than the baseline model. Need to debug | \[debug]      | 200        | 0.76            | 0.70          | \[0.55, 0.45, 0.44, 0.42, 0.40, 0.39] |
| ...          | ...              | ...                                              | ...           | ...        | ...             | ...           |                                       |
| Experiment N | mnist-X-layers   | NOTES                                            | ...           | ...        | ...             | ...           | \[..., ...]                           |

W&Bは実験のCSVファイルを取り込み、それを W&B Experiment Run に変換できます。以下のコードスニペットとスクリプトは、実験のCSVファイルをインポートしてログに記録する方法を示しています。

1. まず、CSVファイルを読み込み、Pandas DataFrameに変換します。 `"experiments.csv"` をお手元のCSVファイル名に置き換えてください。

```python
import wandb
import pandas as pd

FILENAME = "experiments.csv"
loaded_experiment_df = pd.read_csv(FILENAME)

PROJECT_NAME = "Converted Experiments"

EXPERIMENT_NAME_COL = "Experiment"
NOTES_COL = "Notes"
TAGS_COL = "Tags"
CONFIG_COLS = ["Num Layers"]
SUMMARY_COLS = ["Final Train Acc", "Final Val Acc"]
METRIC_COLS = ["Training Losses"]

# 操作しやすいようにPandas DataFrameをフォーマットする
for i, row in loaded_experiment_df.iterrows():
    run_name = row[EXPERIMENT_NAME_COL]
    notes = row[NOTES_COL]
    tags = row[TAGS_COL]

    config = {}
    for config_col in CONFIG_COLS:
        config[config_col] = row[config_col]

    metrics = {}
    for metric_col in METRIC_COLS:
        metrics[metric_col] = row[metric_col]

    summaries = {}
    for summary_col in SUMMARY_COLS:
        summaries[summary_col] = row[summary_col]
```


2. 次に、 [`wandb.init()`](/models/ref/python/functions/init) を使用して新しい W&B Run を開始し、W&Bへのトラッキングとログ記録を行います。

    ```python
    with wandb.init(
        project=PROJECT_NAME, name=run_name, tags=tags, notes=notes, config=config
    ) as run:
    ```

実験が進むにつれて、メトリクスのすべてのインスタンスをログに記録し、W&Bで表示、クエリ、分析できるようにしたい場合があります。これを行うには [`run.log()`](/models/ref/python/experiments/run/#method-runlog) コマンドを使用します。

```python
run.log({key: val})
```

オプションで、 [`define_metric`](/models/ref/python/experiments/run#define_metric) APIを使用して、 Run の結果を定義する最終的なサマリーメトリクスをログに記録できます。この例では、 `run.summary.update()` を使用してサマリーメトリクスを Run に追加しています。

```python
run.summary.update(summaries)
```

サマリーメトリクスの詳細については、 [Log Summary Metrics](./log-summary) を参照してください。

以下は、上記のサンプルテーブルを [W&B Dashboard](/models/track/workspaces/) に変換する完全なサンプルスクリプトです。

```python
FILENAME = "experiments.csv"
loaded_experiment_df = pd.read_csv(FILENAME)

PROJECT_NAME = "Converted Experiments"

EXPERIMENT_NAME_COL = "Experiment"
NOTES_COL = "Notes"
TAGS_COL = "Tags"
CONFIG_COLS = ["Num Layers"]
SUMMARY_COLS = ["Final Train Acc", "Final Val Acc"]
METRIC_COLS = ["Training Losses"]

for i, row in loaded_experiment_df.iterrows():
    run_name = row[EXPERIMENT_NAME_COL]
    notes = row[NOTES_COL]
    tags = row[TAGS_COL]

    config = {}
    for config_col in CONFIG_COLS:
        config[config_col] = row[config_col]

    metrics = {}
    for metric_col in METRIC_COLS:
        metrics[metric_col] = row[metric_col]

    summaries = {}
    for summary_col in SUMMARY_COLS:
        summaries[summary_col] = row[summary_col]

    with  wandb.init(
        project=PROJECT_NAME, name=run_name, tags=tags, notes=notes, config=config
    ) as run:

        for key, val in metrics.items():
            if isinstance(val, list):
                for _val in val:
                    run.log({key: _val})
            else:
                run.log({key: val})

        run.summary.update(summaries)
```