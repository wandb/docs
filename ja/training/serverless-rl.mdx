---
title: サーバーレス RL
description: thought 強化学習 を使用して、より効率的に モデル の事後学習（post-train）を行う方法について学びましょう。
---

現在パブリックプレビュー中の Serverless RL は、開発者が LLM をポストトレーニングして新しい振る舞いを学習させ、マルチターンのエージェントタスクを実行する際の信頼性、速度、コストを向上させるのに役立ちます。W&B はトレーニング用の インフラストラクチャー（[CoreWeave 上](https://docs.coreweave.com/docs/platform)）をプロビジョニングしつつ、環境 のセットアップには完全な柔軟性を提供します。Serverless RL を使用すると、数十台の GPU に弾力的にオートスケールする管理されたトレーニング クラスター に即座に アクセス できます。RL の ワークフロー を推論フェーズとトレーニングフェーズに分割し、ジョブ間でそれらを多重化することで、Serverless RL は GPU の利用率を高め、トレーニング 時間とコストを削減します。

Serverless RL は、以下のようなタスクに最適です：
* ボイスエージェント
* 高度なリサーチアシスタント
* オンプレミス モデル
* コンテンツマーケティングの 分析 エージェント

Serverless RL は Low-Rank Adapters (LoRAs) をトレーニングして、エージェントの特定のタスクに モデル を特化させます。これにより、実務経験を通じて元の モデル の機能を拡張します。トレーニングした LoRA は Artifacts として W&B アカウントに自動的に保存され、ローカルやサードパーティに バックアップ として保存することも可能です。Serverless RL を通じてトレーニングされた Models は、W&B Inference 上でも自動的にホストされます。

使い始めるには、ART [クイックスタート](https://art.openpipe.ai/getting-started/quick-start) または [Colabノートブック](https://colab.research.google.com/github/openpipe/art-notebooks/blob/main/examples/2048/2048.ipynb) をご覧ください。

## なぜ Serverless RL なのか？

強化学習 (RL) は、自身で所有または直接レンタルしている GPU を含む、多くの種類のトレーニング設定で使用できる強力なトレーニング手法のセットです。Serverless RL は、RL ポストトレーニングにおいて以下の利点を提供します：

* **トレーニングコストの削減**: 共有 インフラストラクチャー を多くの ユーザー 間で多重化し、各ジョブのセットアップ プロセス をスキップし、アクティブにトレーニングしていないときは GPU コストを 0 までスケールダウンすることで、Serverless RL はトレーニングコストを大幅に削減します。
* **トレーニング時間の短縮**: 推論リクエストを多くの GPU に分散させ、必要なときに即座にトレーニング インフラストラクチャー をプロビジョニングすることで、Serverless RL はトレーニングジョブをスピードアップし、より迅速な反復を可能にします。
* **自動デプロイメント**: Serverless RL はトレーニングするすべての チェックポイント を自動的に デプロイ するため、ホスティング インフラストラクチャー を手動でセットアップする必要がありません。トレーニングされた モデル は、ローカル、ステージング、または プロダクション 環境 ですぐに アクセス してテストできます。

## Serverless RL が W&B サービスをどのように使用するか

Serverless RL は、以下の W&B コンポーネントを組み合わせて動作します：

* [Inference](/inference): モデル の実行
* [Models](/models): LoRA アダプターのトレーニング中のパフォーマンス メトリクス の追跡
* [Artifacts](/models/artifacts): LoRA アダプターの保存と バージョン 管理
* [Weave (任意)](/weave): トレーニングループの各ステップで モデル がどのように応答するかを可視化（オブザーバビリティ）

Serverless RL はパブリックプレビュー中です。プレビュー期間中、課金対象となるのは推論の使用と Artifacts のストレージのみです。W&B はプレビュー期間中のアダプターのトレーニングに対しては課金しません。