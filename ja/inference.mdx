---
title: W&B Inference
description: W&B Weave と OpenAI 互換 API を通じて、オープンソースの基盤 モデル に アクセス する
mode: wide
---

W&B Inference を使用すると、W&B Weave および OpenAI 互換の API を通じて、主要なオープンソースの基盤 Models にアクセスできます。以下のことが可能です。

- ホスティングプロバイダーへの登録や自前での Model ホスティングを行うことなく、AI アプリケーションやエージェントを構築できます
- [W&B Weave Playground](/weave/guides/tools/playground) で [サポートされている Models](/inference/models) を試すことができます

Weave を使用すると、W&B Inference を活用したアプリケーションのトレース、評価、モニタリング、改善を行うことができます。


## クイックスタート

Python を使用した簡単な例を以下に示します。

```python
import openai

client = openai.OpenAI(
    # カスタム base URL は W&B Inference を指します
    base_url='https://api.inference.wandb.ai/v1',

    # https://wandb.ai/settings で APIキー を作成してください
    api_key="<your-api-key>",

    # オプション: 使用状況を追跡するための Team と Project
    project="<your-team>/<your-project>",
)

response = client.chat.completions.create(
    model="meta-llama/Llama-3.1-8B-Instruct",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Tell me a joke."}
    ],
)

print(response.choices[0].message.content)
```

## 次のステップ

1. [利用可能な Models](/inference/models) と [使用方法および制限](/inference/usage-limits/) を確認する
2. [事前準備](/inference/prerequisites/) ガイドに従ってアカウントを設定する
3. [API](/inference/api-reference/) または [UI](/inference/ui-guide/) を通じてサービスを利用する
4. [使用例](/inference/examples/) を試す

## 使用詳細

<Info>

料金、使用制限、クレジットに関する情報は、[使用方法および制限](/inference/usage-limits/) を参照してください。
</Info>