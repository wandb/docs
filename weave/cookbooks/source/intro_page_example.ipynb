{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parallel Evaluation with W&B Weave\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wandb/docs/blob/main/weave/cookbooks/source/parallel_evaluation_example.ipynb)\n",
        "\n",
        "This notebook demonstrates how to use W&B Weave to send math questions to OpenAI and evaluate the responses for correctness in parallel.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation\n",
        "\n",
        "First, install the required packages:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install weave openai -qU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup API Keys\n",
        "\n",
        "Add your W&B and OpenAI API keys:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Set your OpenAI API key\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "# Log in to W&B\n",
        "import wandb\n",
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parallel Evaluation Example\n",
        "\n",
        "Run the evaluation example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import weave\n",
        "from openai import OpenAI\n",
        "from weave import Scorer\n",
        "import asyncio\n",
        "\n",
        "# Initialize Weave\n",
        "weave.init(\"parallel-evaluation\")\n",
        "\n",
        "# Create OpenAI client\n",
        "client = OpenAI()\n",
        "\n",
        "# Define your model as a weave.op function\n",
        "@weave.op\n",
        "def math_model(question: str) -> str:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": question}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Create a dataset with questions and expected answers\n",
        "dataset = [\n",
        "    {\"question\": \"What is 2+2?\", \"expected\": \"4\"},\n",
        "    {\"question\": \"What is 5+3?\", \"expected\": \"8\"},\n",
        "    {\"question\": \"What is 10-7?\", \"expected\": \"3\"},\n",
        "    {\"question\": \"What is 12*3?\", \"expected\": \"36\"},\n",
        "    {\"question\": \"What is 100/4?\", \"expected\": \"25\"},\n",
        "]\n",
        "\n",
        "# Define a class-based scorer\n",
        "class CorrectnessScorer(Scorer):\n",
        "    \"\"\"Scorer that checks if the answer is correct\"\"\"\n",
        "    \n",
        "    @weave.op\n",
        "    def score(self, question: str, expected: str, output: str) -> dict:\n",
        "        \"\"\"Check if the model output contains the expected answer\"\"\"\n",
        "        import re\n",
        "        \n",
        "        # Extract numbers from the output\n",
        "        numbers = re.findall(r'\\d+', output)\n",
        "        \n",
        "        if numbers:\n",
        "            answer = numbers[0]\n",
        "            correct = answer == expected\n",
        "        else:\n",
        "            correct = False\n",
        "        \n",
        "        return {\n",
        "            \"correct\": correct,\n",
        "            \"extracted_answer\": numbers[0] if numbers else None,\n",
        "            \"contains_expected\": expected in output\n",
        "        }\n",
        "\n",
        "# Instantiate the scorer\n",
        "correctness_scorer = CorrectnessScorer()\n",
        "\n",
        "# Create an evaluation\n",
        "evaluation = weave.Evaluation(\n",
        "    dataset=dataset,\n",
        "    scorers=[correctness_scorer]\n",
        ")\n",
        "\n",
        "# Run the evaluation - automatically evaluates examples in parallel\n",
        "await evaluation.evaluate(math_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Note for Google Colab Users\n",
        "\n",
        "If you're running this notebook in Google Colab, you may need to handle async differently. Use this version instead:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For Google Colab, use this approach:\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Then run the evaluation\n",
        "asyncio.run(evaluation.evaluate(math_model))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View Results\n",
        "\n",
        "After running the evaluation, you can view the results in the W&B Weave dashboard. The evaluation shows:\n",
        "\n",
        "1. **Parallel execution**: All examples are evaluated simultaneously for faster results\n",
        "2. **Correctness scores**: Each response is scored based on whether it contains the correct answer\n",
        "3. **Detailed metrics**: Including extracted answers and whether the expected value was found\n",
        "\n",
        "Visit your [W&B Weave dashboard](https://wandb.ai/home) to explore the evaluation results in detail.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
