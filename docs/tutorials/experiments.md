


# å®Ÿé¨“ã‚’è¿½è·¡ã™ã‚‹


[**ã“ã¡ã‚‰ã®Colabãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã† â†’**](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Intro_to_Weights_&_Biases.ipynb)

è¿…é€Ÿãªå®Ÿé¨“ã¯æ©Ÿæ¢°å­¦ç¿’ã«ãŠã„ã¦åŸºæœ¬ã§ã™ã€‚ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€W&Bã‚’ä½¿ç”¨ã—ã¦å®Ÿé¨“ã‚’è¿½è·¡ã—ã€å¯è¦–åŒ–ã™ã‚‹ã“ã¨ã§ã€çµæœã‚’è¿…é€Ÿã«åå¾©ã—ç†è§£ã—ã¾ã™ã€‚

## ğŸ¤© å®Ÿé¨“ã®ãŸã‚ã®å…±æœ‰ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

ã»ã‚“ã®æ•°è¡Œã®ã‚³ãƒ¼ãƒ‰ã§ã€ãƒªãƒƒãƒã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªå…±æœ‰å¯èƒ½ãªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚[ã“ã¡ã‚‰ã§è‡ªåˆ†ã§è¦‹ã‚‹ã“ã¨ãŒã§ãã¾ã™](https://wandb.ai/wandb/wandb_example)ã€‚
![](https://i.imgur.com/Pell4Oo.png)


## ğŸ”’ ãƒ‡ãƒ¼ã‚¿ã¨ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼

ç§ãŸã¡ã¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’éå¸¸ã«é‡è¦è¦–ã—ã¦ãŠã‚Šã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ›ã‚¹ãƒˆã•ã‚ŒãŸãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã¯æ¥­ç•Œæ¨™æº–ã®æš—å·åŒ–ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¼æ¥­ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‹ã‚‰å¤–ã«å‡ºã™ã“ã¨ãŒã§ããªã„å ´åˆã€[ã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹](https://docs.wandb.com/self-hosted)ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚‚åˆ©ç”¨å¯èƒ½ã§ã™ã€‚

ã¾ãŸã€ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä»–ã®ãƒ„ãƒ¼ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ã®ã‚‚ç°¡å˜ã§ã™ â€” Jupyterãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã®ã‚«ã‚¹ã‚¿ãƒ åˆ†æãªã©ã€‚ã“ã¡ã‚‰ã«[APIã®è©³ç´°ãŒã‚ã‚Šã¾ã™](https://docs.wandb.com/library/api)ã€‚

---

## ğŸª„ `wandb`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ãƒ­ã‚°ã‚¤ãƒ³


ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ç„¡æ–™ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¸ã®ãƒ­ã‚°ã‚¤ãƒ³ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚




```python
!pip install wandb -qU
```


```python
# W&Bã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³
import wandb
wandb.login()
```

## ğŸ‘Ÿ å®Ÿé¨“ã‚’å®Ÿè¡Œã™ã‚‹
1ï¸âƒ£. **æ–°ã—ã„runã‚’é–‹å§‹ã—**ã€è¿½è·¡ã™ã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’æ¸¡ã—ã¾ã™

2ï¸âƒ£. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¾ãŸã¯è©•ä¾¡ã‹ã‚‰**ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ­ã‚°ã—ã¾ã™**

3ï¸âƒ£. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§**çµæœã‚’å¯è¦–åŒ–ã—ã¾ã™**


```python
import random

# 5ã¤ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã•ã‚ŒãŸå®Ÿé¨“ã‚’é–‹å§‹
total_runs = 5
for run in range(total_runs):
  # ğŸ 1ï¸âƒ£ ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’è¿½è·¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„runã‚’é–‹å§‹
  wandb.init(
      # ã“ã®runãŒãƒ­ã‚°ã•ã‚Œã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’è¨­å®š
      project="basic-intro", 
      # runåã‚’æ¸¡ã—ã¾ã™ï¼ˆã•ã‚‚ãªã‘ã‚Œã°ã€sunshine-lollypop-10ã®ã‚ˆã†ã«ãƒ©ãƒ³ãƒ€ãƒ ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¾ã™ï¼‰
      name=f"experiment_{run}", 
      # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã¨runãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½è·¡
      config={
      "learning_rate": 0.02,
      "architecture": "CNN",
      "dataset": "CIFAR-100",
      "epochs": 10,
      })
  
  # ã“ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ–ãƒ­ãƒƒã‚¯ã¯ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ­ã‚°ã™ã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã¾ã™
  epochs = 10
  offset = random.random() / 5
  for epoch in range(2, epochs):
      acc = 1 - 2 ** -epoch - random.random() / epoch - offset
      loss = 2 ** -epoch + random.random() / epoch + offset
      
      # ğŸ 2ï¸âƒ£ ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰W&Bã«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ­ã‚°
      wandb.log({"acc": acc, "loss": loss})
      
  # runã‚’çµ‚äº†ã¨ã—ã¦ãƒãƒ¼ã‚¯
  wandb.finish()
```

3ï¸âƒ£ ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ä¸Šè¨˜ã®ğŸ‘†W&Bã®ãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

# ğŸ”¥ ã‚·ãƒ³ãƒ—ãƒ«ãªPytorchãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯

ğŸ’ª ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã—ã¦ã‚·ãƒ³ãƒ—ãƒ«ãªMNISTåˆ†é¡å™¨ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒšãƒ¼ã‚¸ã®ãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€W&Bãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãƒ©ã‚¤ãƒ–ã§çµæœãŒã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã•ã‚Œã‚‹æ§˜å­ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚

`wandb`å†…ã®ä»»æ„ã®runã¯ã€è‡ªå‹•çš„ã«[ãƒ¡ãƒˆãƒªã‚¯ã‚¹](https://docs.wandb.ai/ref/app/pages/run-page#charts-tab)ã€[ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±](https://docs.wandb.ai/ref/app/pages/run-page#system-tab)ã€[ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼](https://docs.wandb.ai/ref/app/pages/run-page#overview-tab)ã€[ç«¯æœ«å‡ºåŠ›](https://docs.wandb.ai/ref/app/pages/run-page#logs-tab)ã€ãŠã‚ˆã³ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ã¨å‡ºåŠ›ã‚’æŒã¤[ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ†ãƒ¼ãƒ–ãƒ«](https://docs.wandb.ai/guides/tables)ã‚’ãƒ­ã‚°ã—ã¾ã™ã€‚

## Dataloaderã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

ã“ã®ä¾‹ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€PyTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Google Colabã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã¯ã€ã™ã§ã«ãƒ—ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã™ã€‚


```python
!pip install torch torchvision
```


```python
import wandb
import math
import random
import torch, torchvision
import torch.nn as nn
import torchvision.transforms as T

device = "cuda:0" if torch.cuda.is_available() else "cpu"

def get_dataloader(is_train, batch_size, slice=5):
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°dataloaderã‚’å–å¾—"
    full_dataset = torchvision.datasets.MNIST(root=".", train=is_train, transform=T.ToTensor(), download=True)
    sub_dataset = torch.utils.data.Subset(full_dataset, indices=range(0, len(full_dataset), slice))
    loader = torch.utils.data.DataLoader(dataset=sub_dataset, 
                                         batch_size=batch_size, 
                                         shuffle=True if is_train else False, 
                                         pin_memory=True, num_workers=2)
    return loader

def get_model(dropout):
    "ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«"
    model = nn.Sequential(nn.Flatten(),
                         nn.Linear(28*28, 256),
                         nn.BatchNorm1d(256),
                         nn.ReLU(),
                         nn.Dropout(dropout),
                         nn.Linear(256,10)).to(device)
    return model

def validate_model(model, valid_dl, loss_func, log_images=False, batch_idx=0):
    "æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸Šã§ã®ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è¨ˆç®—ã—ã€wandb.Tableã‚’ãƒ­ã‚°"
    model.eval()
    val_loss = 0.
    with torch.inference_mode():
        correct = 0
        for i, (images, labels) in enumerate(valid_dl):
            images, labels = images.to(device), labels.to(device)

            # Forward pass â¡
            outputs = model(images)
            val_loss += loss_func(outputs, labels)*labels.size(0)

            # ç²¾åº¦ã‚’è¨ˆç®—ã—ã€ç´¯ç©
            _, predicted = torch.max(outputs.data, 1)
            correct += (predicted == labels).sum().item()

            # dashboardã«1ãƒãƒƒãƒã®ç”»åƒã‚’ãƒ­ã‚°ã€å¸¸ã«åŒã˜batch_idx
            if i==batch_idx and log_images:
                log_image_table(images, predicted, labels, outputs.softmax(dim=1))
    return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)

def log_image_table(images, predicted, labels, probs):
    "wandb.Tableã«ï¼ˆç”»åƒã€äºˆæ¸¬ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã€ã‚¹ã‚³ã‚¢ï¼‰ã‚’ãƒ­ã‚°"
    # ğŸ ç”»åƒã€ãƒ©ãƒ™ãƒ«ã€äºˆæ¸¬ã‚’ãƒ­ã‚°ã™ã‚‹ãŸã‚ã®wandb Tableã‚’ä½œæˆ
    table = wandb.Table(columns=["image", "pred", "target"]+[f"score_{i}" for i in range(10)])
    for img, pred, targ, prob in zip(images.to("cpu"), predicted.to("cpu"), labels.to("cpu"), probs.to("cpu")):
        table.add_data(wandb.Image(img[0].numpy()*255), pred, targ, *prob.numpy())
    wandb.log({"predictions_table":table}, commit=False)
```

## ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹


```python
# ç•°ãªã‚‹ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡ã‚’è©¦ã—ã¦5ã¤ã®å®Ÿé¨“ã‚’é–‹å§‹
for _ in range(5):
    # ğŸ wandb runã‚’åˆæœŸåŒ–
    wandb.init(
        project="pytorch-intro",
        config={
            "epochs": 10,
            "batch_size": 128,
            "lr": 1e-3,
            "dropout": random.uniform(0.01, 0.80),
            })
    
    # è¨­å®šã‚’ã‚³ãƒ”ãƒ¼
    config = wandb.config

    # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    train_dl = get_dataloader(is_train=True, batch_size=config.batch_size)
    valid_dl = get_dataloader(is_train=False, batch_size=2*config.batch_size)
    n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)
    
    # ã‚·ãƒ³ãƒ—ãƒ«ãªMLPãƒ¢ãƒ‡ãƒ«
    model = get_model(config.dropout)

    # æå¤±é–¢æ•°ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã‚’ä½œæˆ
    loss_func = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)

   # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
    example_ct = 0
    step_ct = 0
    for epoch in range(config.epochs):
        model.train()
        for step, (images, labels) in enumerate(train_dl):
            imagesã€labels = images.to(device)ã€labels.to(device)

            outputs = model(images)
            train_loss = loss_func(outputs, labels)
            optimizer.zero_grad()
            train_loss.backward()
            optimizer.step()
            
            example_ct += len(images)
            metrics = {"train/train_loss": train_loss, 
                       "train/epoch": (step + 1 + (n_steps_per_epoch * epoch)) / n_steps_per_epoch, 
                       "train/example_ct": example_ct}
            
            if step + 1 < n_steps_per_epoch:
                # ğŸ trainãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’wandbã«ãƒ­ã‚°
                wandb.log(metrics)
                
            step_ct += 1

        val_lossã€accuracy = validate_model(modelã€valid_dlã€loss_funcã€log_images=(epoch==(config.epochs-1)))

        # ğŸ trainãŠã‚ˆã³validationãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’wandbã«ãƒ­ã‚°
        val_metrics = {"val/val_loss": val_loss, 
                       "val/val_accuracy": accuracy}
        wandb.log({**metrics, **val_metrics})
        
        print(f"Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}")

    # ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆãŒã‚ã‚Œã°ã€Summaryãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ã—ã¦ãƒ­ã‚°ã™ã‚‹
    wandb.summary['test_accuracy'] = 0.8

    # ğŸ wandb runã‚’ã‚¯ãƒ­ãƒ¼ã‚º
    wandb.finish()
```

ã“ã‚Œã§wandbã‚’ä½¿ç”¨ã—ã¦æœ€åˆã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã—ãŸï¼ğŸ‘† ä¸Šè¨˜ã®W&Bãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

# ğŸ”” W&B Alertsã‚’è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†

**[W&B Alerts](https://docs.wandb.ai/guides/track/alert)**ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€Pythonã‚³ãƒ¼ãƒ‰ã‹ã‚‰ãƒˆãƒªã‚¬ãƒ¼ã•ã‚Œã‚‹ã‚¢ãƒ©ãƒ¼ãƒˆã‚’Slackã‚„ãƒ¡ãƒ¼ãƒ«ã«é€ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚åˆã‚ã¦Slackã‚„ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ã‚³ãƒ¼ãƒ‰ã‹ã‚‰é€ä¿¡ã—ãŸã„å ´åˆã¯ã€æ¬¡ã®2ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

1) W&Bã®[ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š](https://wandb.ai/settings)ã§Alertsã‚’ã‚ªãƒ³ã«ã—ã¾ã™

2) ã‚³ãƒ¼ãƒ‰ã«`wandb.alert()`ã‚’è¿½åŠ ã—ã¾ã™ï¼š

```python
wandb.alert(
    title="Low accuracy", 
    text=f"Accuracy is below the acceptable threshold"
)
```

`wandb.alert`ã®ä½¿ç”¨æ–¹æ³•ã‚’ç¤ºã™æœ€å°é™ã®ä¾‹ã‚’ä»¥ä¸‹ã«ç¤ºã—ã¾ã™ã€‚**[W&B Alertsã®ãƒ•ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã“ã¡ã‚‰](https://docs.wandb.ai/guides/track/alert)**


```python
# wandb runã‚’é–‹å§‹
wandb.init(project="pytorch-intro")

# ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
acc_threshold = 0.3
for training_step in range(1000):

    # æ­£ç¢ºæ€§ã®ãŸã‚ã«ãƒ©ãƒ³ãƒ€ãƒ ãªæ•°å€¤ã‚’ç”Ÿæˆ
    accuracy = round(random.random() + random.random(), 3)
    print(f'Accuracy is: {accuracy}, {acc_threshold}')
    
    # ğŸ æ­£ç¢ºæ€§ã‚’wandbã«ãƒ­ã‚°
    wandb.log({"Accuracy": accuracy})

    # ğŸ”” æ­£ç¢ºæ€§ãŒã—ãã„å€¤ã‚’ä¸‹å›ã£ãŸå ´åˆã€W&B Alertã‚’ç™ºè¡Œã—runã‚’åœæ­¢
    if accuracy <= acc_threshold:
        # ğŸ wandb Alertã‚’é€ä¿¡
        wandb.alert(
            title='Low Accuracy',
            text=f'Accuracy {accuracy} at step {training_step} is below the acceptable threshold, {acc_threshold}',
        )
        print('Alert triggered')
        break

# runã‚’çµ‚äº†ã¨ã—ã¦ãƒãƒ¼ã‚¯ï¼ˆJupyterãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯æœ‰ç”¨ï¼‰
wandb.finish()
```


# æ¬¡ã¯ï¼Ÿ
æ¬¡ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€W&B Tablesã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’è¡¨ç¤ºãŠã‚ˆã³åˆ†æã™ã‚‹æ–¹æ³•ã‚’å­¦ã³ã¾ã™ã€‚
## ğŸ‘‰ [ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã‚’è¡¨ç¤ºãŠã‚ˆã³åˆ†æ](tables)