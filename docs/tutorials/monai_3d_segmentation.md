import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { CTAButtons } from '@site/src/components/CTAButtons/CTAButtons.tsx';


# 3Dè„³è…«ç˜ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ with MONAI

<CTAButtons colabLink="https://colab.research.google.com/github/wandb/examples/blob/main/colabs/monai/3d_brain_tumor_segmentation.ipynb"></CTAButtons>

ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã¯ã€[MONAI](https://github.com/Project-MONAI/MONAI) ã‚’ä½¿ç”¨ã—ã¦ãƒãƒ«ãƒãƒ©ãƒ™ãƒ«ã®3Dè„³è…«ç˜ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰ã—ã€[Weights & Biases](https://wandb.ai/site) ã®å®Ÿé¨“ç®¡ç†ã¨ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–æ©Ÿèƒ½ã‚’åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã«ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ãŒå«ã¾ã‚Œã¦ã„ã¾ã™:

1. Weights & Biases ã® run ã‚’åˆæœŸåŒ–ã—ã€å†ç¾æ€§ã®ãŸã‚ã« run ã«é–¢é€£ã™ã‚‹ã™ã¹ã¦ã®è¨­å®šã‚’åŒæœŸã—ã¾ã™ã€‚
2. MONAI ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ  API:
    1. è¾æ›¸å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚ã® MONAI ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ ã€‚
    2. MONAI `transforms` API ã«å¾“ã£ã¦æ–°ã—ã„ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ ã‚’å®šç¾©ã™ã‚‹æ–¹æ³•ã€‚
    3. ãƒ‡ãƒ¼ã‚¿å¢—å¼·ã®ãŸã‚ã«å¼·åº¦ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«èª¿æ•´ã™ã‚‹æ–¹æ³•ã€‚
3. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å¯è¦–åŒ–:
    1. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ `Nifti` ç”»åƒã‚’èª­ã¿è¾¼ã¿ã€ç”»åƒãƒªã‚¹ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚¹ã‚¿ãƒƒã‚¯ã—ã¾ã™ã€‚
    2. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¤œè¨¼ã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã«ã€IOã¨ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚
    3. Weights & Biases ã§ `wandb.Table` ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–ã—ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’è¡Œã„ã¾ã™ã€‚
4. 3D `SegResNet` ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
    1. MONAI ã® `networks`, `losses`, `metrics` API ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
    2. PyTorch ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½¿ç”¨ã—ã¦ 3D `SegResNet` ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚
    3. Weights & Biases ã‚’ä½¿ç”¨ã—ã¦å®Ÿé¨“ã‚’è¿½è·¡ã—ã¾ã™ã€‚
    4. ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ¢ãƒ‡ãƒ«Artifactsã¨ã—ã¦ãƒ­ã‚°ãŠã‚ˆã³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã—ã¾ã™ã€‚
5. Weights & Biases ã§ `wandb.Table` ã‚’ä½¿ç”¨ã—ã¦æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®äºˆæ¸¬çµæœã‚’å¯è¦–åŒ–ãŠã‚ˆã³æ¯”è¼ƒã—ã¾ã™ã€‚

## ğŸŒ´ ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

ã¾ãšã€æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã® MONAI ã¨ Weights & Biases ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```python
!python -c "import monai" || pip install -q -U "monai[nibabel, tqdm]"
!python -c "import wandb" || pip install -q -U wandb
```

```python
import os

import numpy as np
from tqdm.auto import tqdm
import wandb

from monai.apps import DecathlonDataset
from monai.data import DataLoader, decollate_batch
from monai.losses import DiceLoss
from monai.inferers import sliding_window_inference
from monai.metrics import DiceMetric
from monai.networks.nets import SegResNet
from monai.transforms import (
    Activations,
    AsDiscrete,
    Compose,
    LoadImaged,
    MapTransform,
    NormalizeIntensityd,
    Orientationd,
    RandFlipd,
    RandScaleIntensityd,
    RandShiftIntensityd,
    RandSpatialCropd,
    Spacingd,
    EnsureTyped,
    EnsureChannelFirstd,
)
from monai.utils import set_determinism

import torch
```

æ¬¡ã«ã€Colabã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’èªè¨¼ã—ã¦W&Bã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

```python
wandb.login()
```

## ğŸŒ³ W&B Run ã®åˆæœŸåŒ–

æ–°ã—ã„ W&B run ã‚’é–‹å§‹ã—ã¦ã€å®Ÿé¨“ã®è¿½è·¡ã‚’é–‹å§‹ã—ã¾ã™ã€‚

```python
wandb.init(project="monai-brain-tumor-segmentation")
```

é©åˆ‡ãªè¨­å®šã‚·ã‚¹ãƒ†ãƒ ã®ä½¿ç”¨ã¯ã€å†ç¾å¯èƒ½ãªæ©Ÿæ¢°å­¦ç¿’ã®ãŸã‚ã®æ¨å¥¨ã•ã‚Œã‚‹ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã§ã™ã€‚W&Bã‚’ä½¿ç”¨ã—ã¦ã€ã™ã¹ã¦ã®å®Ÿé¨“ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’è¿½è·¡ã§ãã¾ã™ã€‚

```python
config = wandb.config
config.seed = 0
config.roi_size = [224, 224, 144]
config.batch_size = 1
config.num_workers = 4
config.max_train_images_visualized = 20
config.max_val_images_visualized = 20
config.dice_loss_smoothen_numerator = 0
config.dice_loss_smoothen_denominator = 1e-5
config.dice_loss_squared_prediction = True
config.dice_loss_target_onehot = False
config.dice_loss_apply_sigmoid = True
config.initial_learning_rate = 1e-4
config.weight_decay = 1e-5
config.max_train_epochs = 50
config.validation_intervals = 1
config.dataset_dir = "./dataset/"
config.checkpoint_dir = "./checkpoints"
config.inference_roi_size = (128, 128, 64)
config.max_prediction_images_visualized = 20
```

ã¾ãŸã€ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®šã—ã€æ±ºå®šçš„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æœ‰åŠ¹ã¾ãŸã¯ç„¡åŠ¹ã«ã—ã¾ã™ã€‚

```python
set_determinism(seed=config.seed)

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
os.makedirs(config.dataset_dir, exist_ok=True)
os.makedirs(config.checkpoint_dir, exist_ok=True)
```

## ğŸ’¿ ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å¤‰æ›

ã“ã“ã§ã¯ã€`monai.transforms` API ã‚’ä½¿ç”¨ã—ã¦ã€ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã‚’ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆå½¢å¼ã§ãƒãƒ«ãƒãƒ©ãƒ™ãƒ«ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã«å¤‰æ›ã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ ã‚’ä½œæˆã—ã¾ã™ã€‚

```python
class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):
    """
    è„³è…«ç˜ã‚¯ãƒ©ã‚¹ã«åŸºã¥ã„ã¦ãƒ©ãƒ™ãƒ«ã‚’ãƒãƒ«ãƒãƒãƒ£ãƒãƒ«ã«å¤‰æ›:
    label 1 ã¯è…«ç˜å‘¨è¾ºã®æµ®è…«
    label 2 ã¯å¢—å¼·ã•ã‚ŒãŸè…«ç˜
    label 3 ã¯å£Šæ­»ã—ã¦ã„ã‚‹ã¾ãŸã¯éå¢—å¼·ã•ã‚ŒãŸè…«ç˜æ ¸
    å¯èƒ½ãªã‚¯ãƒ©ã‚¹ã¯ TC (è…«ç˜æ ¸), WT (å…¨è…«ç˜)
    ã¾ãŸã¯ ET (å¢—å¼·ã•ã‚ŒãŸè…«ç˜)ã€‚

    å‚è€ƒ: https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/brats_segmentation_3d.ipynb
    """

    def __call__(self, data):
        d = dict(data)
        for key in self.keys:
            result = []
            # label 2 ã¨ label 3 ã‚’ãƒãƒ¼ã‚¸ã—ã¦ TC ã‚’æ§‹ç¯‰
            result.append(torch.logical_or(d[key] == 2, d[key] == 3))
            # label 1, 2, 3 ã‚’ãƒãƒ¼ã‚¸ã—ã¦ WT ã‚’æ§‹ç¯‰
            result.append(
                torch.logical_or(
                    torch.logical_or(d[key] == 2, d[key] == 3), d[key] == 1
                )
            )
            # label 2 ã¯ ET
            result.append(d[key] == 2)
            d[key] = torch.stack(result, axis=0).float()
        return d
```

æ¬¡ã«ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¤œè¨¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãã‚Œãã‚Œã«å¯¾ã—ã¦ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¨­å®šã—ã¾ã™ã€‚

```python
train_transform = Compose(
    [
        # 4ã¤ã®Niftiç”»åƒã‚’èª­ã¿è¾¼ã¿ã€ä¸€ç·’ã«ã‚¹ã‚¿ãƒƒã‚¯ã—ã¾ã™
        LoadImaged(keys=["image", "label"]),
        EnsureChannelFirstd(keys="image"),
        EnsureTyped(keys=["image", "label"]),
        ConvertToMultiChannelBasedOnBratsClassesd(keys="label"),
        Orientationd(keys=["image", "label"], axcodes="RAS"),
        Spacingd(
            keys=["image", "label"],
            pixdim=(1.0, 1.0, 1.0),
            mode=("bilinear", "nearest"),
        ),
        RandSpatialCropd(
            keys=["image", "label"], roi_size=config.roi_size, random_size=False
        ),
        RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=0),
        RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=1),
        RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=2),
        NormalizeIntensityd(keys="image", nonzero=True, channel_wise=True),
        RandScaleIntensityd(keys="image", factors=0.1, prob=1.0),
        RandShiftIntensityd(keys="image", offsets=0.1, prob=1.0),
    ]
)
val_transform = Compose(
    [
        LoadImaged(keys=["image", "label"]),
        EnsureChannelFirstd(keys="image"),
        EnsureTyped(keys=["image", "label"]),
        ConvertToMultiChannelBasedOnBratsClassesd(keys="label"),
        Orientationd(keys=["image", "label"], axcodes="RAS"),
        Spacingd(
            keys=["image", "label"],
            pixdim=(1.0, 1.0, 1.0),
            mode=("bilinear", "nearest"),
        ),
        NormalizeIntensityd(keys="image", nonzero=True, channel_wise=True),
    ]
)
```

### ğŸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

ã“ã®å®Ÿé¨“ã§ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ http://medicaldecathlon.com/ ã‹ã‚‰å–å¾—ã•ã‚ŒãŸã‚‚ã®ã§ã™ã€‚FLAIRã€T1wã€T1gdã€T2w ãªã©ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªãƒãƒ«ãƒã‚µã‚¤ãƒˆ MRI ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€éå¢—å¼·/æ´»å‹•è…«ç˜ã€å£Šæ­»éƒ¨ä½ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯åˆè¨ˆ750 ã®4Dãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° 484 + ãƒ†ã‚¹ãƒˆ 266ï¼‰ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚

`DecathlonDataset` ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è‡ªå‹•çš„ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£å‡ã—ã¾ã™ã€‚ã“ã‚Œã¯ MONAI ã® `CacheDataset` ã‚’ç¶™æ‰¿ã—ã¦ãŠã‚Šã€`cache_num=N` ã‚’ã‚»ãƒƒãƒˆã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«Nå€‹ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã€æ¤œè¨¼ç”¨ã«ã¯ãƒ¡ãƒ¢ãƒªã‚µã‚¤ã‚ºã«å¿œã˜ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å¼•æ•°ã‚’ä½¿ç”¨ã—ã¦ã™ã¹ã¦ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§ãã¾ã™ã€‚

```python
train_dataset = DecathlonDataset(
    root_dir=config.dataset_dir,
    task="Task01_BrainTumour",
    transform=val_transform,
    section="training",
    download=True,
    cache_rate=0.0,
    num_workers=4,
)
val_dataset = DecathlonDataset(
    root_dir=config.dataset_dir,
    task="Task01_BrainTumour",
    transform=val_transform,
    section="validation",
    download=False,
    cache_rate=0.0,
    num_workers=4,
)
```

:::info
**Note:** `train_transform` ã‚’ `train_dataset` ã«é©ç”¨ã™ã‚‹ä»£ã‚ã‚Šã«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸¡ã‚¹ãƒ—ãƒªãƒƒãƒˆã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚ºã™ã‚‹å‰ã«ã€æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸¡æ–¹ã« `val_transform` ã‚’é©ç”¨ã—ã¾ã™ã€‚
:::

### ğŸ“¸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å¯è¦–åŒ–

Weights & Biases ã¯ç”»åƒã€ãƒ“ãƒ‡ã‚ªã€éŸ³å£°ãªã©ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚çµæœã‚’è¦–è¦šçš„ã«æ¯”è¼ƒã—ãªãŒã‚‰ãƒªãƒƒãƒãƒ¡ãƒ‡ã‚£ã‚¢ã‚’ãƒ­ã‚°ã™ã‚‹ã“ã¨ã§ã€runã€ãƒ¢ãƒ‡ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ¢æ±‚ã§ãã¾ã™ã€‚[ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚·ã‚¹ãƒ†ãƒ ](https://docs.wandb.ai/guides/track/log/media#image-overlays-in-tables) ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚Segmentationãƒã‚¹ã‚¯ã‚’ [tables](https://docs.wandb.ai/guides/tables) ã«ãƒ­ã‚°ã™ã‚‹ã«ã¯ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®å„è¡Œã« `wandb.Image` ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æä¾›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

ä¾‹ã¯ä»¥ä¸‹ã®ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰ã«ç¤ºã•ã‚Œã¦ã„ã¾ã™:

```python
table = wandb.Table(columns=["ID", "Image"])

for id, img, label in zip(ids, images, labels):
    mask_img = wandb.Image(
        img,
        masks={
            "prediction": {"mask_data": label, "class_labels": class_labels}
            # ...
        },
    )

    table.add_data(id, img)

wandb.log({"Table": table})
```

æ¬¡ã«ã€ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã€ãƒ©ãƒ™ãƒ«ã€`wandb.Table` ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€ãŠã‚ˆã³é–¢é€£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€Weights & Biases ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«ãƒ­ã‚°ã•ã‚Œã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡Œã‚’åŸ‹ã‚ã‚‹ç°¡å˜ãªãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚

```python
def log_data_samples_into_tables(
    sample_image: np.array,
    sample_label: np.array,
    split: str = None,
    data_idx: int = None,
    table: wandb.Table = None,
):
    num_channels, _, _, num_slices = sample_image.shape
    with tqdm(total=num_slices, leave=False) as progress_bar:
        for slice_idx in range(num_slices):
            ground_truth_wandb_images = []
            for channel_idx in range(num_channels):
                ground_truth_wandb_images.append(
                    masks = {
                        "ground-truth/Tumor-Core": {
                            "mask_data": sample_label[0, :, :, slice_idx],
                            "class_labels": {0: "background", 1: "Tumor Core"},
                        },
                        "ground-truth/Whole-Tumor": {
                            "mask_data": sample_label[1, :, :, slice_idx] * 2,
                            "class_labels": {0: "background", 2: "Whole Tumor"},
                        },
                        "ground-truth/Enhancing-Tumor": {
                            "mask_data": sample_label[2, :, :, slice_idx] * 3,
                            "class_labels": {0: "background", 3: "Enhancing Tumor"},
                        },
                    }
                    wandb.Image(
                        sample_image[channel_idx, :, :, slice_idx],
                        masks=masks,
                    )
                )
            table.add_data(split, data_idx, slice_idx, *ground_truth_wandb_images)
            progress_bar.update(1)
    return table
```

æ¬¡ã«ã€`wandb.Table` ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ãã®åˆ—ã‚’å®šç¾©ã—ã€ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã§è¡Œã‚’åŸ‹ã‚ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

```python
table = wandb.Table(
    columns=[
        "Split",
        "Data Index",
        "Slice Index",
        "Image-Channel-0",
        "Image-Channel-1",
        "Image-Channel-2",
        "Image-Channel-3",
    ]
)
```

ãã‚Œã‹ã‚‰ã€`train_dataset` ã¨ `val_dataset` ãã‚Œãã‚Œã‚’ãƒ«ãƒ¼ãƒ—ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã®å¯è¦–åŒ–ã‚’ç”Ÿæˆã—ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡Œã‚’åŸ‹ã‚ã¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«ãƒ­ã‚°ã‚’ä½œæˆã—ã¾ã™ã€‚

```python
# train_dataset ã®å¯è¦–åŒ–ã‚’ç”Ÿæˆ
max_samples = (
    min(config.max_train_images_visualized, len(train_dataset))
    if config.max_train_images_visualized > 0
    else len(train_dataset)
)
progress_bar = tqdm(
    enumerate(train_dataset[:max_samples]),
    total=max_samples,
    desc="Generating Train Dataset Visualizations:",
)
for data_idx, sample in progress_bar:
    sample_image = sample["image"].detach().cpu().numpy()
    sample_label = sample["label"].detach().cpu().numpy()
    table = log_data_samples_into_tables(
        sample_image,
        sample_label,
        split="train",
        data_idx=data_idx,
        table=table,
    )

# val_dataset ã®å¯è¦–åŒ–ã‚’ç”Ÿæˆ
max_samples = (
    min(config.max_val_images_visualized, len(val_dataset))
    if config.max_val_images_visualized > 0
    else len(val_dataset)
)
progress_bar = tqdm(
    enumerate(val_dataset[:max_samples]),
    total=max_samples,
    desc="Generating Validation Dataset Visualizations:",
)
for data_idx, sample in progress_bar:
    sample_image = sample["image"].detach().cpu().numpy()
    sample_label = sample["label"].detach().cpu().numpy()
    table = log_data_samples_into_tables(
        sample_image,
        sample_label,
        split="val",
        data_idx=data_idx,
        table=table,
    )

# ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«ãƒ­ã‚°
wandb.log({"Tumor-Segmentation-Data": table})
```

ãƒ‡ãƒ¼ã‚¿ã¯ W&B ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä¸Šã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªè¡¨å½¢å¼ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚å„ãƒãƒ£ãƒãƒ«ã®ç‰¹å®šã®ã‚¹ãƒ©ã‚¤ã‚¹ã‚’ç¢ºèªã—ã€ãã‚Œãã‚Œã®è¡Œã«ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ãŒã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã•ã‚ŒãŸã‚‚ã®ã‚’è¦‹ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚[Weave queries](https://docs.wandb.ai/guides/weave) ã‚’ä½¿ç”¨ã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«å†…ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã€ç‰¹å®šã®è¡Œã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

| ![An example of logged table data.](@site/static/images/tutorials/monai/viz-1.gif) | 
|:--:| 
| **ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ã‚°ä¾‹ã§ã™ã€‚** |

ç”»åƒã‚’é–‹ã„ã¦ã€ãã‚Œãã‚Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ã¨ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã™ã‚‹æ–¹æ³•ã‚’ç¢ºèªã—ã¾ã™ã€‚

| ![An example of visualized segmentation maps.](@site/static/images/tutorials/monai/viz-2.gif) | 
|:--:| 
| **ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒƒãƒ—ã®å¯è¦–åŒ–ä¾‹ã§ã™ã€‚** |

:::info
**Note:** ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ©ãƒ™ãƒ«ã¯ã€ã‚¯ãƒ©ã‚¹é–“ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã—ãªã„ãƒã‚¹ã‚¯ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã¯ã€ãƒ©ãƒ™ãƒ«ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤å†…ã®åˆ¥ã®ãƒã‚¹ã‚¯ã¨ã—ã¦ãƒ­ã‚°ã—ã¾ã™ã€‚
:::

### ğŸ›« ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã® PyTorch DataLoaders ã‚’ä½œæˆã—ã¾ã™ã€‚DataLoaders ã‚’ä½œæˆã™ã‚‹å‰ã«ã€`train_dataset` ã« `train_transform` ã‚’è¨­å®šã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ã—å¤‰æ›ã—ã¾ã™ã€‚

```python
# train_transforms ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é©ç”¨
train_dataset.transform = train_transform

# train_loader ã‚’ä½œæˆ
train_loader = DataLoader(
    train_dataset,
    batch_size=config.batch_size,
    shuffle=True,
    num_workers=config.num_workers,
)

# val_loader ã‚’ä½œæˆ
val_loader = DataLoader(
    val_dataset,
    batch_size