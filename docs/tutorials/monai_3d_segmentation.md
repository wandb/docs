import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { CTAButtons } from '@site/src/components/CTAButtons/CTAButtons.tsx';


# 3Dè„³è…«ç˜ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ with MONAI

<CTAButtons colabLink="https://colab.research.google.com/github/wandb/examples/blob/main/colabs/monai/3d_brain_tumor_segmentation.ipynb"></CTAButtons>

ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€[MONAI](https://github.com/Project-MONAI/MONAI)ã‚’ä½¿ç”¨ã—ã¦ã€3Dè„³è…«ç˜ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰ã—ã€[Weights & Biases](https://wandb.ai/site)ã®å®Ÿé¨“è¿½è·¡ã¨ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã«ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ãŒå«ã¾ã‚Œã¾ã™ï¼š

1. Weights & Biasesã®runã‚’åˆæœŸåŒ–ã—ã€å†ç¾æ€§ã®ãŸã‚ã«runã«é–¢é€£ã™ã‚‹ã™ã¹ã¦ã®è¨­å®šã‚’åŒæœŸåŒ–ã—ã¾ã™ã€‚
2. MONAIã®å¤‰æ›APIï¼š
    1. è¾æ›¸å½¢å¼ãƒ‡ãƒ¼ã‚¿ç”¨ã®MONAIå¤‰æ›ã€‚
    2. MONAIã®`transforms` APIã«åŸºã¥ã„ã¦æ–°ã—ã„å¤‰æ›ã‚’å®šç¾©ã™ã‚‹æ–¹æ³•ã€‚
    3. ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®ãŸã‚ã«å¼·åº¦ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«èª¿æ•´ã™ã‚‹æ–¹æ³•ã€‚
3. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å¯è¦–åŒ–ï¼š
    1. `Nifti`ç”»åƒã‚’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãã§èª­ã¿è¾¼ã¿ã€ç”»åƒãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿ã‚¹ã‚¿ãƒƒã‚¯ã™ã‚‹ã€‚
    2. IOã¨å¤‰æ›ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¤œè¨¼ã‚’é«˜é€ŸåŒ–ã™ã‚‹ã€‚
    3. `wandb.Table`ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–ã—ã€Weights & Biasesã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’è¡Œã†ã€‚
4. 3D `SegResNet`ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼š
    1. MONAIã® `networks`ã€`losses`ã€ãŠã‚ˆã³`metrics` APIã‚’ä½¿ç”¨ã™ã‚‹ã€‚
    2. PyTorchã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½¿ç”¨ã—ã¦3D `SegResNet`ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã€‚
    3. Weights & Biasesã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿé¨“ã‚’è¿½è·¡ã™ã‚‹ã€‚
    4. Weights & Biasesã«ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ­ã‚°ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã™ã‚‹ã€‚
5. æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®äºˆæ¸¬ã‚’`wandb.Table`ã¨Weights & Biasesã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’ä½¿ç”¨ã—ã¦å¯è¦–åŒ–ãŠã‚ˆã³æ¯”è¼ƒã™ã‚‹ã€‚

## ğŸŒ´ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

ã¾ãšã€æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®MONAIã¨Weights and Biasesã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```python
!python -c "import monai" || pip install -q -U "monai[nibabel, tqdm]"
!python -c "import wandb" || pip install -q -U wandb
```

```python
import os

import numpy as np
from tqdm.auto import tqdm
import wandb

from monai.apps import DecathlonDataset
from monai.data import DataLoader, decollate_batch
from monai.losses import DiceLoss
from monai.inferers import sliding_window_inference
from monai.metrics import DiceMetric
from monai.networks.nets import SegResNet
from monai.transforms import (
    Activations,
    AsDiscrete,
    Compose,
    LoadImaged,
    MapTransform,
    NormalizeIntensityd,
    Orientationd,
    RandFlipd,
    RandScaleIntensityd,
    RandShiftIntensityd,
    RandSpatialCropd,
    Spacingd,
    EnsureTyped,
    EnsureChannelFirstd,
)
from monai.utils import set_determinism

import torch
```

æ¬¡ã«ã€Colabã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’W&Bã«èªè¨¼ã—ã¾ã™ã€‚

```python
wandb.login()
```

## ğŸŒ³ W&B Runã®åˆæœŸåŒ–

æ–°ã—ã„W&B runã‚’é–‹å§‹ã—ã¦å®Ÿé¨“ã‚’è¿½è·¡ã—ã¾ã™ã€‚

```python
wandb.init(project="monai-brain-tumor-segmentation")
```

é©åˆ‡ãªæ§‹æˆã‚·ã‚¹ãƒ†ãƒ ã®ä½¿ç”¨ã¯ã€å†ç¾æ€§ã®ã‚ã‚‹æ©Ÿæ¢°å­¦ç¿’ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¨ã—ã¦æ¨å¥¨ã•ã‚Œã¾ã™ã€‚W&Bã‚’ä½¿ç”¨ã—ã¦å„å®Ÿé¨“ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’è¿½è·¡ã§ãã¾ã™ã€‚

```python
config = wandb.config
config.seed = 0
config.roi_size = [224, 224, 144]
config.batch_size = 1
config.num_workers = 4
config.max_train_images_visualized = 20
config.max_val_images_visualized = 20
config.dice_loss_smoothen_numerator = 0
config.dice_loss_smoothen_denominator = 1e-5
config.dice_loss_squared_prediction = True
config.dice_loss_target_onehot = False
config.dice_loss_apply_sigmoid = True
config.initial_learning_rate = 1e-4
config.weight_decay = 1e-5
config.max_train_epochs = 50
config.validation_intervals = 1
config.dataset_dir = "./dataset/"
config.checkpoint_dir = "./checkpoints"
config.inference_roi_size = (128, 128, 64)
config.max_prediction_images_visualized = 20
```

ã¾ãŸã€ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®šã—ã¦ã€æ±ºå®šè«–çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æœ‰åŠ¹ã¾ãŸã¯ç„¡åŠ¹ã«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```python
set_determinism(seed=config.seed)

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
os.makedirs(config.dataset_dir, exist_ok=True)
os.makedirs(config.checkpoint_dir, exist_ok=True)
```

## ğŸ’¿ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å¤‰æ›

ã“ã“ã§ã¯ã€`monai.transforms` APIã‚’ä½¿ç”¨ã—ã¦ã€ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã‚’ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆå½¢å¼ã®ãƒãƒ«ãƒãƒ©ãƒ™ãƒ«ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã«å¤‰æ›ã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ å¤‰æ›ã‚’ä½œæˆã—ã¾ã™ã€‚

```python
class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):
    """
    Bratsã‚¯ãƒ©ã‚¹ã«åŸºã¥ã„ã¦ãƒ©ãƒ™ãƒ«ã‚’ãƒãƒ«ãƒãƒãƒ£ãƒ³ãƒãƒ«ã«å¤‰æ›ã—ã¾ã™ï¼š
    ãƒ©ãƒ™ãƒ«1ã¯è…«ç˜å‘¨è¾ºæµ®è…«
    ãƒ©ãƒ™ãƒ«2ã¯GDå¢—å¼·è…«ç˜
    ãƒ©ãƒ™ãƒ«3ã¯å£Šæ­»ãŠã‚ˆã³éå¢—å¼·è…«ç˜æ ¸
    å¯èƒ½ãªã‚¯ãƒ©ã‚¹ã¯TCï¼ˆè…«ç˜æ ¸ï¼‰ã€WTï¼ˆå…¨è…«ç˜ï¼‰
    ãŠã‚ˆã³ETï¼ˆå¢—å¼·è…«ç˜ï¼‰ã§ã™ã€‚

    å‚è€ƒ: https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/brats_segmentation_3d.ipynb
    """

    def __call__(self, data):
        d = dict(data)
        for key in self.keys:
            result = []
            # ãƒ©ãƒ™ãƒ«2ã¨ãƒ©ãƒ™ãƒ«3ã‚’çµåˆã—ã¦TCã‚’æ§‹ç¯‰
            result.append(torch.logical_or(d[key] == 2, d[key] == 3))
            # ãƒ©ãƒ™ãƒ«1ã€2ã€3ã‚’çµåˆã—ã¦WTã‚’æ§‹ç¯‰
            result.append(
                torch.logical_or(
                    torch.logical_or(d[key] == 2, d[key] == 3), d[key] == 1
                )
            )
            # ãƒ©ãƒ™ãƒ«2ã¯ET
            result.append(d[key] == 2)
            d[key] = torch.stack(result, axis=0).float()
        return d
```

æ¬¡ã«ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”¨ã®å¤‰æ›ã‚’ãã‚Œãã‚Œè¨­å®šã—ã¾ã™ã€‚

```python
train_transform = Compose(
    [
        # 4ã¤ã®Niftiç”»åƒã‚’èª­ã¿è¾¼ã¿ä¸€ç·’ã«ã‚¹ã‚¿ãƒƒã‚¯ã™ã‚‹
        LoadImaged(keys=["image", "label"]),
        EnsureChannelFirstd(keys="image"),
        EnsureTyped(keys=["image", "label"]),
        ConvertToMultiChannelBasedOnBratsClassesd(keys="label"),
        Orientationd(keys=["image", "label"], axcodes="RAS"),
        Spacingd(
            keys=["image", "label"],
            pixdim=(1.0, 1.0, 1.0),
            mode=("bilinear", "nearest"),
        ),
        RandSpatialCropd(
            keys=["image", "label"], roi_size=config.roi_size, random_size=False
        ),
        RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=0),
        RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=1),
        RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=2),
        NormalizeIntensityd(keys="image", nonzero=True, channel_wise=True),
        RandScaleIntensityd(keys="image", factors=0.1, prob=1.0),
        RandShiftIntensityd(keys="image", offsets=0.1, prob=1.0),
    ]
)
val_transform = Compose(
    [
        LoadImaged(keys=["image", "label"]),
        EnsureChannelFirstd(keys="image"),
        EnsureTyped(keys=["image", "label"]),
        ConvertToMultiChannelBasedOnBratsClassesd(keys="label"),
        Orientationd(keys=["image", "label"], axcodes="RAS"),
        Spacingd(
            keys=["image", "label"],
            pixdim=(1.0, 1.0, 1.0),
            mode=("bilinear", "nearest"),
        ),
        NormalizeIntensityd(keys="image", nonzero=True, channel_wise=True),
    ]
)
```

### ğŸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

ã“ã®å®Ÿé¨“ã§ä½¿ç”¨ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯http://medicaldecathlon.com/ã‹ã‚‰å–å¾—ã•ã‚Œã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€å¤šæ–½è¨­ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«MRIãƒ‡ãƒ¼ã‚¿ï¼ˆFLAIRã€T1wã€T1gdã€T2wï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ç¥çµŒè† è…«ã€å£Šæ­»/æ´»å‹•çš„è…«ç˜ã€ãŠã‚ˆã³æµ®è…«ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯750ã®4Dãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆ484ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°+ 266ãƒ†ã‚¹ãƒˆï¼‰ãŒå«ã¾ã‚Œã¾ã™ã€‚

`DecathlonDataset`ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è‡ªå‹•çš„ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦æŠ½å‡ºã—ã¾ã™ã€‚ã“ã‚Œã¯MONAIã®`CacheDataset`ã‚’ç¶™æ‰¿ã—ã¦ãŠã‚Šã€ãƒ¡ãƒ¢ãƒªã‚µã‚¤ã‚ºã«å¿œã˜ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«`cache_num=N`ã‚’è¨­å®šã—ã¦`N`é …ç›®ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã€æ¤œè¨¼ç”¨ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å…¨é …ç›®ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§ãã¾ã™ã€‚

```python
train_dataset = DecathlonDataset(
    root_dir=config.dataset_dir,
    task="Task01_BrainTumour",
    transform=val_transform,
    section="training",
    download=True,
    cache_rate=0.0,
    num_workers=4,
)
val_dataset = DecathlonDataset(
    root_dir=config.dataset_dir,
    task="Task01_BrainTumour",
    transform=val_transform,
    section="validation",
    download=False,
    cache_rate=0.0,
    num_workers=4,
)
```

:::info
**æ³¨æ„:** `train_dataset`ã«`train_transform`ã‚’é©ç”¨ã›ãšã«ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸¡æ–¹ã«`val_transform`ã‚’é©ç”¨ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å‰ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸¡æ–¹ã®åˆ†å‰²ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’è¦–è¦šåŒ–ã™ã‚‹ãŸã‚ã§ã™ã€‚
:::

### ğŸ“¸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å¯è¦–åŒ–

Weights & Biasesã¯ç”»åƒã€ãƒ“ãƒ‡ã‚ªã€ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãªã©ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€çµæœã‚’æ¢æ±‚ã—ã€runã€ãƒ¢ãƒ‡ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¦–è¦šçš„ã«æ¯”è¼ƒã™ã‚‹ãŸã‚ã®ãƒªãƒƒãƒãƒ¡ãƒ‡ã‚£ã‚¢ã‚’ãƒ­ã‚°ã«æ®‹ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’å¯è¦–åŒ–ã™ã‚‹ãŸã‚ã«[ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚·ã‚¹ãƒ†ãƒ ](https://docs.wandb.ai/guides/track/log/media#image-overlays-in-tables)ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚[ãƒ†ãƒ¼ãƒ–ãƒ«](https://docs.wandb.ai/guides/tables)ã«ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ã‚’ãƒ­ã‚°ã«æ®‹ã™ãŸã‚ã«ã¯ã€å„è¡Œã«`wandb.Image`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æä¾›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

æ“¬ä¼¼ã‚³ãƒ¼ãƒ‰ã®ä¾‹ã‚’ä»¥ä¸‹ã«ç¤ºã—ã¾ã™ï¼š

```python
table = wandb.Table(columns=["ID", "Image"])

for id, img, label in zip(ids, images, labels):
    mask_img = wandb.Image(
        img,
        masks={
            "prediction": {"mask_data": label, "class_labels": class_labels}
            # ...
        },
    )

    table.add_data(id, img)

wandb.log({"Table": table})
```

æ¬¡ã«ã€ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã€ãƒ©ãƒ™ãƒ«ã€`wandb.Table`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€ãŠã‚ˆã³é–¢é€£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€Weights & Biasesãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«ãƒ­ã‚°ã™ã‚‹ãŸã‚ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡Œã‚’å…¥åŠ›ã™ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã‚’æ›¸ãã¾ã™ã€‚

```python
def log_data_samples_into_tables(
    sample_image: np.array,
    sample_label: np.array,
    split: str = None,
    data_idx: int = None,
    table: wandb.Table = None,
):
    num_channels, _, _, num_slices = sample_image.shape
    with tqdm(total=num_slices, leave=False) as progress_bar:
        for slice_idx in range(num_slices):
            ground_truth_wandb_images = []
            for channel_idx in range(num_channels):
                ground_truth_wandb_images.append(
                    masks = {
                        "ground-truth/Tumor-Core": {
                            "mask_data": sample_label[0, :, :, slice_idx],
                            "class_labels": {0: "background", 1: "Tumor Core"},
                        },
                        "ground-truth/Whole-Tumor": {
                            "mask_data": sample_label[1, :, :, slice_idx] * 2,
                            "class_labels": {0: "background", 2: "Whole Tumor"},
                        },
                        "ground-truth/Enhancing-Tumor": {
                            "mask_data": sample_label[2, :, :, slice_idx] * 3,
                            "class_labels": {0: "background", 3: "Enhancing Tumor"},
                        },
                    }
                    wandb.Image(
                        sample_image[channel_idx, :, :, slice_idx],
                        masks=masks,
                    )
                )
            table.add_data(split, data_idx, slice_idx, *ground_truth_wandb_images)
            progress_bar.update(1)
    return table
```

æ¬¡ã«ã€`wandb.Table`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ãã®åˆ—ã‚’å®šç¾©ã—ã€ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã§ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

```python
table = wandb.Table(
    columns=[
        "Split",
        "Data Index",
        "Slice Index",
        "Image-Channel-0",
        "Image-Channel-1",
        "Image-Channel-2",
        "Image-Channel-3",
    ]
)
```

æ¬¡ã«ã€ãã‚Œãã‚Œ`train_dataset`ã¨`val_dataset`ã‚’ãƒ«ãƒ¼ãƒ—ã‚ªãƒ¼ãƒãƒ¼ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã®å¯è¦–åŒ–ã‚’ç”Ÿæˆã—ã€ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«ãƒ­ã‚°ã‚’è¨˜å…¥ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡Œã‚’å…¥åŠ›ã—ã¾ã™ã€‚

```python
# train_datasetã®å¯è¦–åŒ–ã‚’ç”Ÿæˆ
max_samples = (
    min(config.max_train_images_visualized, len(train_dataset))
    if config.max_train_images_visualized > 0
    else len(train_dataset)
)
progress_bar = tqdm(
    enumerate(train_dataset[:max_samples]),
    total=max_samples,
    desc="Generating Train Dataset Visualizations:",
)
for data_idx, sample in progress_bar:
    sample_image = sample["image"].detach().cpu().numpy()
    sample_label = sample["label"].detach().cpu().numpy()
    table = log_data_samples_into_tables(
        sample_image,
        sample_label,
        split="train",
        data_idx=data_idx,
        table=table,
    )

# val_datasetã®å¯è¦–åŒ–ã‚’ç”Ÿæˆ
max_samples = (
    min(config.max_val_images_visualized, len(val_dataset))
    if config.max_val_images_visualized > 0
    else len(val_dataset)
)
progress_bar = tqdm(
    enumerate(val_dataset[:max_samples]),
    total=max_samples,
    desc="Generating Validation Dataset Visualizations:",
)
for data_idx, sample in progress_bar:
    sample_image = sample["image"].detach().cpu().numpy()
    sample_label = sample["label"].detach().cpu().numpy()
    table = log_data_samples_into_tables(
        sample_image,
        sample_label,
        split="val",
        data_idx=data_idx,
        table=table,
    )

# ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«ãƒ­ã‚°
wandb.log({"Tumor-Segmentation-Data": table})
```

ãƒ‡ãƒ¼ã‚¿ã¯W&Bãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚¿ãƒ–å½¢å¼ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®ç‰¹å®šã®ã‚¹ãƒ©ã‚¤ã‚¹ã®å„ãƒãƒ£ãƒ³ãƒãƒ«ã‚’ã€å„è¡Œã«ãã‚Œãã‚Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ã‚’é‡ã­åˆã‚ã›ãŸçŠ¶æ…‹ã§è¦‹ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã€ç‰¹å®šã®è¡Œã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ãŸã‚ã®[Weave queries](https://docs.wandb.ai/guides/weave)ã‚’æ›¸ãã“ã¨ãŒã§ãã¾ã™ã€‚

| ![An example of logged table data.](@site/static/images/tutorials/monai/viz-1.gif) | 
|:--:| 
| **An example of logged table data.** |

ç”»åƒã‚’é–‹ãã¨ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’ä½¿ç”¨ã—ã¦å„ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ã‚’æ“ä½œã™ã‚‹æ–¹æ³•ãŒã‚ã‹ã‚Šã¾ã™ã€‚

| ![An example of visualized segmentation maps.](@site/static/images/tutorials/monai/viz-2.gif) | 
|:--:| 
| **An example of visualized segmentation maps.** |

:::info
**æ³¨æ„:** ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ©ãƒ™ãƒ«ã¯ã‚¯ãƒ©ã‚¹é–“ã§éé‡è¤‡ãƒã‚¹ã‚¯ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã¯ãƒ©ãƒ™ãƒ«ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã§åˆ¥ã€…ã®ãƒã‚¹ã‚¯ã¨ã—ã¦ãƒ­ã‚°ã—ã¾ã™ã€‚
:::

### ğŸ›« ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿

PyTorch DataLoadersã‚’ä½œæˆã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚DataLoadersã‚’ä½œæˆã™ã‚‹å‰ã«ã€`train_dataset`ã®`transform`ã‚’`train_transform`ã«è¨­å®šã—ã¦ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ãŠã‚ˆã³å¤‰æ›ã—ã¾ã™ã€‚

```python
# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¤‰æ›ã‚’é©ç”¨
train_dataset.transform = train_transform

# train_loaderã‚’ä½œæˆ
train_loader = DataLoader(
    train_dataset,
    batch_size=config.batch_size,
    shuffle=True,
    num_workers=config.num_workers,
)

# val_loaderã‚’ä½œæˆ
val_loader = DataLoader(
   