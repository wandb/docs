---
title: Visualize predictions with tables
---
import { CTAButtons } from '@site/src/components/CTAButtons/CTAButtons.tsx'

<CTAButtons colabLink='https://colab.research.google.com/github/wandb/examples/blob/master/colabs/datasets-predictions/W&B_Tables_Quickstart.ipynb'/>

ì´ ë¬¸ì„œëŠ” PyTorchë¡œ MNIST ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë ˆì´ë‹ ê³¼ì •ì—ì„œ ëª¨ë¸ ì˜ˆì¸¡ê°’ì„ ì¶”ì í•˜ê³ , ì‹œê°í™”í•˜ë©° ë¹„êµí•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

ì—¬ëŸ¬ë¶„ì€ ë‹¤ìŒì„ ë°°ìš¸ ê²ƒì…ë‹ˆë‹¤:
1. ëª¨ë¸ íŠ¸ë ˆì´ë‹ ë˜ëŠ” í‰ê°€ ì¤‘ì— `wandb.Table()`ì— ë©”íŠ¸ë¦­, ì´ë¯¸ì§€, í…ìŠ¤íŠ¸ ë“±ì„ ë¡œê·¸í•˜ê¸°
2. ì´ í…Œì´ë¸”ë“¤ì„ ë³´ê¸°, ì •ë ¬, í•„í„°ë§, ê·¸ë£¹í™”, ì¡°ì¸, ì¸í„°ë™í‹°ë¸Œ ì¿¼ë¦¬ ë° íƒìƒ‰
3. ëª¨ë¸ ì˜ˆì¸¡ê°’ ë˜ëŠ” ê²°ê³¼ ë¹„êµ: íŠ¹ì • ì´ë¯¸ì§€, í•˜ì´í¼íŒŒë¼ë¯¸í„°/ëª¨ë¸ ë²„ì „, ë˜ëŠ” ì‹œê°„ ë‹¨ê³„ì— ë”°ë¼ ë™ì ìœ¼ë¡œ

## Examples
### íŠ¹ì • ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ ì ìˆ˜ ë¹„êµí•˜ê¸°

[ì‹¤ì‹œê°„ ì˜ˆì œ: 1 vs 5 ì—í¬í¬ íŠ¸ë ˆì´ë‹ í›„ ì˜ˆì¸¡ ë¹„êµí•˜ê¸° â†’](https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU#compare-predictions-after-1-vs-5-epochs)

![1 epoch vs 5 epochs of training](/images/tutorials/tables-1.png)

íˆìŠ¤í† ê·¸ë¨ì€ ë‘ ëª¨ë¸ ê°„ì˜ í´ë˜ìŠ¤ë³„ ì ìˆ˜ë¥¼ ë¹„êµí•©ë‹ˆë‹¤. ê° íˆìŠ¤í† ê·¸ë¨ì˜ ìƒë‹¨ ë…¹ìƒ‰ ë§‰ëŒ€ëŠ” "CNN-2, 1 epoch" (id 0) ëª¨ë¸ì„ ë‚˜íƒ€ë‚´ë©°, ì´ëŠ” 1 ì—í¬í¬ ë™ì•ˆë§Œ íŠ¸ë ˆì´ë‹ë˜ì—ˆìŠµë‹ˆë‹¤. í•˜ë‹¨ ë³´ë¼ìƒ‰ ë§‰ëŒ€ëŠ” "CNN-2, 5 epochs" (id 1) ëª¨ë¸ì„ ë‚˜íƒ€ë‚´ë©°, 5 ì—í¬í¬ ë™ì•ˆ íŠ¸ë ˆì´ë‹ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ëŠ” ëª¨ë¸ë“¤ì´ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°ë¡œ í•„í„°ë§ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì²« ë²ˆì§¸ í–‰ì—ì„œ "4"ëŠ” 1 ì—í¬í¬ í›„ ëª¨ë“  ê°€ëŠ¥í•œ ìˆ«ìì— ëŒ€í•´ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì•˜ì§€ë§Œ, 5 ì—í¬í¬ í›„ì—ëŠ” ì •í™•í•œ ë ˆì´ë¸”ì—ì„œ ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ê³  ë‚˜ë¨¸ì§€ì—ì„œëŠ” ë§¤ìš° ë‚®ì€ ì ìˆ˜ë¥¼ ë°›ìŠµë‹ˆë‹¤.

### ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ì£¼ìš” ì˜¤ë¥˜ì— ì§‘ì¤‘í•˜ê¸°
[ì‹¤ì‹œê°„ ì˜ˆì œ â†’](https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU#top-errors-over-time)

ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì˜ëª»ëœ ì˜ˆì¸¡ì„ í™•ì¸í•©ë‹ˆë‹¤("guess" != "truth"ì¸ í–‰ìœ¼ë¡œ í•„í„°ë§). 1 íŠ¸ë ˆì´ë‹ ì—í¬í¬ í›„ì—ëŠ” 229ê°œì˜ ì˜ëª»ëœ ì˜ˆì¸¡ì´ ìˆì§€ë§Œ, 5 ì—í¬í¬ í›„ì—ëŠ” 98ê°œë§Œ ë‚¨ìŠµë‹ˆë‹¤.

![side by side, 1 vs 5 epochs of training](/images/tutorials/tables-2.png)

### ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë° íŒ¨í„´ ì°¾ê¸°

[ì‹¤ì‹œê°„ ì˜ˆì œì—ì„œ ìì„¸íˆ ë³´ê¸° â†’](https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU#false-positives-grouped-by-guess)

ì •í™•í•œ ë‹µë³€ì€ í•„í„°ë§í•œ í›„, ì¶”ì¸¡ì— ë”°ë¼ ê·¸ë£¹í™”í•˜ì—¬ ì˜ëª» ë¶„ë¥˜ëœ ì´ë¯¸ì§€ì™€ ì‹¤ì œ ë ˆì´ë¸”ì˜ ë¶„í¬ë¥¼ ì–‘ì˜†ìœ¼ë¡œ ë¹„êµí•©ë‹ˆë‹¤. ë ˆì´ì–´ í¬ê¸°ì™€ í•™ìŠµë¥ ì´ 2ë°°ì¸ ëª¨ë¸ ë³€í˜•ì€ ì¢Œì¸¡ì—, ë² ì´ìŠ¤ë¼ì¸ì€ ìš°ì¸¡ì— ìœ„ì¹˜í•©ë‹ˆë‹¤. ë² ì´ìŠ¤ë¼ì¸ì€ ê° ì¶”ì¸¡ëœ í´ë˜ìŠ¤ì—ì„œ ì•½ê°„ ë” ë§ì€ ì‹¤ìˆ˜ë¥¼ í•œë‹¤ëŠ” ì ì„ ì£¼ëª©í•˜ì„¸ìš”.

![grouped errors for baseline vs double variant](/images/tutorials/tables-3.png)

## íšŒì›ê°€ì… ë˜ëŠ” ë¡œê·¸ì¸

W&Bì— [íšŒì›ê°€ì… ë˜ëŠ” ë¡œê·¸ì¸](https://wandb.ai/login)í•˜ì—¬ ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ ì‹¤í—˜ì„ ë³´ê³  ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ ì˜ˆì œì—ì„œëŠ” í¸ë¦¬í•œ í˜¸ìŠ¤íŒ… í™˜ê²½ìœ¼ë¡œ Google Colabì„ ì‚¬ìš©í•˜ê³  ìˆì§€ë§Œ, ì–´ë””ì„œë“  ìì‹ ì˜ íŠ¸ë ˆì´ë‹ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  W&Bì˜ ì‹¤í—˜ ì¶”ì  íˆ´ë¡œ ë©”íŠ¸ë¦­ì„ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
!pip install wandb -qqq
```

ê³„ì •ì— ë¡œê·¸

```python

import wandb
wandb.login()

WANDB_PROJECT = "mnist-viz"
```

## 0. ì„¤ì •

í•„ìˆ˜ ëª¨ë“ˆ ì„¤ì¹˜, MNIST ë‹¤ìš´ë¡œë“œ ë° PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë ˆì¸ê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.


```python
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as T 
import torch.nn.functional as F


device = "cuda:0" if torch.cuda.is_available() else "cpu"

# íŠ¸ë ˆì¸ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œë” ìƒì„±
def get_dataloader(is_train, batch_size, slice=5):
    "íŠ¸ë ˆì´ë‹ ë°ì´í„°ë¡œë” ê°€ì ¸ì˜¤ê¸°"
    ds = torchvision.datasets.MNIST(root=".", train=is_train, transform=T.ToTensor(), download=True)
    loader = torch.utils.data.DataLoader(dataset=ds, 
                                         batch_size=batch_size, 
                                         shuffle=True if is_train else False, 
                                         pin_memory=True, num_workers=2)
    return loader
```

## 1. ëª¨ë¸ ë° íŠ¸ë ˆì´ë‹ ìŠ¤ì¼€ì¤„ ì •ì˜

* ê° ì—í¬í¬ëŠ” íŠ¸ë ˆì´ë‹ ìŠ¤í…ê³¼ ê²€ì¦(í…ŒìŠ¤íŠ¸) ìŠ¤í…ìœ¼ë¡œ êµ¬ì„±ë˜ëŠ”ë°, ì´ë•Œ ì‹¤í–‰í•  ì—í¬í¬ ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ì„ íƒì ìœ¼ë¡œ, ê° í…ŒìŠ¤íŠ¸ ìŠ¤í…ë‹¹ ë¡œê·¸í•  ë°ì´í„°ì˜ ì–‘ì„ ì„¤ì •í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ë°ëª¨ë¥¼ ë‹¨ìˆœí™”í•˜ê¸° ìœ„í•´ ì‹œê°í™”í•  ë°°ì¹˜ ë° ì´ë¯¸ì§€ ìˆ˜ë¥¼ ë‚®ê²Œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.
* ê°„ë‹¨í•œ í•©ì„±ê³± ì‹ ê²½ë§ ì •ì˜ ([pytorch-tutorial](https://github.com/yunjey/pytorch-tutorial) ì½”ë“œ ì°¸ì¡°)
* PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë ˆì¸ ë° í…ŒìŠ¤íŠ¸ì…‹ ë¡œë“œ

```python
# ì‹¤í–‰í•  ì—í¬í¬ ìˆ˜
# ê° ì—í¬í¬ëŠ” íŠ¸ë ˆì´ë‹ ìŠ¤í…ê³¼ í…ŒìŠ¤íŠ¸ ìŠ¤í…ì„ í¬í•¨í•˜ë¯€ë¡œ, ì´ëŠ” ë¡œê·¸í•  í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ í…Œì´ë¸” ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤
EPOCHS = 1

# ê° í…ŒìŠ¤íŠ¸ ìŠ¤í…ë‹¹ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ë¡œê·¸í•  ë°°ì¹˜ ìˆ˜
# (ë°ëª¨ ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ê¸°ë³¸ê°’ì„ ë‚®ê²Œ ì„¤ì •)
NUM_BATCHES_TO_LOG = 10 #79

# ê° í…ŒìŠ¤íŠ¸ ë°°ì¹˜ë‹¹ ë¡œê·¸í•  ì´ë¯¸ì§€ ìˆ˜
# (ë°ëª¨ ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ê¸°ë³¸ê°’ì„ ë‚®ê²Œ ì„¤ì •)
NUM_IMAGES_PER_BATCH = 32 #128

# íŠ¸ë ˆì´ë‹ ì„¤ì • ë° í•˜ì´í¼íŒŒë¼ë¯¸í„°
NUM_CLASSES = 10
BATCH_SIZE = 32
LEARNING_RATE = 0.001
L1_SIZE = 32
L2_SIZE = 64
# ë³€ê²½ ì‹œì—ëŠ” ì¸ì ‘ ë ˆì´ì–´ì˜ ëª¨ì–‘ì„ ë³€ê²½í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
CONV_KERNEL_SIZE = 5

# ì´ì¤‘ ë ˆì´ì–´ í•©ì„±ê³± ì‹ ê²½ë§ ì •ì˜
class ConvNet(nn.Module):
    def __init__(self, num_classes=10):
        super(ConvNet, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, L1_SIZE, CONV_KERNEL_SIZE, stride=1, padding=2),
            nn.BatchNorm2d(L1_SIZE),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer2 = nn.Sequential(
            nn.Conv2d(L1_SIZE, L2_SIZE, CONV_KERNEL_SIZE, stride=1, padding=2),
            nn.BatchNorm2d(L2_SIZE),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.fc = nn.Linear(7*7*L2_SIZE, NUM_CLASSES)
        self.softmax = nn.Softmax(NUM_CLASSES)

    def forward(self, x):
        # ì£¼ì–´ì§„ ë ˆì´ì–´ì˜ ëª¨ì–‘ì„ ë³´ë ¤ë©´ ì£¼ì„ í•´ì œ:
        #print("x: ", x.size())
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.reshape(out.size(0), -1)
        out = self.fc(out)
        return out

train_loader = get_dataloader(is_train=True, batch_size=BATCH_SIZE)
test_loader = get_dataloader(is_train=False, batch_size=2*BATCH_SIZE)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
```

## 2. íŠ¸ë ˆì´ë‹ ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ê°’ ë¡œê·¸

ê° ì—í¬í¬ë§ˆë‹¤ íŠ¸ë ˆì´ë‹ ìŠ¤í…ê³¼ í…ŒìŠ¤íŠ¸ ìŠ¤í…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ê° í…ŒìŠ¤íŠ¸ ìŠ¤í…ë§ˆë‹¤, í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ê°’ì„ ì €ì¥í•  wandb.Table()ì„ ë§Œë“­ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë¸Œë¼ìš°ì €ì—ì„œ ì‹œê°í™”í•˜ê³ , ë™ì ìœ¼ë¡œ ì¿¼ë¦¬í•˜ê³ , ì˜†ìœ¼ë¡œ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
# âœ¨ W&B: ì´ ëª¨ë¸ì˜ íŠ¸ë ˆì´ë‹ì„ ì¶”ì í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ runì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤
wandb.init(project="table-quickstart")

# âœ¨ W&B: ì„¤ì •ì„ ì‚¬ìš©í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë¡œê·¸í•©ë‹ˆë‹¤
cfg = wandb.config
cfg.update({"epochs" : EPOCHS, "batch_size": BATCH_SIZE, "lr" : LEARNING_RATE,
            "l1_size" : L1_SIZE, "l2_size": L2_SIZE,
            "conv_kernel" : CONV_KERNEL_SIZE,
            "img_count" : min(10000, NUM_IMAGES_PER_BATCH*NUM_BATCHES_TO_LOG)})

# ëª¨ë¸, ì†ì‹¤, ì˜µí‹°ë§ˆì´ì € ì •ì˜
model = ConvNet(NUM_CLASSES).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë°°ì¹˜ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ì„ ë¡œê·¸í•˜ê¸° ìœ„í•œ í¸ì˜ í•¨ìˆ˜
def log_test_predictions(images, labels, outputs, predicted, test_table, log_counter):
  # ëª¨ë“  í´ë˜ìŠ¤ì— ëŒ€í•œ ì‹ ë¢° ì ìˆ˜ íšë“
  scores = F.softmax(outputs.data, dim=1)
  log_scores = scores.cpu().numpy()
  log_images = images.cpu().numpy()
  log_labels = labels.cpu().numpy()
  log_preds = predicted.cpu().numpy()
  # ì´ë¯¸ì§€ ìˆœì„œì— ë”°ë¼ id ì¶”ê°€
  _id = 0
  for i, l, p, s in zip(log_images, log_labels, log_preds, log_scores):
    # ë°ì´í„° í…Œì´ë¸”ì— í•„ìš”í•œ ì •ë³´ ì¶”ê°€:
    # id, ì´ë¯¸ì§€ í”½ì…€, ëª¨ë¸ì˜ ì¶”ì¸¡, ì‹¤ì œ ë ˆì´ë¸”, ëª¨ë“  í´ë˜ìŠ¤ì— ëŒ€í•œ ì ìˆ˜
    img_id = str(_id) + "_" + str(log_counter)
    test_table.add_data(img_id, wandb.Image(i), p, l, *s)
    _id += 1
    if _id == NUM_IMAGES_PER_BATCH:
      break

# ëª¨ë¸ íŠ¸ë ˆì´ë‹
total_step = len(train_loader)
for epoch in range(EPOCHS):
    # íŠ¸ë ˆì´ë‹ ìŠ¤í…
    for i, (images, labels) in enumerate(train_loader):
        images = images.to(device)
        labels = labels.to(device)
        # forward íŒ¨ìŠ¤
        outputs = model(images)
        loss = criterion(outputs, labels)
        # backward ë° ìµœì í™”
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
  
        # âœ¨ W&B: íŠ¸ë ˆì´ë‹ ë‹¨ê³„ ë™ì•ˆ ì†ì‹¤ì„ ë¡œê·¸í•˜ì—¬ UIì— ì‹¤ì‹œê°„ìœ¼ë¡œ ì‹œê°í™”
        wandb.log({"loss" : loss})
        if (i+1) % 100 == 0:
            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'
                .format(epoch+1, EPOCHS, i+1, total_step, loss.item()))
            

    # âœ¨ W&B: ê° í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ì„ ì €ì¥í•˜ê¸° ìœ„í•œ í…Œì´ë¸” ìƒì„±
    columns=["id", "image", "guess", "truth"]
    for digit in range(10):
      columns.append("score_" + str(digit))
    test_table = wandb.Table(columns=columns)

    # ëª¨ë¸ í…ŒìŠ¤íŠ¸
    model.eval()
    log_counter = 0
    with torch.no_grad():
        correct = 0
        total = 0
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            if log_counter < NUM_BATCHES_TO_LOG:
              log_test_predictions(images, labels, outputs, predicted, test_table, log_counter)
              log_counter += 1
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        acc = 100 * correct / total
        # âœ¨ W&B: íŠ¸ë ˆì´ë‹ ì—í¬í¬ ê°„ ì •í™•ë„ë¥¼ ë¡œê·¸í•˜ì—¬ UIì— ì‹œê°í™”
        wandb.log({"epoch" : epoch, "acc" : acc})
        print('Test Accuracy of the model on the 10000 test images: {} %'.format(acc))

    # âœ¨ W&B: ì˜ˆì¸¡ í…Œì´ë¸”ì„ wandbì— ë¡œê·¸
    wandb.log({"test_predictions" : test_table})

# âœ¨ W&B: runì„ ì™„ë£Œë¡œ í‘œì‹œ (ì—¬ëŸ¬ ì…€ ë…¸íŠ¸ë¶ì—ì„œ ìœ ìš©)
wandb.finish()
```

## ë‹¤ìŒ ë‹¨ê³„ëŠ”?
ë‹¤ìŒ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” W&B Sweepsë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™”í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤:
## ğŸ‘‰ [í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”í•˜ê¸°](sweeps)