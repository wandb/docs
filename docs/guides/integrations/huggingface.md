---
title: Hugging Face Transformers
displayed_sidebar: default
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { CTAButtons } from '@site/src/components/CTAButtons/CTAButtons.tsx';

<CTAButtons colabLink="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/huggingface/Optimize_Hugging_Face_models_with_Weights_&_Biases.ipynb"></CTAButtons>

[Hugging Face Transformers](https://huggingface.co/transformers/) ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” BERTì™€ ê°™ì€ ìµœì‹  NLP ëª¨ë¸ ë° í˜¼í•© ì •ë°€ë„ ë° ê·¸ë ˆì´ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…ê³¼ ê°™ì€ íŠ¸ë ˆì´ë‹ ê¸°ë²•ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. [W&B ì¸í…Œê·¸ë ˆì´ì…˜](https://huggingface.co/transformers/main_classes/callback.html#transformers.integrations.WandbCallback)ì€ ì¸í„°ë™í‹°ë¸Œí•œ ì¤‘ì•™ ì§‘ì¤‘ì‹ ëŒ€ì‹œë³´ë“œì— ì‹¤í—˜ ì¶”ì  ë° ëª¨ë¸ ë²„ì „ ê´€ë¦¬ë¥¼ ì¶”ê°€í•˜ì—¬ ì‚¬ìš©ì˜ ìš©ì´ì„±ì„ ì†ìƒì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤.

## ğŸ¤— ê°„ë‹¨í•œ ì½”ë“œë¡œ ì°¨ì› ë†’ì€ ë¡œê¹…

```python
os.environ["WANDB_PROJECT"] = "<my-amazing-project>"  # W&B í”„ë¡œì íŠ¸ ì´ë¦„ ì§€ì •
os.environ["WANDB_LOG_MODEL"] = "checkpoint"  # ëª¨ë“  ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œê·¸ ê¸°ë¡

from transformers import TrainingArguments, Trainer

args = TrainingArguments(..., report_to="wandb")  # W&B ë¡œê¹… í™œì„±í™”
trainer = Trainer(..., args=args)
```
![W&B ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œì—ì„œ ì‹¤í—˜ ê²°ê³¼ íƒìƒ‰](/images/integrations/huggingface_gif.gif)

:::info
ë°”ë¡œ ì‘ì—… ì½”ë“œì— ë›°ì–´ë“¤ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´, [Google Colab](https://wandb.me/hf)ì„ í™•ì¸í•´ë³´ì„¸ìš”.
:::

## ì‹œì‘í•˜ê¸°: ì‹¤í—˜ ì¶”ì í•˜ê¸°

### 1) íšŒì› ê°€ì…, `wandb` ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ë¡œê·¸ì¸

a) ë¬´ë£Œ ê³„ì •ì— [**ê°€ì…í•˜ì„¸ìš”**](https://wandb.ai/site)

b) `wandb` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ Pipìœ¼ë¡œ ì„¤ì¹˜í•˜ì‹­ì‹œì˜¤.

c) íŠ¸ë ˆì´ë‹ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ë¡œê·¸ì¸í•˜ë ¤ë©´ www.wandb.aiì—ì„œ ê³„ì •ì— ë¡œê·¸ì¸í•´ì•¼ í•˜ë©°, ê·¸ í›„ì— [**ìŠ¹ì¸ í˜ì´ì§€**](https://wandb.ai/authorize)ì—ì„œ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

Weights and Biasesë¥¼ ì²˜ìŒ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ì—ëŠ” [**í€µìŠ¤íƒ€íŠ¸**](../../quickstart.md)ë¥¼ í™•ì¸í•˜ì‹œëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

<Tabs
  defaultValue="cli"
  values={[
    {label: 'Python', value: 'python'},
    {label: 'Command Line', value: 'cli'},
  ]}>
  <TabItem value="cli">

```shell
pip install wandb

wandb login
```

  </TabItem>
  <TabItem value="python">

```notebook
!pip install wandb

import wandb
wandb.login()
```

  </TabItem>
</Tabs>

### 2) í”„ë¡œì íŠ¸ ì´ë¦„ ì„¤ì •

[Project](../app/pages/project-page.md)ëŠ” ê´€ë ¨ëœ runìœ¼ë¡œë¶€í„° ë¡œê¹…ëœ ëª¨ë“  ì°¨íŠ¸, ë°ì´í„°, ëª¨ë¸ì´ ì €ì¥ë˜ëŠ” ê³³ì…ë‹ˆë‹¤. í”„ë¡œì íŠ¸ì— ì´ë¦„ì„ ì§€ì •í•˜ë©´ ì‘ì—…ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ê³  ë‹¨ì¼ í”„ë¡œì íŠ¸ì— ëŒ€í•œ ëª¨ë“  ì •ë³´ë¥¼ í•œ ê³³ì—ì„œ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

í”„ë¡œì íŠ¸ì— runì„ ì¶”ê°€í•˜ë ¤ë©´ `WANDB_PROJECT` í™˜ê²½ ë³€ìˆ˜ë¥¼ í”„ë¡œì íŠ¸ ì´ë¦„ìœ¼ë¡œ ì„¤ì •í•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤. `WandbCallback`ì€ ì´ í”„ë¡œì íŠ¸ ì´ë¦„ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì¸ì‹í•˜ê³  run ì„¤ì • ì‹œ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.

<Tabs
  defaultValue="python"
  values={[
    {label: 'Python', value: 'python'},
    {label: 'Command Line', value: 'cli'},
    {label: 'Notebook', value: 'notebook'}
  ]}>
  <TabItem value="cli">

```bash
WANDB_PROJECT=amazon_sentiment_analysis
```

  </TabItem>
  <TabItem value="notebook">

```notebook
%env WANDB_PROJECT=amazon_sentiment_analysis
```

  </TabItem>
  <TabItem value="python">

```notebook
import os
os.environ["WANDB_PROJECT"]="amazon_sentiment_analysis"
```

  </TabItem>
</Tabs>

:::info
`Trainer`ë¥¼ ì´ˆê¸°í™”í•˜ê¸° _ì „ì—_ í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
:::

í”„ë¡œì íŠ¸ ì´ë¦„ì´ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ í”„ë¡œì íŠ¸ ì´ë¦„ì€ ê¸°ë³¸ì ìœ¼ë¡œ "huggingface"ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.

### 3) W&Bì— íŠ¸ë ˆì´ë‹ run ê¸°ë¡í•˜ê¸°

ì´ê²ƒì€ **ê°€ì¥ ì¤‘ìš”í•œ ë‹¨ê³„**ì…ë‹ˆë‹¤: `Trainer` íŠ¸ë ˆì´ë‹ ì¸ìˆ˜ë¥¼ ì½”ë“œ ë‚´ì—ì„œë“  ì»¤ë§¨ë“œë¼ì¸ì—ì„œë“  ì •ì˜í•  ë•Œ, Weights & Biasesë¡œ ë¡œê¹…ì„ í™œì„±í™”í•˜ë ¤ë©´ `report_to`ë¥¼ `"wandb"`ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.

`TrainingArguments`ì˜ `logging_steps` ì¸ìˆ˜ëŠ” íŠ¸ë ˆì´ë‹ ì¤‘ W&Bë¡œ ë©”íŠ¸ë¦­ì„ ì–¼ë§ˆë‚˜ ìì£¼ í‘¸ì‹œí• ì§€ë¥¼ ì œì–´í•©ë‹ˆë‹¤. `run_name` ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ W&Bì—ì„œ íŠ¸ë ˆì´ë‹ runì— ì´ë¦„ì„ ì§€ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

ê·¸ê²Œ ë‹¤ì…ë‹ˆë‹¤! ì´ì œ ëª¨ë¸ì´ íŠ¸ë ˆì´ë‹í•˜ëŠ” ë™ì•ˆ ì†ì‹¤, í‰ê°€ ë©”íŠ¸ë¦­, ëª¨ë¸ í† í´ë¡œì§€, ê·¸ë ˆì´ë””ì–¸íŠ¸ë¥¼ Weights & Biasesì— ë¡œê·¸ë¡œ ê¸°ë¡í•˜ê²Œ ë©ë‹ˆë‹¤.

<Tabs
  defaultValue="python"
  values={[
    {label: 'Python', value: 'python'},
    {label: 'Command Line', value: 'cli'},
  ]}>
  <TabItem value="cli">

```bash
python run_glue.py \     # Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
  --report_to wandb \    # W&Bë¡œ ë¡œê¹… í™œì„±í™”
  --run_name bert-base-high-lr \   # W&B run ì´ë¦„ (ì„ íƒ ì‚¬í•­)
  # ë‹¤ë¥¸ ì»¤ë§¨ë“œë¼ì¸ ì¸ìˆ˜ë“¤ì„ ì—¬ê¸°ì— ì…ë ¥
```

  </TabItem>
  <TabItem value="python">

```python
from transformers import TrainingArguments, Trainer

args = TrainingArguments(
    # ë‹¤ë¥¸ ì¸ìˆ˜ ë° kwargsëŠ” ì—¬ê¸°ì—
    report_to="wandb",  # W&Bë¡œ ë¡œê¹… í™œì„±í™”
    run_name="bert-base-high-lr",  # W&B run ì´ë¦„ (ì„ íƒ ì‚¬í•­)
    logging_steps=1,  # W&Bë¡œ ì–¼ë§ˆë‚˜ ìì£¼ ë¡œê·¸ë¥¼ ë‚¨ê¸¸ì§€
)

trainer = Trainer(
    # ë‹¤ë¥¸ ì¸ìˆ˜ ë° kwargsëŠ” ì—¬ê¸°ì—
    args=args,  # íŠ¸ë ˆì´ë‹ ì¸ìˆ˜
)

trainer.train()  # íŠ¸ë ˆì´ë‹ ë° W&Bë¡œì˜ ë¡œê¹… ì‹œì‘
```

  </TabItem>
</Tabs>

:::info
TensorFlowë¥¼ ì‚¬ìš©í•˜ì‹œë‚˜ìš”? PyTorch `Trainer` ëŒ€ì‹  TensorFlow `TFTrainer`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
:::

### 4) ëª¨ë¸ ì²´í¬í¬ì¸íŒ… í™œì„±í™”

Weights & Biasesì˜ [Artifacts](../artifacts)ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœëŒ€ 100GBì˜ ëª¨ë¸ ë° ë°ì´í„°ì…‹ì„ ë¬´ë£Œë¡œ ì €ì¥í•˜ê³  Weights & Biases [Model Registry](../model_registry)ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë“±ë¡í•˜ì—¬ ìŠ¤í…Œì´ì§• ë˜ëŠ” í”„ë¡œë•ì…˜ í™˜ê²½ì— ë°°í¬í•  ì¤€ë¹„ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

 Hugging Face ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ Artifactsì— ë¡œê·¸ê¸°ë¡œ ê¸°ë¡í•˜ë ¤ë©´ `WANDB_LOG_MODEL` í™˜ê²½ ë³€ìˆ˜ë¥¼ `end`, `checkpoint`, `false` ì¤‘ í•˜ë‚˜ë¡œ ì„¤ì •í•˜ì‹­ì‹œì˜¤.

-  **`checkpoint`**: [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments)ì—ì„œ `args.save_steps`ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ê°€ ì—…ë¡œë“œ ë©ë‹ˆë‹¤.
- **`end`**: íŠ¸ë ˆì´ë‹ì´ ëë‚˜ë©´ ëª¨ë¸ì´ ì—…ë¡œë“œ ë©ë‹ˆë‹¤.

`WANDB_LOG_MODEL`ì„ `load_best_model_at_end`ì™€ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ íŠ¸ë ˆì´ë‹ ì¢…ë£Œ ì‹œ ìµœê³ ì˜ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.

<Tabs
  defaultValue="python"
  values={[
    {label: 'Python', value: 'python'},
    {label: 'Command Line', value: 'cli'},
    {label: 'Notebook', value: 'notebook'},
  ]}>

  <TabItem value="python">

```python
import os

os.environ["WANDB_LOG_MODEL"] = "checkpoint"
```

  </TabItem>
  <TabItem value="cli">

```bash
WANDB_LOG_MODEL="checkpoint"
```

  </TabItem>
  <TabItem value="notebook">

```notebook
%env WANDB_LOG_MODEL="checkpoint"
```

  </TabItem>
</Tabs>

ì´ì œë¶€í„° ì´ˆê¸°í™”í•˜ëŠ” ëª¨ë“  Transformers `Trainer`ëŠ” W&B í”„ë¡œì íŠ¸ì— ëª¨ë¸ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤. ë¡œê·¸ë¡œ ê¸°ë¡í•œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ëŠ” [Artifacts](../artifacts) UIë¥¼ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆìœ¼ë©°, ì „ì²´ ëª¨ë¸ ê³„ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤ (UIì—ì„œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì˜ˆì œë¥¼ [ì—¬ê¸°ì„œ](https://wandb.ai/wandb/arttest/artifacts/model/iv3_trained/5334ab69740f9dda4fed/lineage?_gl=1*yyql5q*_ga*MTQxOTYyNzExOS4xNjg0NDYyNzk1*_ga_JH1SJHJQXJ*MTY5MjMwNzI2Mi4yNjkuMS4xNjkyMzA5NjM2LjM3LjAuMA..) í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤).

:::info
ê¸°ë³¸ì ìœ¼ë¡œ `WANDB_LOG_MODEL`ì´ `end`ë¡œ ì„¤ì •ë˜ì—ˆì„ ë•Œ ê·€í•˜ì˜ ëª¨ë¸ì€ `model-{run_id}`ë¡œ W&B Artifactsì— ì €ì¥ë˜ë©°, `checkpoint`ë¡œ ì„¤ì •ë˜ì—ˆì„ ë•ŒëŠ” `checkpoint-{run_id}`ë¡œ ì €ì¥ë©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ `TrainingArguments`ì˜ [`run_name`](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments.run_name)ì„ ì „ë‹¬í•˜ë©´ ëª¨ë¸ì€ `model-{run_name}` ë˜ëŠ” `checkpoint-{run_name}`ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.
:::

#### W&B ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
ì²´í¬í¬ì¸íŠ¸ë¥¼ Artifactsì— ë¡œê·¸í•œ í›„ì—ëŠ” ìµœê³ ì˜ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë“±ë¡í•˜ì—¬ íŒ€ ì „ì²´ì—ì„œ ì¤‘ì•™ ì§‘ì¤‘í™”í•˜ê³  Weights & Biases **[Model Registry](../model_registry)**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ ë‹¤ì–‘í•œ ì‘ì—…ë³„ë¡œ ìµœê³ ì˜ ëª¨ë¸ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ê³  ëª¨ë¸ ìƒëª… ì£¼ê¸°ë¥¼ ê´€ë¦¬í•˜ë©° ML ìƒëª… ì£¼ê¸° ì „ë°˜ì— ê±¸ì³ íš¨ìœ¨ì ì¸ ì¶”ì ê³¼ ê°ì‚¬ë¥¼ ìš©ì´í•˜ê²Œ í•˜ë©°, ì›¹í›…ì´ë‚˜ ì‘ì—…ìœ¼ë¡œ í›„ì† ì‘ì—…ì„ [ìë™í™”](/guides/artifacts/project-scoped-automations/#create-a-webhook-automation)í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

[Model Registry](../model_registry) ë¬¸ì„œì—ì„œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì™€ ì—°ê²°í•˜ëŠ” ë°©ë²•ì„ í™•ì¸í•˜ì„¸ìš”.

### 5) íŠ¸ë ˆì´ë‹ ì¤‘ í‰ê°€ ì¶œë ¥ ì‹œê°í™”í•˜ê¸° 

íŠ¸ë ˆì´ë‹ ë˜ëŠ” í‰ê°€ ì¤‘ ëª¨ë¸ ì¶œë ¥ì„ ì‹œê°í™”í•˜ëŠ” ê²ƒì€ ëª¨ë¸ íŠ¸ë ˆì´ë‹ ìƒíƒœë¥¼ ì´í•´í•˜ëŠ” ë° ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.

Transformers `Trainer`ì˜ ì½œë°± ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ í…ìŠ¤íŠ¸ ìƒì„± ì¶œë ¥ ë˜ëŠ” ë‹¤ë¥¸ ì˜ˆì¸¡ì„ W&B í…Œì´ë¸”ì— ê¸°ë¡í•˜ëŠ” ê²ƒê³¼ ê°™ì€ ì¶”ê°€ì ìœ¼ë¡œ ìœ ìš©í•œ ë°ì´í„°ë¥¼ W&Bì— ë¡œê·¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì—¬ê¸° ì•„ë˜ì˜ **[ì»¤ìŠ¤í…€ ë¡œê¹… ì„¹ì…˜](#custom-logging-log-and-view-evaluation-samples-during-training)**ì—ì„œ íŠ¸ë ˆì´ë‹ ì¤‘ í‰ê°€ ì¶œë ¥ì„ ë¡œê·¸í•˜ì—¬ ì´ì™€ ê°™ì€ W&B í…Œì´ë¸”ë¡œ ê¸°ë¡í•˜ëŠ” ì „ë¬¸ ê°€ì´ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.

![í‰ê°€ ì¶œë ¥ì´ í¬í•¨ëœ W&B í…Œì´ë¸”ì„ ë³´ì—¬ ì¤ë‹ˆë‹¤](/images/integrations/huggingface_eval_tables.png)

### 6) W&B Run ì™„ë£Œ (ë…¸íŠ¸ë¶ë§Œ í•´ë‹¹) 

íŠ¸ë ˆì´ë‹ì´ Python ìŠ¤í¬ë¦½íŠ¸ì— ìº¡ìŠí™”ë˜ì–´ ìˆëŠ” ê²½ìš°, ê·€í•˜ì˜ W&B runì€ ìŠ¤í¬ë¦½íŠ¸ê°€ ëë‚˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.

Jupyter ë˜ëŠ” Google Colab ë…¸íŠ¸ë¶ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, íŠ¸ë ˆì´ë‹ì´ ëë‚¬ì„ ë•Œ `wandb.finish()`ë¥¼ í˜¸ì¶œí•˜ì—¬ ì™„ë£Œë¥¼ ì•Œë ¤ì¤„ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.

```python
trainer.train()  # íŠ¸ë ˆì´ë‹ ì‹œì‘ ë° W&Bë¡œì˜ ë¡œê¹…

# ì‚¬í›„ ë¶„ì„, í…ŒìŠ¤íŠ¸, ê¸°íƒ€ ë¡œê·¸ëœ ì½”ë“œ

wandb.finish()
```

### 7) ê²°ê³¼ ì‹œê°í™”

íŠ¸ë ˆì´ë‹ ê²°ê³¼ë¥¼ ë¡œê·¸í–ˆìœ¼ë©´, ì´ì œ [W&B ëŒ€ì‹œë³´ë“œ](../track/app.md)ì—ì„œ ë™ì ìœ¼ë¡œ ê²°ê³¼ë¥¼ íƒìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ runì„ í•œ ë²ˆì— ë¹„êµí•˜ê³ , í¥ë¯¸ë¡œìš´ ë°œê²¬ì— ì§‘ì¤‘í•˜ë©°, ìœ ì—°í•œ ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™”ë¥¼ í†µí•´ ë³µì¡í•œ ë°ì´í„°ì—ì„œ ì¸ì‚¬ì´íŠ¸ë¥¼ ìœ ë„í•˜ëŠ” ê²Œ ë§¤ìš° ì‰½ìŠµë‹ˆë‹¤.

## ê³ ê¸‰ ê¸°ëŠ¥ê³¼ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ë“¤

### ìµœê³ ì˜ ëª¨ë¸ì„ ì €ì¥í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?
`TrainingArguments`ì—ì„œ `load_best_model_at_end=True`ë¡œ ì„¤ì •ëœ ê²½ìš°, W&BëŠ” ìµœê³ ì˜ ì„±ëŠ¥ì„ ë°œíœ˜í•œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ Artifactsì— ì €ì¥í•©ë‹ˆë‹¤.

ëª¨ë“  ìµœê³ ì˜ ëª¨ë¸ ë²„ì „ì„ íŒ€ ì „ì²´ì—ì„œ ì¤‘ì•™ ì§‘ì¤‘í™”í•˜ì—¬ ML ì‘ì—…ë³„ë¡œ ì •ë¦¬í•˜ê±°ë‚˜, í”„ë¡œë•ì…˜ ì¤€ë¹„ë¥¼ ìœ„í•´ ìŠ¤í…Œì´ì§•í•˜ê±°ë‚˜, ì¶”ê°€ í‰ê°€ë¥¼ ìœ„í•´ ë¶ë§ˆí¬í•˜ê±°ë‚˜, ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ëª¨ë¸ CI/CD í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•˜ë ¤ëŠ” ê²½ìš° ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ Artifactsì— ì €ì¥í•˜ì‹­ì‹œì˜¤. Artifactsì— ë¡œê·¸ëœ í›„ ì´ëŸ¬í•œ ì²´í¬í¬ì¸íŠ¸ëŠ” [Model Registry](../model_registry/intro.md)ë¡œ ìŠ¹ê²©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì €ì¥ëœ ëª¨ë¸ì„ ë¡œë“œí•˜ê¸°

`WANDB_LOG_MODEL`ë¡œ W&B Artifactsì— ëª¨ë¸ì„ ì €ì¥í–ˆìœ¼ë©´, ì¶”ê°€ íŠ¸ë ˆì´ë‹ì„ ìœ„í•´ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ ì¶”ë¡ ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•ì„œ ì‚¬ìš©í–ˆë˜ Hugging Face ì•„í‚¤í…ì²˜ì— ë‹¤ì‹œ ë¡œë“œí•˜ë©´ ë©ë‹ˆë‹¤.

```python
# ìƒˆë¡œìš´ run ìƒì„±
with wandb.init(project="amazon_sentiment_analysis") as run:
    # ì•„í‹°íŒ©íŠ¸ ì´ë¦„ ë° ë²„ì „ ì„¤ì •
    my_model_name = "model-bert-base-high-lr:latest"
    my_model_artifact = run.use_artifact(my_model_name)

    # ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ í´ë”ì— ë‹¤ìš´ë¡œë“œí•˜ê³  ê²½ë¡œ ë°˜í™˜
    model_dir = my_model_artifact.download()

    # ë™ì¼í•œ ëª¨ë¸ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ Hugging Face ëª¨ë¸ì„ í•´ë‹¹ í´ë”ì—ì„œ ë¡œë“œ
    model = AutoModelForSequenceClassification.from_pretrained(
        model_dir, num_labels=num_labels
    )

    # ì¶”ê°€ íŠ¸ë ˆì´ë‹ ë˜ëŠ” ì¶”ë¡  ì‹¤í–‰
```

### ì²´í¬í¬ì¸íŠ¸ì—ì„œ íŠ¸ë ˆì´ë‹ ì¬ê°œí•˜ê¸°
`WANDB_LOG_MODEL='checkpoint'`ë¡œ ì„¤ì •í–ˆë‹¤ë©´, `model_dir`ì„ `TrainingArguments`ì˜ `model_name_or_path` ì¸ìˆ˜ë¡œ ì‚¬ìš©í•˜ê³  `Trainer`ì— `resume_from_checkpoint=True`ë¥¼ ì „ë‹¬í•˜ì—¬ íŠ¸ë ˆì´ë‹ì„ ì¬ê°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
last_run_id = "xxxxxxxx"  # wandb ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì—ì„œ run_id ê°€ì ¸ì˜¤ê¸°

# run_idì—ì„œ wandb run ì¬ê°œ
with wandb.init(
    project=os.environ["WANDB_PROJECT"],
    id=last_run_id,
    resume="must",
) as run:
    # Artifactë¥¼ runì— ì—°ê²°
    my_checkpoint_name = f"checkpoint-{last_run_id}:latest"
    my_checkpoint_artifact = run.use_artifact(my_model_name)

    # ì²´í¬í¬ì¸íŠ¸ë¥¼ í´ë”ë¡œ ë‹¤ìš´ë¡œë“œí•˜ê³  ê²½ë¡œ ë°˜í™˜
    checkpoint_dir = my_checkpoint_artifact.download()

    # ëª¨ë¸ê³¼ íŠ¸ë ˆì´ë„ˆ ì¬ì´ˆê¸°í™”
    model = AutoModelForSequenceClassification.from_pretrained(
        "<model_name>", num_labels=num_labels
    )
    # ë©‹ì§„ íŠ¸ë ˆì´ë‹ ì¸ìˆ˜ëŠ” ì—¬ê¸°ì—.
    training_args = TrainingArguments()

    trainer = Trainer(model=model, args=training_args)

    # ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì²´í¬í¬ì¸íŠ¸ì—ì„œ íŠ¸ë ˆì´ë‹ ì¬ê°œ
    trainer.train(resume_from_checkpoint=checkpoint_dir)
```

### ì»¤ìŠ¤í…€ ë¡œê¹…: íŠ¸ë ˆì´ë‹ ì¤‘ í‰ê°€ ìƒ˜í”Œì„ ë¡œê·¸í•˜ê³  ë³´ê¸°

Weights & Biasesë¡œ Transformer's `Trainer`ì— ë¡œê¹…í•˜ëŠ” ê²ƒì€ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ [`WandbCallback`](https://huggingface.co/transformers/main_classes/callback.html#transformers.integrations.WandbCallback)ì— ì˜í•´ ì²˜ë¦¬ë©ë‹ˆë‹¤. Hugging Face ë¡œê¹…ì„ ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆí•´ì•¼ í•˜ëŠ” ê²½ìš° ì´ ì½œë°±ì„ ì„œë¸Œí´ë˜ì‹±í•˜ì—¬ `Trainer` í´ë˜ìŠ¤ì˜ ì¶”ê°€ ë©”ì†Œë“œë¥¼ í™œìš©í•˜ëŠ” ê¸°ëŠ¥ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì•„ë˜ëŠ” ì´ ìƒˆë¡œìš´ ì½œë°±ì„ HF Trainerì— ì¶”ê°€í•˜ëŠ” ì¼ë°˜ì ì¸ íŒ¨í„´ì´ë©°, ê·¸ ì•„ë˜ëŠ” íŠ¸ë ˆì´ë‹ ì¤‘ í‰ê°€ ì¶œë ¥ì„ W&B í…Œì´ë¸”ë¡œ ë¡œê·¸í•˜ëŠ” ì½”ë“œ ì™„ì„± ì˜ˆì œì…ë‹ˆë‹¤:

```python
# ì¼ë°˜ì ìœ¼ë¡œ Trainer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
trainer = Trainer()

# Trainer ê°ì²´ë¥¼ ì „ë‹¬í•˜ì—¬ ìƒˆë¡œìš´ ë¡œê¹… ì½œë°± ì¸ìŠ¤í„´ìŠ¤í™”
evals_callback = WandbEvalsCallback(trainer, tokenizer, ...)

# ì½œë°±ì„ Trainerì— ì¶”ê°€
trainer.add_callback(evals_callback)

# ì¼ë°˜ì ìœ¼ë¡œ Trainer íŠ¸ë ˆì´ë‹ ì‹œì‘
trainer.train()
```

#### íŠ¸ë ˆì´ë‹ ì¤‘ í‰ê°€ ìƒ˜í”Œ ë³´ê¸°

ë‹¤ìŒ ì„¹ì…˜ì—ì„œëŠ” `WandbCallback`ì„ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ì—¬ ëª¨ë¸ ì˜ˆì¸¡ì„ ì‹¤í–‰í•˜ê³  íŠ¸ë ˆì´ë‹ ì¤‘ W&B í…Œì´ë¸”ë¡œ í‰ê°€ ìƒ˜í”Œì„ ë¡œê·¸í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ëŠ” `Trainer` ì½œë°±ì˜ `on_evaluate` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë§¤ `eval_steps`ë§ˆë‹¤ ì˜ˆì¸¡ì„ ë¡œê·¸í•©ë‹ˆë‹¤.

ì—¬ê¸°ì„œ, ìš°ë¦¬ëŠ” ëª¨ë¸ ì¶œë ¥ì—ì„œ ì˜ˆì¸¡ê³¼ ë¼ë²¨ì„ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ ë””ì½”ë”©í•˜ëŠ” `decode_predictions` í•¨ìˆ˜ë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.

ê·¸ëŸ° ë‹¤ìŒ, ì˜ˆì¸¡ê³¼ ë¼ë²¨ë¡œë¶€í„° íŒë‹¤ìŠ¤ DataFrameì„ ìƒì„±í•˜ê³  DataFrameì— `epoch` ì—´ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

ë§ˆì§€ë§‰ìœ¼ë¡œ, DataFrameìœ¼ë¡œë¶€í„° `wandb.Table`ì„ ë§Œë“¤ê³  ì´ë¥¼ wandbì— ë¡œê·¸í•©ë‹ˆë‹¤. ë˜í•œ, `freq` ì—í¬í¬ë§ˆë‹¤ ì˜ˆì¸¡ì„ ë¡œê·¸í•˜ì—¬ ë¡œê·¸ ì£¼ê¸°ë¥¼ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì£¼ì˜ì‚¬í•­**: ì¼ë°˜ `WandbCallback`ê³¼ ë‹¬ë¦¬, ì´ ì»¤ìŠ¤í…€ ì½œë°±ì€ `Trainer` ì¸ìŠ¤í„´ìŠ¤í™” í›„ì— íŠ¸ë ˆì´ë„ˆì— ì¶”ê°€í•´ì•¼ í•˜ë©° `Trainer` ì´ˆê¸°í™” ì¤‘ì—ëŠ” ì¶”ê°€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ëŠ” `Trainer` ì¸ìŠ¤í„´ìŠ¤ê°€ ì´ˆê¸°í™” ì¤‘ì— ì½œë°±ì— ì „ë‹¬ë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

```python
from transformers.integrations import WandbCallback
import pandas as pd


def decode_predictions(tokenizer, predictions):
    labels = tokenizer.batch_decode(predictions.label_ids)
    logits = predictions.predictions.argmax(axis=-1)
    prediction_text = tokenizer.batch_decode(logits)
    return {"labels": labels, "predictions": prediction_text}


class WandbPredictionProgressCallback(WandbCallback):
    """íŠ¸ë ˆì´ë‹ ì¤‘ ëª¨ë¸ ì˜ˆì¸¡ì„ ë¡œê·¸í•˜ëŠ” ì»¤ìŠ¤í…€ WandbCallback.

    ì´ ì½œë°±ì€ íŠ¸ë ˆì´ë‹ ì¤‘ ë§¤ ë¡œê¹… ë‹¨ê³„ë§ˆë‹¤ ëª¨ë¸ ì˜ˆì¸¡ê³¼ ë¼ë²¨ì„ wandb.Tableì— ë¡œê·¸ì¸í•©ë‹ˆë‹¤.
    íŠ¸ë ˆì´ë‹ì´ ì§„í–‰ë¨ì— ë”°ë¼ ëª¨ë¸ ì˜ˆì¸¡ì„ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    ì†ì„±:
        trainer (Trainer): Hugging Face Trainer ì¸ìŠ¤í„´ìŠ¤.
        tokenizer (AutoTokenizer): ëª¨ë¸ê³¼ ê´€ë ¨ëœ í† í¬ë‚˜ì´ì €.
        sample_dataset (Dataset): 
íŠ¸ë ˆì´ë‹ ì¤‘ ë¡œê·¸ë§í•  í‰ê°€ ìƒ˜í”Œì˜ ë°ì´í„°ì…‹ ì„œë¸Œì…‹.
        num_samples (int, optional): 
ì˜ˆì¸¡ ìƒì„±ì„ ìœ„í•´ì„œ í‰ê°€ ë°ì´í„°ì…‹ì—ì„œ ì„ íƒí•  ìƒ˜í”Œ ìˆ˜. ê¸°ë³¸ê°’ì€ 100.
        freq (int, optional): 
ë¡œê¹… ì£¼ê¸°. ê¸°ë³¸ê°’ì€ 2.
    """

    def __init__(self, trainer, tokenizer, val_dataset,
                 num_samples=100, freq=2):
        """WandbPredictionProgressCallback ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        ì¸ìˆ˜:
            trainer (Trainer): Hugging Face Trainer ì¸ìŠ¤í„´ìŠ¤.
            tokenizer (AutoTokenizer): ëª¨ë¸ê³¼ ê´€ë ¨ëœ í† í¬ë‚˜ì´ì €.
            val_dataset (Dataset): í‰ê°€ ë°ì´í„°ì…‹.
            num_samples (int, optional): ì˜ˆì¸¡ ìƒì„±ì„ ìœ„í•´ì„œ í‰ê°€ ë°ì´í„°ì…‹ì—ì„œ ì„ íƒí•  ìƒ˜í”Œ ìˆ˜.
            ê¸°ë³¸ê°’ì€ 100.
            freq (int, optional): ë¡œê¹… ì£¼ê¸°. ê¸°ë³¸ê°’ì€ 2.
        """
        super().__init__()
        self.trainer = trainer
        self.tokenizer = tokenizer
        self.sample_dataset = val_dataset.select(range(num_samples))
        self.freq = freq

    def on_evaluate(self, args, state, control, **kwargs):
        super().on_evaluate(args, state, control, **kwargs)
        # ë¡œê¹… ì£¼ê¸°ë¥¼ ì œì–´í•˜ì—¬ ì˜ˆì¸¡ì„ `freq` ì—í¬í¬ë§ˆë‹¤ ë¡œê¹…
        if state.epoch % self.freq == 0:
            # ì˜ˆì¸¡ ìƒì„±
            predictions = self.trainer.predict(self.sample_dataset)
            # ì˜ˆì¸¡ê³¼ ë¼ë²¨ ë””ì½”ë”©
            predictions = decode_predictions(self.tokenizer, predictions)
            # ì˜ˆì¸¡ì„ wandb.Tableì— ì¶”ê°€
            predictions_df = pd.DataFrame(predictions)
            predictions_df["epoch"] = state.epoch
            records_table = self._wandb.Table(dataframe=predictions_df)
            # í…Œì´ë¸”ì„ wandbì— ë¡œê·¸
            self._wandb.log({"sample_predictions": records_table})


# ë¨¼ì €, íŠ¸ë ˆì´ë„ˆë¥¼ ì¸ìŠ¤í„´ìŠ¤í™”
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=lm_datasets["train"],
    eval_dataset=lm_datasets["validation"],
)

# WandbPredictionProgressCallbackì„ ì¸ìŠ¤í„´ìŠ¤í™”
progress_callback = WandbPredictionProgressCallback(
    trainer=trainer,
    tokenizer=tokenizer,
    val_dataset=lm_dataset["validation"],
    num_samples=10,
    freq=2,
)

# ì½œë°±ì„ íŠ¸ë ˆì´ë„ˆì— ì¶”ê°€
trainer.add_callback(progress_callback)
```

ë” ìì„¸í•œ ì˜ˆì œëŠ” [colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/huggingface/Custom_Progress_Callback.ipynb)ì„ ì°¸ì¡°í•˜ì„¸ìš”.

### ì¶”ê°€ W&B ì„¤ì •

`Trainer`ë¡œ ë¡œê¹…ë˜ëŠ” ë‚´ìš©ì„ ë”ìš± ì„¤ì •í•˜ë ¤ë©´ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì—¬ ê°€ëŠ¥í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. W&B í™˜ê²½ ë³€ìˆ˜ì˜ ì „ì²´ ëª©ë¡ì€ [ì—¬ê¸°ì„œ í™•ì¸](/guides/hosting/env-vars/)í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

| í™˜ê²½ ë³€ìˆ˜ | ìš©ë„                                                                                                                                                                                                                                                                                                  |
| -------------------- |------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `WANDB_PROJECT`      | í”„ë¡œì íŠ¸ì— ì´ë¦„ì„ ì§€ì • (`huggingface`ê°€ ê¸°ë³¸ê°’)                                                                                                                                                                                                                                                |
| `WANDB_LOG_MODEL`    | <p>ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ W&B Artifactë¡œ ë¡œê·¸ (`false`ê°€ ê¸°ë³¸ê°’) </p><ul><li><code>false</code> (ê¸°ë³¸ê°’): ëª¨ë¸ ì²´í¬í¬ì¸íŒ… ì—†ìŒ </li><li><code>checkpoint</code>: Trainersì˜ TrainingArgumentsì—ì„œ ì„¤ì •ëœ `args.save_steps`ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ê°€ ì—…ë¡œë“œ ë©ë‹ˆë‹¤. </li><li><code>end</code>: íŠ¸ë ˆì´ë‹ì´ ëë‚  ë•Œ ìµœì¢… ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ê°€ ì—…ë¡œë“œ ë©ë‹ˆë‹¤.</li></ul>                                                                                                                                                                                                                                   |
| `WANDB_WATCH`        | <p>ëª¨ë¸ ê·¸ë ˆì´ë””ì–¸íŠ¸, íŒŒë¼ë¯¸í„° ë˜ëŠ” ë‘˜ ì¤‘ ì•„ë¬´ ê²ƒë„ ë¡œê·¸í• ì§€ ì„¤ì •</p><ul><li><code>false</code> (ê¸°ë³¸ê°’): ê·¸ë ˆì´ë””ì–¸íŠ¸ ë˜ëŠ” íŒŒë¼ë¯¸í„° ë¡œê¹… ì—†ìŒ </li><li><code>gradients</code>: ê·¸ë ˆì´ë””ì–¸íŠ¸ì˜ íˆìŠ¤í† ê·¸ë¨ ë¡œê·¸ </li><li><code>all</code>: ê·¸ë ˆì´ë””ì–¸íŠ¸ì™€ íŒŒë¼ë¯¸í„° ë‘˜ ë‹¤ì˜ íˆìŠ¤í† ê·¸ë¨ ë¡œê·¸</li></ul> |
| `WANDB_DISABLED`     | ì „ì²´ ë¡œê¹…ì„ ë¹„í™œì„±í™”ë¡œ ì„¤ì • (`false`ê°€ ê¸°ë³¸ê°’)                                                                                                                                                                                                                                               |
| `WANDB_SILENT`       | wandbì˜ ì¶œë ¥ëœ ë‚´ìš©ì„ ê°ì¶”ë„ë¡ ì„¤ì • (`false`ê°€ ê¸°ë³¸ê°’)                                                                                                                                                                                                                                         |

<Tabs
  defaultValue="cli"
  values={[
    {label: 'Command Line', value: 'cli'},
    {label: 'Notebook', value: 'notebook'},
  ]}>
  <TabItem value="cli">

```bash
WANDB_WATCH=all
WANDB_SILENT=true
```

  </TabItem>
  <TabItem value="notebook">

```notebook
%env WANDB_WATCH=all
%env WANDB_SILENT=true
```

  </TabItem>
</Tabs>

### `wandb.init` ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆ í•˜ê¸°

`Trainer`ê°€ ì‚¬ìš©í•˜ëŠ” `WandbCallback`ì€ `Trainer`ê°€ ì´ˆê¸°í™”ë  ë•Œ ë‚´ë¶€ì ìœ¼ë¡œ `wandb.init`ì„ í˜¸ì¶œí•©ë‹ˆë‹¤. ëŒ€ì‹  `Trainer`ë¥¼ ì´ˆê¸°í™”í•˜ê¸° ì „ì— ìˆ˜ë™ìœ¼ë¡œ `wandb.init`ì„ í˜¸ì¶œí•˜ì—¬ runì„ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ W&B run ì„¤ì •ì— ëŒ€í•œ ì™„ì „í•œ ì œì–´ ê¶Œí•œì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

`init`ì— ì „ë‹¬í•  ìˆ˜ ìˆëŠ” ê²ƒì˜ ì˜ˆì‹œëŠ” ì•„ë˜ì— ë‚˜ì™€ ìˆìŠµë‹ˆë‹¤. `wandb.init`ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ì°¸ì¡° ë¬¸ì„œ](../../ref/python/init.md)ë¥¼ í™•ì¸í•˜ì„¸ìš”.

```python
wandb.init(
    project="amazon_sentiment_analysis",
    name="bert-base-high-lr",
    tags=["baseline", "high-lr"],
    group="bert",
)
```

## ì¶”ì²œ ì•„í‹°í´

ì•„ë˜ëŠ” Transformers ë° W&B ê´€ë ¨í•˜ì—¬ ì—¬ëŸ¬ë¶„ì´ ì¢‹ì•„í• ë§Œí•œ ì•„í‹°í´ë“¤ì´ ìˆìŠµë‹ˆë‹¤.

<details>

<summary>Hugging Face Transformersì— ëŒ€í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”</summary>

* Hugging Face Transformersì— ëŒ€í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ìœ„í•œ ì„¸ ê°€ì§€ ì „ëµì„ ë¹„êµí•©ë‹ˆë‹¤ - ê·¸ë¦¬ë“œ ê²€ìƒ‰, ë² ì´ì§€ì•ˆ ìµœì í™”, ëª¨ì§‘ë‹¨ì  í•™ìŠµ.
* Hugging Face íŠ¸ëœìŠ¤í¬ë¨¸ì˜ í‘œì¤€ uncased BERT ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©°, SuperGLUE ë²¤ì¹˜ë§ˆí¬ì—ì„œ RTE ë°ì´í„°ì…‹ì„ íŒŒì¸íŠœë‹í•©ë‹ˆë‹¤.
* ê²°ê³¼ëŠ” ëª¨ì§‘ë‹¨ì  í•™ìŠµì´ Hugging Face íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ìœ„í•œ ê°€ì¥ íš¨ê³¼ì ì¸ ì ‘ê·¼ë²•ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

ì „ì²´ ë¦¬í¬íŠ¸ë¥¼ [ì—¬ê¸°](https://wandb.ai/amogkam/transformers/reports/Hyperparameter-Optimization-for-Hugging-Face-Transformers--VmlldzoyMTc2ODI)ì—ì„œ ì½ì–´ë³´ì„¸ìš”.
</details>

<details>

<summary>Hugging Tweets: íŠ¸ìœ— ìƒì„± ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸°</summary>

* ì´ ì•„í‹°í´ì—ì„œ ì €ìëŠ” ëª‡ ë¶„ ì•ˆì— ëˆ„êµ¬ì˜ íŠ¸ìœ—ë„ ì‚¬ì „í•™ìŠµëœ GPT2 HuggingFace Transformer ëª¨ë¸ì— íŒŒì¸íŠœë‹ í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.
* ëª¨ë¸ì€ ë‹¤ìŒê³¼ ê°™ì€ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: íŠ¸ìœ— ë‹¤ìš´ë¡œë“œ, ë°ì´í„°ì…‹ ìµœì í™”, ì´ˆê¸° ì‹¤í—˜, ì‚¬ìš©ì ê°„ ì†ì‹¤ ë¹„êµ, ëª¨ë¸ íŒŒì¸íŠœë‹.

ì „ì²´ ë¦¬í¬íŠ¸ë¥¼ [ì—¬ê¸°](https://wandb.ai/wandb/huggingtweets/reports/HuggingTweets-Train-a-Model-to-Generate-Tweets--VmlldzoxMTY5MjI)ì—ì„œ ì½ì–´ë³´ì„¸ìš”.
</details>

<details>

<summary>Hugging Face BERTì™€ W&Bë¥¼ ì‚¬ìš©í•œ ë¬¸ì¥ ë¶„ë¥˜</summary>

* ì´ ì•„í‹°í´ì—ì„œëŠ” NLPì˜ ì „ì´ í•™ìŠµì˜ í•œ ì‘ìš©ì— ì´ˆì ì„ ë§ì¶”ì–´ ìµœê·¼ ìì—°ì–´ ì²˜ë¦¬ì˜ ëŒíŒŒêµ¬ë¥¼ í™œìš©í•˜ì—¬ ë¬¸ì¥ ë¶„ë¥˜ê¸°ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
* ë‹¨ì¼ ë¬¸ì¥ ë¶„ë¥˜ë¥¼ ìœ„í•œ The Corpus of Linguistic Acceptability (CoLA) ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•  ê²ƒì´ë©°, ì²˜ìŒì—ëŠ” ë¬¸ë²•ì ìœ¼ë¡œ ì •í™•í•˜ê±°ë‚˜ ë¶€ì •í™•í•œ ë¬¸ì¥ ì„¸íŠ¸ë¡œ 2018ë…„ 5ì›”ì— ì²«ë²ˆì§¸ë¡œ ê²Œì‹œë˜ì—ˆìŠµë‹ˆë‹¤.
* ìš°ë¦¬ëŠ” Googleì˜ BERTë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì†Œí•œì˜ ë…¸ë ¥ìœ¼ë¡œ ë‹¤ì–‘í•œ NLP ì‘ì—…ì—ì„œ ë†’ì€ ì„±ëŠ¥ì˜ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.

ì „ì²´ ë¦¬í¬íŠ¸ë¥¼ [ì—¬ê¸°](https://wandb.ai/cayush/bert-finetuning/reports/Sentence-Classification-With-Huggingface-BERT-and-W-B--Vmlldzo4MDMwNA)ì—ì„œ ì½ì–´ë³´ì„¸ìš”.
</details>

<details>

<summary>Hugging Face ëª¨ë¸ ì„±ëŠ¥ ì¶”ì ì˜ ë‹¨ê³„ë³„ ê°€ì´ë“œ</summary>

* DistilBERT, BERTì˜ 40% ë” ì‘ì€ Transformerì´ì§€ë§Œ BERTì˜ ì •í™•ë„ 97%ë¥¼ ìœ ì§€í•œ ëª¨ë¸ì„ Weights & Biasesì™€ Hugging Face transformersë¥¼ ì‚¬ìš©í•˜ì—¬ GLUE ë²¤ì¹˜ë§ˆí¬ì—ì„œ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ì„ ì‚´í´ë´…ë‹ˆë‹¤.
* GLUE ë²¤ì¹˜ë§ˆí¬ëŠ” NLP ëª¨ë¸ íŠ¸ë ˆì´ë‹ì„ ìœ„í•œ ì•„í™‰ ê°œì˜ ë°ì´í„°ì…‹ê³¼ ì‘ì—…ìœ¼ë¡œ êµ¬ì„±ëœ ì»¬ë ‰ì…˜ì…ë‹ˆë‹¤.

ì „ì²´ ë¦¬í¬íŠ¸ë¥¼ [ì—¬ê¸°](https://wandb.ai/jxmorris12/huggingface-demo/reports/A-Step-by-Step-Guide-to-Tracking-HuggingFace-Model-Performance--VmlldzoxMDE2MTU)ì—ì„œ ì½ì–´ë³´ì„¸ìš”.
</details>

<details>

<summary>HuggingFaceì˜ ì¡°ê¸° ì¤‘ì§€ - ì˜ˆì œë“¤</summary>

* ì¡°ê¸° ì¤‘ì§€ ì •ê·œí™”ë¥¼ ì‚¬ìš©í•˜ì—¬ Hugging Face Transformerë¥¼ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ì€ PyTorch ë˜ëŠ” TensorFlowì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* TensorFlowì—ì„œ EarlyStopping ì½œë°±ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ `tf.keras.callbacks.EarlyStopping` ì½œë°±ìœ¼ë¡œ ê°„ë‹¨í•©ë‹ˆë‹¤.
* PyTorchì—ì„œëŠ” ìì²´ì ì¸ ì¡°ê¸° ì¤‘ì§€ ë°©ë²•ì´ ì—†ì§€ë§Œ GitHub Gistì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì›Œí‚¹ ì¡°ê¸° ì¤‘ì¹˜ í›…ì´ ìˆìŠµë‹ˆë‹¤.

ì „ì²´ ë¦¬í¬íŠ¸ë¥¼ [ì—¬ê¸°](https://wandb.ai/ayush-thakur/huggingface/reports/Early-Stopping-in-HuggingFace-Examples--Vmlldzo0MzE2MTM)ì—ì„œ ì½ì–´ë³´ì„¸ìš”.
</details>

<details>

<summary>ì‚¬ìš©ì ì§€ì • ë°ì´í„°ì…‹ì— Hugging Face Transformers íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•</summary>

  ìš°ë¦¬ëŠ” ì»¤ìŠ¤í…€ IMDB ë°ì´í„°ì…‹ì—ì„œ ê°ì • ë¶„ì„(ì´ì§„ ë¶„ë¥˜)ì„ ìœ„í•´ DistilBERT íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ íŒŒì¸íŠœë‹í•©ë‹ˆë‹¤.

ì „ì²´ ë¦¬í¬íŠ¸ë¥¼ [ì—¬ê¸°](https://wandb.ai/ayush-thakur/huggingface/reports/How-to-Fine-Tune-HuggingFace-Transformers-on-a-Custom-Dataset--Vmlldzo0MzQ2MDc)ì—ì„œ ì½ì–´ë³´ì„¸ìš”.
</details>

## ì´ìŠˆ, ì§ˆë¬¸, ê¸°ëŠ¥ ìš”ì²­

Hugging Face W&B ì¸í…Œê·¸ë ˆì´ì…˜ì— ëŒ€í•œ ë¬¸ì œ, ì§ˆë¬¸ ë˜ëŠ” ê¸°ëŠ¥ ìš”ì²­ì— ëŒ€í•´, [Hugging Face í¬ëŸ¼ì˜ ì´ ìŠ¤ë ˆë“œ](https://discuss.huggingface.co/t/logging-experiment-tracking-with-w-b/498)ì— ê²Œì‹œí•˜ê±°ë‚˜ Hugging Face [Transformers GitHub repo](https://github.com/huggingface/transformers)ì— ì´ìŠˆë¥¼ ì—´ì–´ì£¼ì„¸ìš”.