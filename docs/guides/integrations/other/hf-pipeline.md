---
slug: /guides/integrations/huggingface-pipelines
description: How to integrate HuggingFace Pipelines ðŸ¤— with OpenAI.
displayed_sidebar: default
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Hugging Face Pipelines

## Log OpenAI API calls in 1 line of code

**[Try in a Colab Notebook here â†’](https://github.com/wandb/examples/blob/master/colabs/openai/OpenAI_API_Autologger_Quickstart.ipynb)**

With just 1 line of code you can now automatically log inputs and outputs from HuggingFace Transformers Pipelines to Weights & Biases!

![](/images/integrations/qna_autologged_table_hf_pipelines.png)

Once you start logging your API inputs and outputs you can quickly evaluate the performance of difference queries, compare different model settings, and track other important metadata.

To get started, pip install the `wandb` library, then follow the steps below:

### 1. Import autolog and initialise it

First, import `autolog` from `wandb.integration.huggingface` and initialise it.

```python
from transformers import pipeline
from wandb.integration.huggingface import autolog

autolog({"project":"fine-tuned-OS_GPT"})
```

You can optionally pass a dictionary with argument that `wandb.init()` accepts to `autolog`. This includes a project name, team name, entity, and more. For more information about [`wandb.init`](../../../ref/python/init.md), see the API Reference Guide.

### 2. Call a Supported HuggingFace Pipeline

Each call you make to a supported HuggingFace Pipeline will now be logged to Weights & Biases automatically.

```python
SUPPORTED_PIPELINE_TASKS = [
    "text-classification",
    "sentiment-analysis",
    "question-answering",
    "summarization",
    "translation",
    "text2text-generation",
    "text-generation",
]
task = "text-classification" #any task from SUPPORTED_PIPELINE_TASKS
task_pipeline = pipeline(task)
query = "This tracker is amazing!"

response = task_pipeline(query, **kwargs)
# [{'label': 'POSITIVE', 'score': 0.98}, {'label': 'NEGATIVE', 'score': 0.02}]
```

### 3. View your HuggingFace Pipeline inputs and responses

Click on the Weights & Biases [run](../../runs/intro.md) link generated by `autolog` in **step 1**. This will redirect you to your project workspace in the W&B App.

Select a run you created to view the model details, all the inputs and outputs, and any necessary metadata, from your HuggingFace Pipeline.

### 4. Disable autolog

We recommend that you call `disable()` to close all W&B processes when you are finished using the OpenAI API.

```python
autolog.disable()
```

Now your inputs and completions will be logged to Weights & Biases, ready for analysis or to be shared with colleagues.

### Can I track my datasets with W&B?

Yes, you can integrate your entire pipeline to W&B through Artifacts, including creating your dataset, splitting it, training your models and evaluating them!

This will allow complete traceability of your models. You can read more about it [here](../../artifacts/quickstart.md).

## :books: Resources

- [Demo Colab](https://colab.research.google.com/drive/1k4LT1JW6hYUwyjklftc_1M95uYrytiW1#scrollTo=5I2-81XtuIdl)
